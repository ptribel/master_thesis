{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutionnal Generative Adversarial Networks\n",
    "## Initialisation and dataset preparation\n",
    "\n",
    "First, let us import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us include the dataset.\n",
    "\n",
    "The dataset is made of two files: `clean/p1.wav`and `white/p1.wav` which are converted into arrays of `int32` and then split into segments of `samples_length`.\n",
    "\n",
    "The goal of the CGAN here is to predict the clean sample, when fed with the white one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"int32\")\n",
    "white = np.array(white, dtype=\"int32\")\n",
    "\n",
    "clean_dataset = []\n",
    "white_dataset = []\n",
    "\n",
    "samples_length = nperseg\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_dataset.append(clean[i:i+samples_length])\n",
    "    white_dataset.append(white[i:i+samples_length])\n",
    "clean_dataset = np.array(clean_dataset)\n",
    "white_dataset = np.array(white_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10659, 3, 513) (10659, 3, 513) (10659, 3, 513) (10659, 3, 513)\n"
     ]
    }
   ],
   "source": [
    "stft_clean_dataset_real = []\n",
    "stft_clean_dataset_imag = []\n",
    "stft_white_dataset_real = []\n",
    "stft_white_dataset_imag = []\n",
    "\n",
    "for i in clean_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_clean_dataset_real.append(np.real(inp).T)\n",
    "    stft_clean_dataset_imag.append(np.imag(inp).T)\n",
    "    \n",
    "for i in white_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_white_dataset_real.append(np.real(inp).T)\n",
    "    stft_white_dataset_imag.append(np.imag(inp).T)\n",
    "\n",
    "stft_clean_dataset_real = np.array(stft_clean_dataset_real)\n",
    "stft_clean_dataset_imag = np.array(stft_clean_dataset_imag)\n",
    "stft_white_dataset_real = np.array(stft_white_dataset_real)\n",
    "stft_white_dataset_imag = np.array(stft_white_dataset_imag)\n",
    "print(stft_clean_dataset_real.shape, stft_clean_dataset_imag.shape, stft_white_dataset_real.shape, stft_white_dataset_imag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN Model\n",
    "The main idea of a GAN model is to create two networks who play an adversarial game:\n",
    "- A Generator, whose goal is to produce the most realistic samples possible to fool the Discriminator\n",
    "- A Discriminator, whose goal is to correctly guess if its input is a real sample from the clean dataset or an output created by the Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator here uses a layer to process the Short-Time Fourier Transform (https://en.wikipedia.org/wiki/Short-time_Fourier_transform) before reducing the problem dimension to one single boolean prediction layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]))\n",
    "    x2 = tf.keras.layers.Dense(512, activation=\"tanh\")(inputs)\n",
    "    x3 = tf.keras.layers.Dense(256, activation=\"tanh\")(x2)\n",
    "    x4 = tf.keras.layers.Dense(128, activation=\"tanh\")(x3)\n",
    "    x5 = tf.keras.layers.Dense(1, activation=\"tanh\")(x4)\n",
    "    x6 = tf.keras.layers.Flatten()(x5)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"tanh\")(x6)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer= 'adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "The generator itself is a Convolutionnal Autoencoder.\n",
    "\n",
    "Its input size and output size are both the size of the stft array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sizes):\n",
    "    inputs = tf.keras.Input(shape=(sizes[1], sizes[2]))\n",
    "    x1 = tf.keras.layers.Dense(128, activation='tanh')(inputs)\n",
    "    x2 = tf.keras.layers.Dense(32, activation='tanh')(x1)\n",
    "    x3 = tf.keras.layers.Dense(128, activation='tanh')(x2)\n",
    "    x4 = tf.keras.layers.Dense(sizes[2], activation='tanh')(x3)\n",
    "    x5 = tf.keras.layers.Add()([inputs, x4])\n",
    "    outputs = tf.keras.layers.Dense(sizes[2], activation='linear')(x5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"autoencoder\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take care, the distance between the raw audio might be 'too continuous' to use a classical distance function. Maybe, use the distance function on the STFT's, or another loss function on the raw audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_generator(g, inputs, outputs, size):\n",
    "    res = 0\n",
    "    s = min(size, inputs.shape[0])\n",
    "    for i in range(s):\n",
    "        expected = outputs[i]\n",
    "        c, t, inp = stft(inputs[i], fs=samplerate, nperseg=nperseg)\n",
    "        inp_real = np.real(inp)\n",
    "        inp_imag = np.imag(inp)\n",
    "        y = np.reshape(inp_real.T, (-1, inp_real.shape[1], inp_real.shape[0]))\n",
    "        prediction = np.reshape(g.predict(y), (inp_real.shape[0], inp_real.shape[1]))\n",
    "        t, y1 = istft(prediction + np.imag(inp_imag))\n",
    "        res += (sum((expected-y1)**2)/expected.shape[0])\n",
    "    return res/(s*10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_outputs(white, train_size, g, nperseg, clean):\n",
    "    rng = np.random.default_rng()\n",
    "    g_outputs = []\n",
    "    batch = rng.choice(white, train_size)\n",
    "    for i in range(train_size):\n",
    "        t = np.reshape(white[i, :, :], (-1, white.shape[1], white.shape[2]))\n",
    "        m = g.predict(t)\n",
    "        g_outputs.append(m)\n",
    "    g_outputs = np.reshape(np.array(g_outputs), (train_size,  white.shape[1], white.shape[2]))\n",
    "    input_data = np.concatenate((g_outputs, clean[:train_size,]))\n",
    "    output_data = np.concatenate((-1*np.ones((train_size,)), np.ones((train_size,))))\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 3, 513)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 3, 128)       65792       input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 3, 32)        4128        dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 3, 128)       4224        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 3, 513)       66177       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 3, 513)       0           input_17[0][0]                   \n",
      "                                                                 dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 3, 513)       263682      add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 404,003\n",
      "Trainable params: 404,003\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 3, 513)]          0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3, 512)            263168    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3, 1)              129       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 427,525\n",
      "Trainable params: 427,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN:\n",
    "    def __init__(self, size, g, d):\n",
    "        self.g = g\n",
    "        self.d = d\n",
    "        self.z = tf.keras.layers.Input(shape=(size[1],size[2]))\n",
    "        self.image = self.g(self.z)\n",
    "        self.valid = self.d(self.image)\n",
    "        self.combined_network = tf.keras.Model(self.z, self.valid)\n",
    "        self.compile()\n",
    "    def block_discriminator(self):\n",
    "        self.d.trainable = False\n",
    "        self.g.trainable = True\n",
    "        self.compile()\n",
    "    def block_generator(self):\n",
    "        self.g.trainable = False\n",
    "        self.d.trainable = True\n",
    "        self.compile()\n",
    "    def compile(self):\n",
    "        self.combined_network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        #combined_network.summary()\n",
    "\n",
    "g = generator(stft_white_dataset_real.shape)\n",
    "d = discriminator(stft_white_dataset_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(d, i, o, verbose=True):  \n",
    "    history = d.fit(i, o, batch_size=16, verbose=verbose)\n",
    "    return np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Training the discriminator\n",
      "0.003949999809265137\n",
      "0.4874500036239624\n",
      "0.5\n",
      "Training the generator\n",
      "0.5580999851226807\n",
      "0.984499990940094\n",
      "Step 1\n",
      "Training the discriminator\n",
      "0.4918999969959259\n",
      "0.5\n",
      "Training the generator\n",
      "0.3059999942779541\n",
      "0.9323999881744385\n",
      "0.9800999760627747\n",
      "Step 2\n",
      "Training the discriminator\n",
      "0.4941500127315521\n",
      "0.4999000132083893\n",
      "0.5\n",
      "Training the generator\n",
      "0.1671999990940094\n",
      "0.8517000079154968\n",
      "0.9584000110626221\n",
      "Step 3\n",
      "Training the discriminator\n",
      "0.4939500093460083\n",
      "0.5\n",
      "Training the generator\n",
      "0.0017000000225380063\n",
      "0.26649999618530273\n",
      "0.7792999744415283\n",
      "0.9083999991416931\n",
      "0.9434999823570251\n",
      "0.9609000086784363\n",
      "Step 4\n",
      "Training the discriminator\n",
      "0.49334999918937683\n",
      "0.49970000982284546\n",
      "0.5\n",
      "Training the generator\n",
      "0.0\n",
      "0.021800000220537186\n",
      "0.4203999936580658\n",
      "0.7276999950408936\n",
      "0.8367000222206116\n",
      "0.8944000005722046\n",
      "0.9192000031471252\n",
      "0.9381999969482422\n",
      "0.9502999782562256\n",
      "Step 5\n",
      "Training the discriminator\n",
      "0.4918000102043152\n",
      "0.49869999289512634\n",
      "0.49935001134872437\n",
      "0.49924999475479126\n",
      "0.4995500147342682\n",
      "0.4995500147342682\n",
      "0.499099999666214\n",
      "0.49970000982284546\n",
      "0.49970000982284546\n",
      "0.49915000796318054\n",
      "0.4997999966144562\n",
      "0.5\n",
      "Training the generator\n",
      "0.0\n",
      "0.0003000000142492354\n",
      "0.002099999925121665\n",
      "0.01119999960064888\n",
      "0.06689999997615814\n",
      "0.24220000207424164\n",
      "0.48559999465942383\n",
      "0.6588000059127808\n",
      "0.7666000127792358\n",
      "0.829200029373169\n",
      "0.8723999857902527\n",
      "0.8945000171661377\n",
      "0.909500002861023\n",
      "0.9271000027656555\n",
      "0.9387999773025513\n",
      "0.9470000267028809\n",
      "0.9545000195503235\n",
      "Step 6\n",
      "Training the discriminator\n",
      "0.4932500123977661\n",
      "0.49900001287460327\n",
      "0.4994499981403351\n",
      "0.49939998984336853\n",
      "0.4995500147342682\n",
      "0.4996500015258789\n",
      "0.49915000796318054\n",
      "0.49935001134872437\n",
      "0.4994499981403351\n",
      "0.4997499883174896\n",
      "0.4995500147342682\n",
      "0.4991999864578247\n",
      "0.49970000982284546\n",
      "0.4999000132083893\n",
      "0.4996500015258789\n",
      "0.4989500045776367\n",
      "0.49950000643730164\n",
      "0.49994999170303345\n",
      "0.49950000643730164\n",
      "0.4996500015258789\n",
      "0.49935001134872437\n",
      "0.49959999322891235\n",
      "0.49985000491142273\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.4994499981403351\n",
      "0.4996500015258789\n",
      "0.49959999322891235\n",
      "0.4999000132083893\n",
      "0.4997499883174896\n",
      "0.49950000643730164\n",
      "0.4999000132083893\n",
      "0.49950000643730164\n",
      "0.4995500147342682\n",
      "0.4997999966144562\n",
      "0.5\n",
      "Training the generator\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "0.00039999998989515007\n",
      "0.0010999999940395355\n",
      "0.0006000000284984708\n",
      "0.001500000013038516\n",
      "0.001500000013038516\n",
      "0.0026000000070780516\n",
      "0.004000000189989805\n",
      "0.007300000172108412\n",
      "0.01080000028014183\n",
      "0.012900000438094139\n",
      "0.01769999973475933\n",
      "0.022199999541044235\n",
      "0.025599999353289604\n",
      "0.02850000001490116\n",
      "0.033900000154972076\n",
      "0.03400000184774399\n",
      "0.04170000180602074\n",
      "0.04410000145435333\n",
      "0.04740000143647194\n",
      "0.05209999904036522\n",
      "0.06270000338554382\n",
      "0.0723000019788742\n",
      "0.08089999854564667\n",
      "0.08910000324249268\n",
      "0.10369999706745148\n",
      "0.11569999903440475\n",
      "0.12960000336170197\n",
      "0.13689999282360077\n",
      "0.14399999380111694\n",
      "0.15700000524520874\n",
      "0.18160000443458557\n",
      "0.20360000431537628\n",
      "0.22269999980926514\n",
      "0.23399999737739563\n",
      "0.2517000138759613\n",
      "0.27639999985694885\n",
      "0.3068000078201294\n",
      "0.3497999906539917\n",
      "0.388700008392334\n",
      "0.4228000044822693\n",
      "0.44850000739097595\n",
      "0.48489999771118164\n",
      "0.5062999725341797\n",
      "0.5254999995231628\n",
      "0.5515000224113464\n",
      "0.5809000134468079\n",
      "0.6085000038146973\n",
      "0.6391000151634216\n",
      "0.6516000032424927\n",
      "0.673799991607666\n",
      "0.6863999962806702\n",
      "0.7092999815940857\n",
      "0.7211999893188477\n",
      "0.7398999929428101\n",
      "0.7581999897956848\n",
      "0.7713000178337097\n",
      "0.789900004863739\n",
      "0.8051999807357788\n",
      "0.8145999908447266\n",
      "0.826200008392334\n",
      "0.8278999924659729\n",
      "0.8325999975204468\n",
      "0.8348000049591064\n",
      "0.8348000049591064\n",
      "0.850600004196167\n",
      "0.8522999882698059\n",
      "0.8565999865531921\n",
      "0.8669000267982483\n",
      "0.8716999888420105\n",
      "0.8762000203132629\n",
      "0.8747000098228455\n",
      "0.8827999830245972\n",
      "0.8838000297546387\n",
      "0.885200023651123\n",
      "0.8981000185012817\n",
      "0.9039000272750854\n",
      "0.9060999751091003\n",
      "0.9100000262260437\n",
      "0.9110000133514404\n",
      "0.9132000207901001\n",
      "0.9100000262260437\n",
      "0.9132000207901001\n",
      "0.9138000011444092\n",
      "0.9125999808311462\n",
      "0.9096999764442444\n",
      "0.9125999808311462\n",
      "0.9101999998092651\n",
      "0.917900025844574\n",
      "0.9172999858856201\n",
      "0.917900025844574\n",
      "0.9240999817848206\n",
      "0.9266999959945679\n",
      "0.9290000200271606\n",
      "0.9279000163078308\n",
      "0.9301999807357788\n",
      "0.9294999837875366\n",
      "0.9280999898910522\n",
      "0.9325000047683716\n",
      "0.9329000115394592\n",
      "0.9323999881744385\n",
      "0.9337999820709229\n",
      "0.9380000233650208\n",
      "0.9343000054359436\n",
      "0.9347000122070312\n",
      "0.9344000220298767\n",
      "0.9379000067710876\n",
      "0.9369000196456909\n",
      "0.9343000054359436\n",
      "0.9366000294685364\n",
      "0.9377999901771545\n",
      "0.9355000257492065\n",
      "0.9362999796867371\n",
      "0.9351999759674072\n",
      "0.9391000270843506\n",
      "0.942300021648407\n",
      "0.9430999755859375\n",
      "0.9373999834060669\n",
      "0.9384999871253967\n",
      "0.9401999711990356\n",
      "0.9416000247001648\n",
      "0.9420999884605408\n",
      "0.944599986076355\n",
      "0.9465000033378601\n",
      "0.9483000040054321\n",
      "0.9449999928474426\n",
      "0.9462000131607056\n",
      "0.9467999935150146\n",
      "0.9476000070571899\n",
      "0.9492999911308289\n",
      "0.9458000063896179\n",
      "0.9472000002861023\n",
      "0.9473999738693237\n",
      "0.9480000138282776\n",
      "0.949400007724762\n",
      "0.9524000287055969\n",
      "Step 7\n",
      "Training the discriminator\n",
      "0.4878000020980835\n",
      "0.49825000762939453\n",
      "0.499099999666214\n",
      "0.4994499981403351\n",
      "0.49900001287460327\n",
      "0.4991999864578247\n",
      "0.4994499981403351\n",
      "0.4987500011920929\n",
      "0.49935001134872437\n",
      "0.4993000030517578\n",
      "0.4994499981403351\n",
      "0.4994499981403351\n",
      "0.49924999475479126\n",
      "0.4996500015258789\n",
      "0.4994499981403351\n",
      "0.49950000643730164\n",
      "0.49959999322891235\n",
      "0.4995500147342682\n",
      "0.49985000491142273\n",
      "0.4997499883174896\n",
      "0.5\n",
      "Training the generator\n",
      "0.0\n",
      "0.0\n",
      "0.0003000000142492354\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "9.999999747378752e-05\n",
      "0.00019999999494757503\n",
      "9.999999747378752e-05\n",
      "9.999999747378752e-05\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.0003000000142492354\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.0005000000237487257\n",
      "0.0005000000237487257\n",
      "0.0005000000237487257\n",
      "0.0006000000284984708\n",
      "0.0007999999797903001\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.0007999999797903001\n",
      "0.0007999999797903001\n",
      "0.0010000000474974513\n",
      "0.00139999995008111\n",
      "0.0010000000474974513\n",
      "0.001500000013038516\n",
      "0.0013000000035390258\n",
      "0.0010999999940395355\n",
      "0.00139999995008111\n",
      "0.0013000000035390258\n",
      "0.0010000000474974513\n",
      "0.0012000000569969416\n",
      "0.0015999999595806003\n",
      "0.00139999995008111\n",
      "0.0020000000949949026\n",
      "0.00279999990016222\n",
      "0.00279999990016222\n",
      "0.003000000026077032\n",
      "0.005200000014156103\n",
      "0.006899999920278788\n",
      "0.006500000134110451\n",
      "0.006099999882280827\n",
      "0.0071000000461936\n",
      "0.006099999882280827\n",
      "0.006500000134110451\n",
      "0.009200000204145908\n",
      "0.010700000450015068\n",
      "0.012299999594688416\n",
      "0.012199999764561653\n",
      "0.013199999928474426\n",
      "0.015200000256299973\n",
      "0.016899999231100082\n",
      "0.016699999570846558\n",
      "0.01720000058412552\n",
      "0.017000000923871994\n",
      "0.01720000058412552\n",
      "0.019899999722838402\n",
      "0.02250000089406967\n",
      "0.02280000038444996\n",
      "0.026100000366568565\n",
      "0.026100000366568565\n",
      "0.029400000348687172\n",
      "0.03200000151991844\n",
      "0.03099999949336052\n",
      "0.033900000154972076\n",
      "0.039400000125169754\n",
      "0.04349999874830246\n",
      "0.049800001084804535\n",
      "0.05460000038146973\n",
      "0.059700001031160355\n",
      "0.05889999866485596\n",
      "0.06279999762773514\n",
      "0.07020000368356705\n",
      "0.0754999965429306\n",
      "0.08179999887943268\n",
      "0.09049999713897705\n",
      "0.10239999741315842\n",
      "0.10270000249147415\n",
      "0.11909999698400497\n",
      "0.12520000338554382\n",
      "0.13199999928474426\n",
      "0.13940000534057617\n",
      "0.14910000562667847\n",
      "0.1662999987602234\n",
      "0.1761000007390976\n",
      "0.1931000053882599\n",
      "0.2092999964952469\n",
      "0.22030000388622284\n",
      "0.24070000648498535\n",
      "0.2558000087738037\n",
      "0.2605000138282776\n",
      "0.2851000130176544\n",
      "0.2939999997615814\n",
      "0.30550000071525574\n",
      "0.3249000012874603\n",
      "0.3407999873161316\n",
      "0.35830000042915344\n",
      "0.37220001220703125\n",
      "0.3962000012397766\n",
      "0.41359999775886536\n",
      "0.4244000017642975\n",
      "0.44029998779296875\n",
      "0.4632999897003174\n",
      "0.475600004196167\n",
      "0.48989999294281006\n",
      "0.5091999769210815\n",
      "0.5309000015258789\n",
      "0.5508999824523926\n",
      "0.5630999803543091\n",
      "0.5756000280380249\n",
      "0.5799000263214111\n",
      "0.5989999771118164\n",
      "0.6079999804496765\n",
      "0.6172999739646912\n",
      "0.6274999976158142\n",
      "0.6310999989509583\n",
      "0.6527000069618225\n",
      "0.6607999801635742\n",
      "0.6740000247955322\n",
      "0.6901000142097473\n",
      "0.699400007724762\n",
      "0.7070000171661377\n",
      "0.7102000117301941\n",
      "0.7192000150680542\n",
      "0.7192999720573425\n",
      "0.7211999893188477\n",
      "0.7247999906539917\n",
      "0.7361000180244446\n",
      "0.7386999726295471\n",
      "0.7480000257492065\n",
      "0.7547000050544739\n",
      "0.7623000144958496\n",
      "0.7745000123977661\n",
      "0.7786999940872192\n",
      "0.7871999740600586\n",
      "0.7886000275611877\n",
      "0.796500027179718\n",
      "0.8040000200271606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8051000237464905\n",
      "0.8112000226974487\n",
      "0.8069000244140625\n",
      "0.8059999942779541\n",
      "0.8155999779701233\n",
      "0.8206999897956848\n",
      "0.817799985408783\n",
      "0.8241000175476074\n",
      "0.8288999795913696\n",
      "0.8378999829292297\n",
      "0.8446999788284302\n",
      "0.8497999906539917\n",
      "0.8531000018119812\n",
      "0.8551999926567078\n",
      "0.8551999926567078\n",
      "0.8629000186920166\n",
      "0.8615000247955322\n",
      "0.8608999848365784\n",
      "0.8610000014305115\n",
      "0.8611999750137329\n",
      "0.8708000183105469\n",
      "0.8712999820709229\n",
      "0.8694000244140625\n",
      "0.8704000115394592\n",
      "0.8747000098228455\n",
      "0.8766999840736389\n",
      "0.876800000667572\n",
      "0.8827999830245972\n",
      "0.8841999769210815\n",
      "0.8877999782562256\n",
      "0.8891000151634216\n",
      "0.8931999802589417\n",
      "0.8901000022888184\n",
      "0.8931000232696533\n",
      "0.8942000269889832\n",
      "0.8942999839782715\n",
      "0.8917999863624573\n",
      "0.8878999948501587\n",
      "0.8844000101089478\n",
      "0.8896999955177307\n",
      "0.8974000215530396\n",
      "0.8924000263214111\n",
      "0.9013000130653381\n",
      "0.9046000242233276\n",
      "0.9043999910354614\n",
      "0.9045000076293945\n",
      "0.9077000021934509\n",
      "0.9049000144004822\n",
      "0.9093000292778015\n",
      "0.9118000268936157\n",
      "0.909500002861023\n",
      "0.9133999943733215\n",
      "0.9090999960899353\n",
      "0.9103000164031982\n",
      "0.9093999862670898\n",
      "0.913100004196167\n",
      "0.9121000170707703\n",
      "0.9151999950408936\n",
      "0.9160000085830688\n",
      "0.9158999919891357\n",
      "0.9153000116348267\n",
      "0.9150000214576721\n",
      "0.917900025844574\n",
      "0.9150999784469604\n",
      "0.9157000184059143\n",
      "0.9212999939918518\n",
      "0.9176999926567078\n",
      "0.9240000247955322\n",
      "0.9271000027656555\n",
      "0.9276999831199646\n",
      "0.929099977016449\n",
      "0.9323999881744385\n",
      "0.9323999881744385\n",
      "0.932200014591217\n",
      "0.9333000183105469\n",
      "0.9337000250816345\n",
      "0.9362000226974487\n",
      "0.9354000091552734\n",
      "0.9380999803543091\n",
      "0.9391999840736389\n",
      "0.9387000203132629\n",
      "0.9383000135421753\n",
      "0.9398999810218811\n",
      "0.9395999908447266\n",
      "0.9395999908447266\n",
      "0.942300021648407\n",
      "0.9430999755859375\n",
      "0.9434999823570251\n",
      "0.9448999762535095\n",
      "0.9430000185966492\n",
      "0.9429000020027161\n",
      "0.9409000277519226\n",
      "0.9417999982833862\n",
      "0.9416000247001648\n",
      "0.946399986743927\n",
      "0.9480000138282776\n",
      "0.9488000273704529\n",
      "0.9492999911308289\n",
      "0.9490000009536743\n",
      "0.9501000046730042\n",
      "Step 8\n",
      "Training the discriminator\n",
      "0.4818499982357025\n",
      "0.4961000084877014\n",
      "0.49825000762939453\n",
      "0.4975000023841858\n",
      "0.49880000948905945\n",
      "0.49869999289512634\n",
      "0.4975999891757965\n",
      "0.4986500144004822\n",
      "0.4989500045776367\n",
      "0.49900001287460327\n",
      "0.4988499879837036\n",
      "0.49904999136924744\n",
      "0.4995500147342682\n",
      "0.4995500147342682\n",
      "0.499099999666214\n",
      "0.49950000643730164\n",
      "0.49950000643730164\n",
      "0.49915000796318054\n",
      "0.49904999136924744\n",
      "0.4989500045776367\n",
      "0.49959999322891235\n",
      "0.4993000030517578\n",
      "0.49924999475479126\n",
      "0.49900001287460327\n",
      "0.4997499883174896\n",
      "0.499099999666214\n",
      "0.49935001134872437\n",
      "0.4997999966144562\n",
      "0.49924999475479126\n",
      "0.49959999322891235\n",
      "0.4996500015258789\n",
      "0.49985000491142273\n",
      "0.49915000796318054\n",
      "0.4997499883174896\n",
      "0.4996500015258789\n",
      "0.49950000643730164\n",
      "0.49959999322891235\n",
      "0.4995500147342682\n",
      "0.4997499883174896\n",
      "0.49904999136924744\n",
      "0.4997499883174896\n",
      "0.49959999322891235\n",
      "0.4994499981403351\n",
      "0.4993000030517578\n",
      "0.49935001134872437\n",
      "0.4995500147342682\n",
      "0.4993000030517578\n",
      "0.4997499883174896\n",
      "0.49959999322891235\n",
      "0.49959999322891235\n",
      "0.4994499981403351\n",
      "0.49939998984336853\n",
      "0.49959999322891235\n",
      "0.4997999966144562\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.49959999322891235\n",
      "0.49985000491142273\n",
      "0.49935001134872437\n",
      "0.4997999966144562\n",
      "0.4995500147342682\n",
      "0.49950000643730164\n",
      "0.4997499883174896\n",
      "0.4996500015258789\n",
      "0.4997999966144562\n",
      "0.49970000982284546\n",
      "0.49959999322891235\n",
      "0.4999000132083893\n",
      "0.4997999966144562\n",
      "0.4995500147342682\n",
      "0.4996500015258789\n",
      "0.4996500015258789\n",
      "0.4995500147342682\n",
      "0.4994499981403351\n",
      "0.49985000491142273\n",
      "0.49959999322891235\n",
      "0.4995500147342682\n",
      "0.49985000491142273\n",
      "0.49994999170303345\n",
      "0.49939998984336853\n",
      "0.4996500015258789\n",
      "0.4997499883174896\n",
      "0.4997499883174896\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.4997499883174896\n",
      "0.49985000491142273\n",
      "0.49970000982284546\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.4996500015258789\n",
      "0.49959999322891235\n",
      "0.4997999966144562\n",
      "0.4995500147342682\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.49985000491142273\n",
      "0.49985000491142273\n",
      "0.49939998984336853\n",
      "0.4997999966144562\n",
      "0.49970000982284546\n",
      "0.4997999966144562\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.4996500015258789\n",
      "0.49985000491142273\n",
      "0.4997999966144562\n",
      "0.49970000982284546\n",
      "0.49939998984336853\n",
      "0.4997999966144562\n",
      "0.4996500015258789\n",
      "0.49959999322891235\n",
      "0.49985000491142273\n",
      "0.49970000982284546\n",
      "0.4997499883174896\n",
      "0.4997499883174896\n",
      "0.49950000643730164\n",
      "0.4997999966144562\n",
      "0.4994499981403351\n",
      "0.49994999170303345\n",
      "0.49970000982284546\n",
      "0.49994999170303345\n",
      "0.49935001134872437\n",
      "0.4997499883174896\n",
      "0.4997499883174896\n",
      "0.49970000982284546\n",
      "0.49985000491142273\n",
      "0.4999000132083893\n",
      "0.49970000982284546\n",
      "0.49985000491142273\n",
      "0.49985000491142273\n",
      "0.4996500015258789\n",
      "0.49970000982284546\n",
      "0.49985000491142273\n",
      "0.49970000982284546\n",
      "0.49950000643730164\n",
      "0.4997999966144562\n",
      "0.4999000132083893\n",
      "0.4999000132083893\n",
      "0.4997999966144562\n",
      "0.4997499883174896\n",
      "0.4996500015258789\n",
      "0.4997999966144562\n",
      "0.4999000132083893\n",
      "0.49985000491142273\n",
      "0.4997499883174896\n",
      "0.4997499883174896\n",
      "0.4997999966144562\n",
      "0.49970000982284546\n",
      "0.4997499883174896\n",
      "0.49950000643730164\n",
      "0.49970000982284546\n",
      "0.49985000491142273\n",
      "0.4997999966144562\n",
      "0.4997999966144562\n",
      "0.4997999966144562\n",
      "0.4999000132083893\n",
      "0.4995500147342682\n",
      "0.4997999966144562\n",
      "0.4994499981403351\n",
      "0.4997499883174896\n",
      "0.4997999966144562\n",
      "0.49994999170303345\n",
      "0.5\n",
      "Training the generator\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "0.0003000000142492354\n",
      "0.0003000000142492354\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "0.0\n",
      "0.00019999999494757503\n",
      "0.0003000000142492354\n",
      "9.999999747378752e-05\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.0003000000142492354\n",
      "0.00019999999494757503\n",
      "9.999999747378752e-05\n",
      "0.0\n",
      "9.999999747378752e-05\n",
      "0.0005000000237487257\n",
      "0.0005000000237487257\n",
      "0.0003000000142492354\n",
      "0.0003000000142492354\n",
      "0.0003000000142492354\n",
      "0.0003000000142492354\n",
      "0.0003000000142492354\n",
      "0.00019999999494757503\n",
      "0.00019999999494757503\n",
      "0.00019999999494757503\n",
      "0.00019999999494757503\n",
      "0.0005000000237487257\n",
      "9.999999747378752e-05\n",
      "9.999999747378752e-05\n",
      "0.00039999998989515007\n",
      "9.999999747378752e-05\n",
      "0.0003000000142492354\n",
      "0.00039999998989515007\n",
      "0.00039999998989515007\n",
      "0.0003000000142492354\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.00039999998989515007\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.00019999999494757503\n",
      "0.00039999998989515007\n",
      "0.00039999998989515007\n",
      "0.0005000000237487257\n",
      "0.0005000000237487257\n",
      "0.0008999999845400453\n",
      "0.00019999999494757503\n",
      "0.000699999975040555\n",
      "0.0007999999797903001\n",
      "0.0007999999797903001\n",
      "0.0005000000237487257\n",
      "0.000699999975040555\n",
      "0.0007999999797903001\n",
      "0.0006000000284984708\n",
      "0.0003000000142492354\n",
      "0.0006000000284984708\n",
      "0.000699999975040555\n",
      "0.0008999999845400453\n",
      "0.0012000000569969416\n",
      "0.000699999975040555\n",
      "0.0008999999845400453\n",
      "0.0007999999797903001\n",
      "0.0006000000284984708\n",
      "0.0007999999797903001\n",
      "0.0007999999797903001\n",
      "0.0005000000237487257\n",
      "0.0010000000474974513\n",
      "0.0007999999797903001\n",
      "0.0005000000237487257\n",
      "0.000699999975040555\n",
      "0.0010999999940395355\n",
      "0.0008999999845400453\n",
      "0.0008999999845400453\n",
      "0.00139999995008111\n",
      "0.000699999975040555\n",
      "0.0003000000142492354\n",
      "0.000699999975040555\n",
      "0.000699999975040555\n",
      "0.0010999999940395355\n",
      "0.0010999999940395355\n",
      "0.0010999999940395355\n",
      "0.0012000000569969416\n",
      "0.001500000013038516\n",
      "0.00139999995008111\n",
      "0.000699999975040555\n",
      "0.0010000000474974513\n",
      "0.0010000000474974513\n",
      "0.0010999999940395355\n",
      "0.0013000000035390258\n",
      "0.0008999999845400453\n",
      "0.00139999995008111\n",
      "0.0010000000474974513\n",
      "0.00139999995008111\n",
      "0.0007999999797903001\n",
      "0.0010999999940395355\n",
      "0.00139999995008111\n",
      "0.001500000013038516\n",
      "0.001500000013038516\n",
      "0.000699999975040555\n",
      "0.001500000013038516\n",
      "0.0010000000474974513\n",
      "0.0015999999595806003\n",
      "0.0010999999940395355\n",
      "0.0008999999845400453\n",
      "0.0013000000035390258\n",
      "0.0010000000474974513\n",
      "0.0006000000284984708\n",
      "0.0013000000035390258\n",
      "0.0015999999595806003\n",
      "0.0015999999595806003\n",
      "0.001500000013038516\n",
      "0.0020000000949949026\n",
      "0.00139999995008111\n",
      "0.0017000000225380063\n",
      "0.001500000013038516\n",
      "0.001500000013038516\n",
      "0.0017000000225380063\n",
      "0.001500000013038516\n",
      "0.00139999995008111\n",
      "0.0017000000225380063\n",
      "0.0027000000700354576\n",
      "0.0017000000225380063\n",
      "0.001500000013038516\n",
      "0.002199999988079071\n",
      "0.0017000000225380063\n",
      "0.0019000000320374966\n",
      "0.0017999999690800905\n",
      "0.0017000000225380063\n",
      "0.001500000013038516\n",
      "0.002099999925121665\n",
      "0.0019000000320374966\n",
      "0.0019000000320374966\n",
      "0.0020000000949949026\n",
      "0.0027000000700354576\n",
      "0.0019000000320374966\n",
      "0.0020000000949949026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017999999690800905\n",
      "0.002400000113993883\n",
      "0.002300000051036477\n",
      "0.002099999925121665\n",
      "0.002199999988079071\n",
      "0.0017000000225380063\n",
      "0.002300000051036477\n",
      "0.0017999999690800905\n",
      "0.0026000000070780516\n",
      "0.002899999963119626\n",
      "0.0026000000070780516\n",
      "0.0024999999441206455\n",
      "0.003100000089034438\n",
      "0.004000000189989805\n",
      "0.003700000001117587\n",
      "0.003000000026077032\n",
      "0.003100000089034438\n",
      "0.0034000000450760126\n",
      "0.002899999963119626\n",
      "0.003100000089034438\n",
      "0.0035000001080334187\n",
      "0.003100000089034438\n",
      "0.0031999999191612005\n",
      "0.003800000064074993\n",
      "0.004000000189989805\n",
      "0.004900000058114529\n",
      "0.004399999976158142\n",
      "0.004800000227987766\n",
      "0.0038999998942017555\n",
      "0.005100000184029341\n",
      "0.00570000009611249\n",
      "0.00559999980032444\n",
      "0.004399999976158142\n",
      "0.004800000227987766\n",
      "0.006000000052154064\n",
      "0.006500000134110451\n",
      "0.006300000008195639\n",
      "0.007199999876320362\n",
      "0.007199999876320362\n",
      "0.006300000008195639\n",
      "0.006300000008195639\n",
      "0.006899999920278788\n",
      "0.005799999926239252\n",
      "0.006599999964237213\n",
      "0.006500000134110451\n",
      "0.005200000014156103\n",
      "0.005900000222027302\n",
      "0.00570000009611249\n",
      "0.005400000140070915\n",
      "0.006500000134110451\n",
      "0.00559999980032444\n",
      "0.007199999876320362\n",
      "0.007000000216066837\n",
      "0.008200000040233135\n",
      "0.007799999788403511\n",
      "0.007799999788403511\n",
      "0.0071000000461936\n",
      "0.00860000029206276\n",
      "0.007600000128149986\n",
      "0.007699999958276749\n",
      "0.008299999870359898\n",
      "0.008799999952316284\n",
      "0.010599999688565731\n",
      "0.008500000461935997\n",
      "0.009399999864399433\n",
      "0.008299999870359898\n",
      "0.007600000128149986\n",
      "0.008299999870359898\n",
      "0.008500000461935997\n",
      "0.00860000029206276\n",
      "0.009200000204145908\n",
      "0.009399999864399433\n",
      "0.00800000037997961\n",
      "0.009100000374019146\n",
      "0.010599999688565731\n",
      "0.010400000028312206\n",
      "0.010499999858438969\n",
      "0.010999999940395355\n",
      "0.010700000450015068\n",
      "0.010200000368058681\n",
      "0.011800000444054604\n",
      "0.010999999940395355\n",
      "0.012500000186264515\n",
      "0.012900000438094139\n",
      "0.012500000186264515\n",
      "0.01140000019222498\n",
      "0.011599999852478504\n",
      "0.01209999993443489\n",
      "0.011300000362098217\n",
      "0.01080000028014183\n",
      "0.012799999676644802\n",
      "0.014299999922513962\n",
      "0.015300000086426735\n",
      "0.0142000000923872\n",
      "0.013700000010430813\n",
      "0.016100000590085983\n",
      "0.015599999576807022\n",
      "0.01720000058412552\n",
      "0.019200000911951065\n",
      "0.018799999728798866\n",
      "0.0215000007301569\n",
      "0.021700000390410423\n",
      "0.022299999371170998\n",
      "0.019999999552965164\n",
      "0.021400000900030136\n",
      "0.021900000050663948\n",
      "0.025699999183416367\n",
      "0.023900000378489494\n",
      "0.02250000089406967\n",
      "0.025299999862909317\n",
      "0.027400000020861626\n",
      "0.02969999983906746\n",
      "0.03189999982714653\n",
      "0.03370000049471855\n",
      "0.031099999323487282\n",
      "0.0340999998152256\n",
      "0.03420000150799751\n",
      "0.034299999475479126\n",
      "0.03449999913573265\n",
      "0.03720000013709068\n",
      "0.03519999980926514\n",
      "0.0357000008225441\n",
      "0.03480000048875809\n",
      "0.03720000013709068\n",
      "0.03880000114440918\n",
      "0.03819999843835831\n",
      "0.03799999877810478\n",
      "0.040800001472234726\n",
      "0.04540000110864639\n",
      "0.04360000044107437\n",
      "0.04439999908208847\n",
      "0.048500001430511475\n",
      "0.049300000071525574\n",
      "0.050599999725818634\n",
      "0.05480000004172325\n",
      "0.054499998688697815\n",
      "0.05180000141263008\n",
      "0.05469999834895134\n",
      "0.05270000174641609\n",
      "0.05770000070333481\n",
      "0.05959999933838844\n",
      "0.06279999762773514\n",
      "0.06469999998807907\n",
      "0.0617000013589859\n",
      "0.06270000338554382\n",
      "0.06390000134706497\n",
      "0.06849999725818634\n",
      "0.07280000299215317\n",
      "0.07580000162124634\n",
      "0.07819999754428864\n",
      "0.0794999971985817\n",
      "0.07829999923706055\n",
      "0.07919999957084656\n",
      "0.07980000227689743\n",
      "0.08150000125169754\n",
      "0.08349999785423279\n",
      "0.09130000323057175\n",
      "0.09830000251531601\n",
      "0.09570000320672989\n",
      "0.0982000008225441\n",
      "0.10199999809265137\n",
      "0.10809999704360962\n",
      "0.10999999940395355\n",
      "0.10559999942779541\n",
      "0.10559999942779541\n",
      "0.10599999874830246\n",
      "0.10530000180006027\n",
      "0.11169999837875366\n",
      "0.11129999905824661\n",
      "0.11749999970197678\n",
      "0.12470000237226486\n",
      "0.1200999990105629\n",
      "0.11710000038146973\n",
      "0.12309999763965607\n",
      "0.1281999945640564\n",
      "0.1289999932050705\n",
      "0.13120000064373016\n",
      "0.13169999420642853\n",
      "0.1348000019788742\n",
      "0.133200004696846\n",
      "0.1347000002861023\n",
      "0.13349999487400055\n",
      "0.13459999859333038\n",
      "0.1315000057220459\n",
      "0.13840000331401825\n",
      "0.13699999451637268\n",
      "0.13289999961853027\n",
      "0.13779999315738678\n",
      "0.14309999346733093\n",
      "0.14069999754428864\n",
      "0.13779999315738678\n",
      "0.1445000022649765\n",
      "0.1429000049829483\n",
      "0.1518000066280365\n",
      "0.15119999647140503\n",
      "0.15080000460147858\n",
      "0.15569999814033508\n",
      "0.1590999960899353\n",
      "0.16040000319480896\n",
      "0.1582999974489212\n",
      "0.16519999504089355\n",
      "0.16169999539852142\n",
      "0.16580000519752502\n",
      "0.1606999933719635\n",
      "0.16380000114440918\n",
      "0.15649999678134918\n",
      "0.15780000388622284\n",
      "0.163100004196167\n",
      "0.164000004529953\n",
      "0.1662999987602234\n",
      "0.18150000274181366\n",
      "0.18400000035762787\n",
      "0.1882999986410141\n",
      "0.19259999692440033\n",
      "0.1923000067472458\n",
      "0.193900004029274\n",
      "0.19339999556541443\n",
      "0.18979999423027039\n",
      "0.19210000336170197\n",
      "0.19499999284744263\n",
      "0.20340000092983246\n",
      "0.2143000066280365\n",
      "0.21870000660419464\n",
      "0.21699999272823334\n",
      "0.20749999582767487\n",
      "0.2070000022649765\n",
      "0.21140000224113464\n",
      "0.21739999949932098\n",
      "0.22470000386238098\n",
      "0.227400004863739\n",
      "0.22579999268054962\n",
      "0.23180000483989716\n",
      "0.23649999499320984\n",
      "0.24040000140666962\n",
      "0.24500000476837158\n",
      "0.25369998812675476\n",
      "0.25609999895095825\n",
      "0.2542000114917755\n",
      "0.2596000134944916\n",
      "0.26660001277923584\n",
      "0.2653000056743622\n",
      "0.26589998602867126\n",
      "0.26510000228881836\n",
      "0.26510000228881836\n",
      "0.26840001344680786\n",
      "0.2775999903678894\n",
      "0.2809000015258789\n",
      "0.28519999980926514\n",
      "0.289900004863739\n",
      "0.29510000348091125\n",
      "0.299699991941452\n",
      "0.3005000054836273\n",
      "0.2973000109195709\n",
      "0.3149999976158142\n",
      "0.3133000135421753\n",
      "0.31349998712539673\n",
      "0.31679999828338623\n",
      "0.31439998745918274\n",
      "0.31859999895095825\n",
      "0.32429999113082886\n",
      "0.33570000529289246\n",
      "0.34549999237060547\n",
      "0.34869998693466187\n",
      "0.353300005197525\n",
      "0.3481000065803528\n",
      "0.35040000081062317\n",
      "0.35120001435279846\n",
      "0.357699990272522\n",
      "0.36880001425743103\n",
      "0.37070000171661377\n",
      "0.3772999942302704\n",
      "0.3765000104904175\n",
      "0.37389999628067017\n",
      "0.3856000006198883\n",
      "0.3903000056743622\n",
      "0.39100000262260437\n",
      "0.3986999988555908\n",
      "0.4025000035762787\n",
      "0.4032999873161316\n",
      "0.4066999852657318\n",
      "0.39910000562667847\n",
      "0.4016999900341034\n",
      "0.40619999170303345\n",
      "0.41269999742507935\n",
      "0.42320001125335693\n",
      "0.4203999936580658\n",
      "0.4244000017642975\n",
      "0.42820000648498535\n",
      "0.4325000047683716\n",
      "0.43709999322891235\n",
      "0.4422000050544739\n",
      "0.45080000162124634\n",
      "0.460099995136261\n",
      "0.45989999175071716\n",
      "0.45649999380111694\n",
      "0.4603999853134155\n",
      "0.4634000062942505\n",
      "0.46939998865127563\n",
      "0.4708000123500824\n",
      "0.4745999872684479\n",
      "0.47440001368522644\n",
      "0.4715000092983246\n",
      "0.46869999170303345\n",
      "0.4763000011444092\n",
      "0.47839999198913574\n",
      "0.4853000044822693\n",
      "0.4860999882221222\n",
      "0.4821000099182129\n",
      "0.48489999771118164\n",
      "0.48559999465942383\n",
      "0.48410001397132874\n",
      "0.4812999963760376\n",
      "0.48890000581741333\n",
      "0.49079999327659607\n",
      "0.5001999735832214\n",
      "0.5041999816894531\n",
      "0.5077000260353088\n",
      "0.5120000243186951\n",
      "0.5181999802589417\n",
      "0.5163000226020813\n",
      "0.5199999809265137\n",
      "0.5257999897003174\n",
      "0.5349000096321106\n",
      "0.5386999845504761\n",
      "0.5351999998092651\n",
      "0.5325000286102295\n",
      "0.5300999879837036\n",
      "0.5295000076293945\n",
      "0.5354999899864197\n",
      "0.5468999743461609\n",
      "0.5516999959945679\n",
      "0.5598000288009644\n",
      "0.5541999936103821\n",
      "0.5551000237464905\n",
      "0.5623000264167786\n",
      "0.5590999722480774\n",
      "0.5629000067710876\n",
      "0.5673999786376953\n",
      "0.5659999847412109\n",
      "0.5730999708175659\n",
      "0.582099974155426\n",
      "0.5848000049591064\n",
      "0.5845999717712402\n",
      "0.583299994468689\n",
      "0.5885000228881836\n",
      "0.5885999798774719\n",
      "0.5888000130653381\n",
      "0.5929999947547913\n",
      "0.5949000120162964\n",
      "0.6008999943733215\n",
      "0.5989000201225281\n",
      "0.59579998254776\n",
      "0.6011000275611877\n",
      "0.5974000096321106\n",
      "0.6062999963760376\n",
      "0.6067000031471252\n",
      "0.6108999848365784\n",
      "0.6123999953269958\n",
      "0.6215999722480774\n",
      "0.6290000081062317\n",
      "0.6288999915122986\n",
      "0.6345999836921692\n",
      "0.6388000249862671\n",
      "0.6417999863624573\n",
      "0.6485999822616577\n",
      "0.646399974822998\n",
      "0.6510999798774719\n",
      "0.6484000086784363\n",
      "0.6557999849319458\n",
      "0.6589999794960022\n",
      "0.6615999937057495\n",
      "0.6650000214576721\n",
      "0.6665999889373779\n",
      "0.670199990272522\n",
      "0.6664000153541565\n",
      "0.6658999919891357\n",
      "0.6674000024795532\n",
      "0.671500027179718\n",
      "0.6690999865531921\n",
      "0.6712999939918518\n",
      "0.6773999929428101\n",
      "0.6769000291824341\n",
      "0.6722999811172485\n",
      "0.6751000285148621\n",
      "0.6675000190734863\n",
      "0.6711999773979187\n",
      "0.6685000061988831\n",
      "0.6772000193595886\n",
      "0.6779999732971191\n",
      "0.6873000264167786\n",
      "0.6881999969482422\n",
      "0.6875\n",
      "0.6930999755859375\n",
      "0.6962000131607056\n",
      "0.6958000063896179\n",
      "0.7023000121116638\n",
      "0.7006999850273132\n",
      "0.698199987411499\n",
      "0.697700023651123\n",
      "0.7002999782562256\n",
      "0.7027000188827515\n",
      "0.7021999955177307\n",
      "0.701200008392334\n",
      "0.7088000178337097\n",
      "0.7092999815940857\n",
      "0.714900016784668\n",
      "0.7161999940872192\n",
      "0.7167999744415283\n",
      "0.7171000242233276\n",
      "0.7135999798774719\n",
      "0.7236999869346619\n",
      "0.722000002861023\n",
      "0.7218000292778015\n",
      "0.7228000164031982\n",
      "0.7299000024795532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7261999845504761\n",
      "0.7305999994277954\n",
      "0.7211999893188477\n",
      "0.7263000011444092\n",
      "0.7289999723434448\n",
      "0.7278000116348267\n",
      "0.7286999821662903\n",
      "0.7285000085830688\n",
      "0.7294999957084656\n",
      "0.732200026512146\n",
      "0.7287999987602234\n",
      "0.7261999845504761\n",
      "0.7282999753952026\n",
      "0.7289000153541565\n",
      "0.7303000092506409\n",
      "0.7325000166893005\n",
      "0.7286999821662903\n",
      "0.7311000227928162\n",
      "0.7336999773979187\n",
      "0.7311000227928162\n",
      "0.7389000058174133\n",
      "0.7361000180244446\n",
      "0.7426000237464905\n",
      "0.7425000071525574\n",
      "0.7408000230789185\n",
      "0.7422000169754028\n",
      "0.7426999807357788\n",
      "0.7493000030517578\n",
      "0.756600022315979\n",
      "0.7570000290870667\n",
      "0.7620000243186951\n",
      "0.7597000002861023\n",
      "0.7513999938964844\n",
      "0.7530999779701233\n",
      "0.7573000192642212\n",
      "0.758400022983551\n",
      "0.7603999972343445\n",
      "0.7642999887466431\n",
      "0.7666000127792358\n",
      "0.7664999961853027\n",
      "0.7692999839782715\n",
      "0.7677000164985657\n",
      "0.7723000049591064\n",
      "0.7670000195503235\n",
      "0.7742999792098999\n",
      "0.770799994468689\n",
      "0.774399995803833\n",
      "0.7698000073432922\n",
      "0.7684999704360962\n",
      "0.7698000073432922\n",
      "0.7709000110626221\n",
      "0.7695000171661377\n",
      "0.7706999778747559\n",
      "0.7705000042915344\n",
      "0.7681000232696533\n",
      "0.7685999870300293\n",
      "0.7731000185012817\n",
      "0.7760999798774719\n",
      "0.7778000235557556\n",
      "0.7849000096321106\n",
      "0.7795000076293945\n",
      "0.7861999869346619\n",
      "0.781499981880188\n",
      "0.7843999862670898\n",
      "0.7796000242233276\n",
      "0.7813000082969666\n",
      "0.7817999720573425\n",
      "0.7835000157356262\n",
      "0.7804999947547913\n",
      "0.7774999737739563\n",
      "0.7791000008583069\n",
      "0.779699981212616\n",
      "0.7814000248908997\n",
      "0.7870000004768372\n",
      "0.7878999710083008\n",
      "0.7914999723434448\n",
      "0.7906000018119812\n",
      "0.7915999889373779\n",
      "0.7962999939918518\n",
      "0.7947999835014343\n",
      "0.7972000241279602\n",
      "0.8061000108718872\n",
      "0.8022000193595886\n",
      "0.8087999820709229\n",
      "0.8075000047683716\n",
      "0.8051000237464905\n",
      "0.8061000108718872\n",
      "0.8076000213623047\n",
      "0.8087000250816345\n",
      "0.8101999759674072\n",
      "0.8066999912261963\n",
      "0.8069000244140625\n",
      "0.8051000237464905\n",
      "0.8064000010490417\n",
      "0.8083000183105469\n",
      "0.8077999949455261\n",
      "0.8115000128746033\n",
      "0.8086000084877014\n",
      "0.8055999875068665\n",
      "0.8116000294685364\n",
      "0.8134999871253967\n",
      "0.8137999773025513\n",
      "0.8169999718666077\n",
      "0.8118000030517578\n",
      "0.8180999755859375\n",
      "0.821399986743927\n",
      "0.8205999732017517\n",
      "0.8251000046730042\n",
      "0.8264999985694885\n",
      "0.829800009727478\n",
      "0.8306000232696533\n",
      "0.833899974822998\n",
      "0.8323000073432922\n",
      "0.8296999931335449\n",
      "0.8276000022888184\n",
      "0.8291000127792358\n",
      "0.829800009727478\n",
      "0.8342000246047974\n",
      "0.8328999876976013\n",
      "0.8323000073432922\n",
      "0.8320000171661377\n",
      "0.8285999894142151\n",
      "0.8295000195503235\n",
      "0.8353999853134155\n",
      "0.8339999914169312\n",
      "0.8349000215530396\n",
      "0.8342999815940857\n",
      "0.8402000069618225\n",
      "0.8321999907493591\n",
      "0.8359000086784363\n",
      "0.8393999934196472\n",
      "0.8395000100135803\n",
      "0.8431000113487244\n",
      "0.840499997138977\n",
      "0.8428000211715698\n",
      "0.845300018787384\n",
      "0.8428999781608582\n",
      "0.8417999744415283\n",
      "0.8500000238418579\n",
      "0.8471999764442444\n",
      "0.8432999849319458\n",
      "0.8438000082969666\n",
      "0.847599983215332\n",
      "0.8454999923706055\n",
      "0.8460000157356262\n",
      "0.8435999751091003\n",
      "0.8474000096321106\n",
      "0.8528000116348267\n",
      "0.8546000123023987\n",
      "0.8539000153541565\n",
      "0.8521000146865845\n",
      "0.8501999974250793\n",
      "0.8503999710083008\n",
      "0.8500000238418579\n",
      "0.8486999869346619\n",
      "0.8467000126838684\n",
      "0.8504999876022339\n",
      "0.8508999943733215\n",
      "0.8492000102996826\n",
      "0.8478999733924866\n",
      "0.8540999889373779\n",
      "0.8500000238418579\n",
      "0.8525999784469604\n",
      "0.8529000282287598\n",
      "0.8532999753952026\n",
      "0.8525000214576721\n",
      "0.8464000225067139\n",
      "0.8482999801635742\n",
      "0.8468000292778015\n",
      "0.8496999740600586\n",
      "0.8482000231742859\n",
      "0.8504999876022339\n",
      "0.8510000109672546\n",
      "0.8507999777793884\n",
      "0.8496999740600586\n",
      "0.8546000123023987\n",
      "0.852400004863739\n",
      "0.8547000288963318\n",
      "0.8560000061988831\n",
      "0.8517000079154968\n",
      "0.8567000031471252\n",
      "0.8579000234603882\n",
      "0.8580999970436096\n",
      "0.8572999835014343\n",
      "0.857699990272522\n",
      "0.8582000136375427\n",
      "0.8589000105857849\n",
      "0.855400025844574\n",
      "0.8564000129699707\n",
      "0.8621000051498413\n",
      "0.8621000051498413\n",
      "0.8641999959945679\n",
      "0.8666999936103821\n",
      "0.8669000267982483\n",
      "0.8673999905586243\n",
      "0.8687000274658203\n",
      "0.8704000115394592\n",
      "0.8718000054359436\n",
      "0.8718000054359436\n",
      "0.8715000152587891\n",
      "0.8723999857902527\n",
      "0.8704000115394592\n",
      "0.871399998664856\n",
      "0.8708000183105469\n",
      "0.8737999796867371\n",
      "0.8701000213623047\n",
      "0.8700000047683716\n",
      "0.8694000244140625\n",
      "0.8676999807357788\n",
      "0.8689000010490417\n",
      "0.866599977016449\n",
      "0.869700014591217\n",
      "0.866100013256073\n",
      "0.8634999990463257\n",
      "0.8654000163078308\n",
      "0.8666999936103821\n",
      "0.8672999739646912\n",
      "0.8677999973297119\n",
      "0.8644000291824341\n",
      "0.8648999929428101\n",
      "0.8680999875068665\n",
      "0.8675000071525574\n",
      "0.8684999942779541\n",
      "0.8712999820709229\n",
      "0.8694000244140625\n",
      "0.8675000071525574\n",
      "0.8673999905586243\n",
      "0.8694000244140625\n",
      "0.8691999912261963\n",
      "0.8682000041007996\n",
      "0.8690000176429749\n",
      "0.8712999820709229\n",
      "0.8748000264167786\n",
      "0.8726000189781189\n",
      "0.8691999912261963\n",
      "0.8741000294685364\n",
      "0.8736000061035156\n",
      "0.873199999332428\n",
      "0.8708999752998352\n",
      "0.869700014591217\n",
      "0.8687999844551086\n",
      "0.8741000294685364\n",
      "0.8761000037193298\n",
      "0.8751999735832214\n",
      "0.8719000220298767\n",
      "0.8763999938964844\n",
      "0.8763999938964844\n",
      "0.8776999711990356\n",
      "0.8729000091552734\n",
      "0.8712999820709229\n",
      "0.8708000183105469\n",
      "0.8697999715805054\n",
      "0.8737999796867371\n",
      "0.875\n",
      "0.8730000257492065\n",
      "0.8769999742507935\n",
      "0.8761000037193298\n",
      "0.8765000104904175\n",
      "0.8754000067710876\n",
      "0.8752999901771545\n",
      "0.8722000122070312\n",
      "0.8772000074386597\n",
      "0.8716999888420105\n",
      "0.878000020980835\n",
      "0.8727999925613403\n",
      "0.8734999895095825\n",
      "0.8733999729156494\n",
      "0.8759999871253967\n",
      "0.878600001335144\n",
      "0.8769999742507935\n",
      "0.8776999711990356\n",
      "0.8766000270843506\n",
      "0.8744999766349792\n",
      "0.8787999749183655\n",
      "0.8758999705314636\n",
      "0.8766000270843506\n",
      "0.8790000081062317\n",
      "0.8799999952316284\n",
      "0.8752999901771545\n",
      "0.8766999840736389\n",
      "0.8794999718666077\n",
      "0.8792999982833862\n",
      "0.8784000277519226\n",
      "0.8823000192642212\n",
      "0.883899986743927\n",
      "0.8819000124931335\n",
      "0.8823999762535095\n",
      "0.8727999925613403\n",
      "0.873199999332428\n",
      "0.8762000203132629\n",
      "0.8779000043869019\n",
      "0.8790000081062317\n",
      "0.8809999823570251\n",
      "0.8754000067710876\n",
      "0.8781999945640564\n",
      "0.881600022315979\n",
      "0.8816999793052673\n",
      "0.8776999711990356\n",
      "0.8774999976158142\n",
      "0.8810999989509583\n",
      "0.8784000277519226\n",
      "0.8784000277519226\n",
      "0.8773999810218811\n",
      "0.8725000023841858\n",
      "0.8773000240325928\n",
      "0.8716999888420105\n",
      "0.8730000257492065\n",
      "0.8693000078201294\n",
      "0.8708000183105469\n",
      "0.8715000152587891\n",
      "0.8733000159263611\n",
      "0.8751999735832214\n",
      "0.8708999752998352\n",
      "0.8715000152587891\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(stft_white_dataset_real.shape, g, d)\n",
    "disc_acc = []\n",
    "gen_acc = []\n",
    "\n",
    "for step in range(10):\n",
    "    g_accuracy = 0\n",
    "    d_accuracy = 0\n",
    "    print(\"Step\", step)\n",
    "    if d_accuracy < 1:\n",
    "        i, o = get_generator_outputs(stft_white_dataset_real, train_size, gan.g, nperseg, stft_clean_dataset_real)\n",
    "    gan.block_generator()\n",
    "    print(\"Training the discriminator\")\n",
    "    while d_accuracy < 0.5:\n",
    "        d_accuracy = train_on_batch(gan.d, i, o, verbose=False)\n",
    "        print(d_accuracy)\n",
    "        disc_acc.append(d_accuracy)\n",
    "        gen_acc.append(0)\n",
    "    gan.block_discriminator()\n",
    "    print(\"Training the generator\")\n",
    "    while  (g_accuracy <= 0.95 or g_accuracy <= d_accuracy) and g_accuracy < 1:\n",
    "        g_accuracy = train_on_batch(gan.combined_network, stft_white_dataset_real[:train_size,], np.ones(train_size), verbose=False)\n",
    "        print(g_accuracy)\n",
    "        gen_acc.append(g_accuracy)\n",
    "        disc_acc.append(0)\n",
    "plt.plot(disc_acc)\n",
    "plt.plot(gen_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for i in range(10):\n",
    "    x = np.reshape(white_dataset[i, :].T, (1, white_dataset.shape[1]))\n",
    "    y = np.reshape(stft_white_dataset_real[i, :, :], (-1, stft_white_dataset_real.shape[1], stft_white_dataset_real.shape[2]))\n",
    "    t, y1 = istft(np.reshape(gan.g.predict(y).T, (513, 3))+np.imag(stft_white_dataset_imag[i]).T)\n",
    "    x2 = np.reshape(x.T, (clean_dataset.shape[1],))\n",
    "    y2 = np.reshape(y1.T, (clean_dataset.shape[1],))\n",
    "    inputs.append(x2)\n",
    "    outputs.append(y2)\n",
    "\n",
    "a = np.concatenate(inputs)\n",
    "b = np.concatenate(outputs)\n",
    "\n",
    "c, t, axx = stft(a, fs=samplerate, nperseg=nperseg)\n",
    "c, t, bxx = stft(b, fs=samplerate, nperseg=nperseg)\n",
    "displaySpectrogram(axx)\n",
    "plt.show()\n",
    "displaySpectrogram(bxx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(b, rate=samplerate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
