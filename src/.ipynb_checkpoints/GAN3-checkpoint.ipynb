{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutionnal Generative Adversarial Networks\n",
    "## Initialisation and dataset preparation\n",
    "\n",
    "First, let us import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us include the dataset.\n",
    "\n",
    "The dataset is made of two files: `clean/p1.wav`and `white/p1.wav` which are converted into arrays of `int32` and then split into segments of `samples_length`.\n",
    "\n",
    "The goal of the CGAN here is to predict the clean sample, when fed with the white one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"int32\")\n",
    "white = np.array(white, dtype=\"int32\")\n",
    "\n",
    "clean_dataset = []\n",
    "white_dataset = []\n",
    "\n",
    "samples_length = nperseg//2\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_dataset.append(clean[i:i+samples_length])\n",
    "    white_dataset.append(white[i:i+samples_length])\n",
    "clean_dataset = np.array(clean_dataset)\n",
    "white_dataset = np.array(white_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21318, 3, 257) (21318, 3, 257) (21318, 3, 257) (21318, 3, 257)\n"
     ]
    }
   ],
   "source": [
    "stft_clean_dataset_real = []\n",
    "stft_clean_dataset_imag = []\n",
    "stft_white_dataset_real = []\n",
    "stft_white_dataset_imag = []\n",
    "\n",
    "for i in clean_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_clean_dataset_real.append(np.real(inp).T)\n",
    "    stft_clean_dataset_imag.append(np.imag(inp).T)\n",
    "    \n",
    "for i in white_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_white_dataset_real.append(np.real(inp).T)\n",
    "    stft_white_dataset_imag.append(np.imag(inp).T)\n",
    "\n",
    "max_clean = 1.#np.max(np.abs(np.array(stft_clean_dataset_real)))\n",
    "max_white = 1.#np.max(np.abs(np.array(stft_white_dataset_real)))\n",
    "\n",
    "stft_clean_dataset_real = np.array(stft_clean_dataset_real)/max_clean\n",
    "stft_clean_dataset_imag = np.array(stft_clean_dataset_imag)\n",
    "stft_white_dataset_real = np.array(stft_white_dataset_real)/max_white\n",
    "stft_white_dataset_imag = np.array(stft_white_dataset_imag)\n",
    "print(stft_clean_dataset_real.shape, stft_clean_dataset_imag.shape, stft_white_dataset_real.shape, stft_white_dataset_imag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (stft_clean_dataset_real.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 257)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8502.226041951562 8092.186286362657\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(np.array(stft_clean_dataset_real))), np.max(np.abs(np.array(stft_white_dataset_real))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_output(stft_white_dataset_real, gan, p):\n",
    "    outputs = []\n",
    "    for i in range(10):\n",
    "        y = np.reshape(stft_white_dataset_real[i, :, :], (-1, stft_white_dataset_real.shape[1], stft_white_dataset_real.shape[2]))\n",
    "        t, y1 = istft(np.reshape((gan.g.predict(y)*max_clean).T, data_shape[::-1])+np.imag(stft_white_dataset_imag[i]).T)\n",
    "        y2 = np.reshape(y1.T, (clean_dataset.shape[1],))\n",
    "        outputs.append(y2)\n",
    "    b = np.concatenate(outputs)\n",
    "    c, t, bxx = stft(b, fs=samplerate, nperseg=nperseg)\n",
    "    displaySpectrogram(bxx)\n",
    "    plt.savefig(str(p)+\".png\", format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN Model\n",
    "The main idea of a GAN model is to create two networks who play an adversarial game:\n",
    "- A Generator, whose goal is to produce the most realistic samples possible to fool the Discriminator\n",
    "- A Discriminator, whose goal is to correctly guess if its input is a real sample from the clean dataset or an output created by the Generator\n",
    "\n",
    "A first model is saved in `'save2/gan_without_add'`. It does not have any add layer. It has been train on 3104 steps on 5000 samples of size 2048, visualizable in the folder `save2` gif.\n",
    "\n",
    "A first model is saved in `'save2/gan_with_add'`. It does have an add layer. It has been train on 2475 steps on 10000 samples of size 1024, visualizable in the folder `save3` gif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator here uses a layer to process the Short-Time Fourier Transform (https://en.wikipedia.org/wiki/Short-time_Fourier_transform) before reducing the problem dimension to one single boolean prediction layer.\n",
    "\n",
    "Interestingly, adding a Dropout layer on the input seems to prevent the generator to adapt itself to the little flaws of detection (which then only produces noise unrecognized by the discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    #x3 = tf.keras.layers.Dense(512, activation=\"tanh\")(x)\n",
    "    x4 = tf.keras.layers.Dense(256, activation=\"tanh\")(x)\n",
    "    x5 = tf.keras.layers.Dense(128, activation=\"tanh\")(x4)\n",
    "    x6 = tf.keras.layers.Dense(1, activation=\"tanh\")(x5)\n",
    "    x7 = tf.keras.layers.Flatten()(x6)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x7)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer= 'adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "The generator itself is a Convolutionnal Autoencoder.\n",
    "\n",
    "Its input size and output size are both the size of the stft array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sizes):\n",
    "    inputs = tf.keras.Input(shape=(sizes[1], sizes[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    x1 = tf.keras.layers.Dense(10, activation='tanh')(x)\n",
    "    x4 = tf.keras.layers.Dense(sizes[2], activation='tanh')(x1)\n",
    "    x5 = tf.keras.layers.Add()([inputs, x4])\n",
    "    outputs = tf.keras.layers.Dense(sizes[2], activation='linear')(x4)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"autoencoder\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_generator(g, inputs, outputs, size=100):\n",
    "    res = 0\n",
    "    s = min(size, inputs.shape[0])\n",
    "    for i in range(s):\n",
    "        error = (g.predict(np.reshape(inputs[i], (-1, inputs[i].shape[0], inputs[i].shape[1])))-outputs[i])**2\n",
    "        res += np.sum(error)\n",
    "    return res/(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_outputs(white, train_size, g, nperseg, clean):\n",
    "    steps = train_size//20\n",
    "    rng = np.random.default_rng()\n",
    "    g_outputs = []\n",
    "    batch = rng.choice(white, train_size)\n",
    "    for i in range(train_size):\n",
    "        if i%steps == 0:\n",
    "            print(\"=\", end='')\n",
    "        t = np.reshape(white[i, :, :], (-1, white.shape[1], white.shape[2]))\n",
    "        m = g.predict(t)\n",
    "        g_outputs.append(m)\n",
    "    print()\n",
    "    g_outputs = np.reshape(np.array(g_outputs), (train_size,  white.shape[1], white.shape[2]))\n",
    "    input_data = np.concatenate((g_outputs, clean[:train_size,]))\n",
    "    output_data = np.concatenate((np.zeros((train_size,)), np.ones((train_size,))))\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, size, g, d):\n",
    "        self.g = g\n",
    "        self.d = d\n",
    "        self.size = size\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.z = self.g.inputs\n",
    "        self.image = self.g(self.z)\n",
    "        self.valid = self.d(self.image)\n",
    "        self.combined_network = tf.keras.Model(self.z, self.valid)\n",
    "        self.compile()\n",
    "        \n",
    "    def block_discriminator(self):\n",
    "        self.d.trainable = False\n",
    "        self.g.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def block_generator(self):\n",
    "        self.g.trainable = False\n",
    "        self.d.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def compile(self):\n",
    "        self.combined_network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 3, 257)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 257)            0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3, 10)             2580      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3, 257)            2827      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3, 257)            66306     \n",
      "=================================================================\n",
      "Total params: 71,713\n",
      "Trainable params: 71,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 3, 257)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 257)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3, 256)            66048     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3, 1)              129       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 99,077\n",
      "Trainable params: 99,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator(stft_white_dataset_real.shape)\n",
    "d = discriminator(stft_white_dataset_real.shape)\n",
    "gan = GAN(stft_white_dataset_real.shape, g, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(d, i, o, validation_split=0, batch_size=16, verbose=True):  \n",
    "    history = d.fit(i, o, batch_size=batch_size, validation_split=validation_split, verbose=verbose)\n",
    "    return np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_train_size = 1000#stft_white_dataset_real.shape[0]\n",
    "generator_train_size = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "d_accuracy = 0\n",
    "while d_accuracy < 0.5:\n",
    "    d_accuracy = train_on_batch(gan.d, np.concatenate((stft_white_dataset_real[:train_size], stft_clean_dataset_real[:train_size])), np.concatenate((np.zeros(train_size), np.ones(train_size))), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "====================\n",
      "Training the discriminator\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2277 - accuracy: 0.6204\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.7940\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.8650\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9685\n",
      "Training the generator\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.0374 - accuracy: 0.9626\n",
      "18782361.250520658\n",
      "Step 1\n",
      "====================\n",
      "Training the discriminator\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.4940\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.5000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.4990\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.4990\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4985\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4990\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4995\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4790\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.5510\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9900\n",
      "Training the generator\n",
      "2048/5000 [===========>..................] - ETA: 5s - loss: 0.1360 - accuracy: 0.8918"
     ]
    }
   ],
   "source": [
    "disc_acc = []\n",
    "gen_loss = [0]\n",
    "gan_acc = []\n",
    "for e in range(50):\n",
    "    g_accuracy = 0\n",
    "    d_accuracy = 0\n",
    "    print(\"Step\", e)\n",
    "    if d_accuracy < 1:\n",
    "        i, o = get_generator_outputs(stft_white_dataset_real, discriminator_train_size, gan.g, nperseg, stft_clean_dataset_real)\n",
    "    gan.block_generator()\n",
    "    print(\"Training the discriminator\")\n",
    "    s = 0\n",
    "    err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "    while d_accuracy < 0.9:\n",
    "        d_accuracy = train_on_batch(gan.d, i, o, verbose=True)\n",
    "        disc_acc.append(d_accuracy)\n",
    "        gan_acc.append(0)\n",
    "        s+=1\n",
    "        gen_loss.append(err)\n",
    "    gan.block_discriminator()\n",
    "    print(\"Training the generator\")\n",
    "    s = 0\n",
    "    while g_accuracy < 0.95:\n",
    "        g_accuracy = train_on_batch(gan.combined_network, stft_white_dataset_real[:generator_train_size], np.ones(generator_train_size), batch_size=4, verbose=True)\n",
    "        gan_acc.append(g_accuracy)\n",
    "        disc_acc.append(0)\n",
    "        err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "        print(err)\n",
    "        gen_loss.append(err)\n",
    "        view_output(stft_white_dataset_real, gan, p)\n",
    "        s+=1\n",
    "        p+=1\n",
    "    #print(evaluate_generator(gan.g, white_dataset, clean_dataset))\n",
    "plt.plot(disc_acc)\n",
    "plt.plot(gan_acc)\n",
    "plt.show()\n",
    "plt.plot(gen_loss[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.combined_network.save('save2/gan_with_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(b, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
