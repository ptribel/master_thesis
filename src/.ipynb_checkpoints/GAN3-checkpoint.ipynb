{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutionnal Generative Adversarial Networks\n",
    "## Initialisation and dataset preparation\n",
    "\n",
    "First, let us import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us include the dataset.\n",
    "\n",
    "The dataset is made of two files: `clean/p1.wav`and `white/p1.wav` which are converted into arrays of `int32` and then split into segments of `samples_length`.\n",
    "\n",
    "The goal of the CGAN here is to predict the clean sample, when fed with the white one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"int32\")\n",
    "white = np.array(white, dtype=\"int32\")\n",
    "\n",
    "clean_dataset = []\n",
    "white_dataset = []\n",
    "\n",
    "samples_length = nperseg\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_dataset.append(clean[i:i+samples_length])\n",
    "    white_dataset.append(white[i:i+samples_length])\n",
    "clean_dataset = np.array(clean_dataset)\n",
    "white_dataset = np.array(white_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10659, 3, 513) (10659, 3, 513) (10659, 3, 513) (10659, 3, 513)\n"
     ]
    }
   ],
   "source": [
    "stft_clean_dataset_real = []\n",
    "stft_clean_dataset_imag = []\n",
    "stft_white_dataset_real = []\n",
    "stft_white_dataset_imag = []\n",
    "\n",
    "for i in clean_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_clean_dataset_real.append(np.real(inp).T)\n",
    "    stft_clean_dataset_imag.append(np.imag(inp).T)\n",
    "    \n",
    "for i in white_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_white_dataset_real.append(np.real(inp).T)\n",
    "    stft_white_dataset_imag.append(np.imag(inp).T)\n",
    "\n",
    "stft_clean_dataset_real = np.array(stft_clean_dataset_real)\n",
    "stft_clean_dataset_imag = np.array(stft_clean_dataset_imag)\n",
    "stft_white_dataset_real = np.array(stft_white_dataset_real)\n",
    "stft_white_dataset_imag = np.array(stft_white_dataset_imag)\n",
    "print(stft_clean_dataset_real.shape, stft_clean_dataset_imag.shape, stft_white_dataset_real.shape, stft_white_dataset_imag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = stft_clean_dataset_real.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_output(stft_white_dataset_real, gan, p):\n",
    "    outputs = []\n",
    "    for i in range(10):\n",
    "        y = np.reshape(stft_white_dataset_real[i, :, :], (-1, stft_white_dataset_real.shape[1], stft_white_dataset_real.shape[2]))\n",
    "        t, y1 = istft(np.reshape(gan.g.predict(y).T, data_shape[::-1])+np.imag(stft_white_dataset_imag[i]).T)\n",
    "        y2 = np.reshape(y1.T, (clean_dataset.shape[1],))\n",
    "        outputs.append(y2)\n",
    "    b = np.concatenate(outputs)\n",
    "    c, t, bxx = stft(b, fs=samplerate, nperseg=nperseg)\n",
    "    displaySpectrogram(bxx)\n",
    "    plt.savefig(str(p)+\".png\", format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN Model\n",
    "The main idea of a GAN model is to create two networks who play an adversarial game:\n",
    "- A Generator, whose goal is to produce the most realistic samples possible to fool the Discriminator\n",
    "- A Discriminator, whose goal is to correctly guess if its input is a real sample from the clean dataset or an output created by the Generator\n",
    "\n",
    "A first model is saved in `'save2/gan_without_add'`. It does not have any add layer. It has been train on 3104 steps on 5000 samples of size 2048, visualizable in the folder `save2` gif.\n",
    "\n",
    "A first model is saved in `'save2/gan_with_add'`. It does have an add layer. It has been train on 2475 steps on 10000 samples of size 1024, visualizable in the folder `save3` gif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator here uses a layer to process the Short-Time Fourier Transform (https://en.wikipedia.org/wiki/Short-time_Fourier_transform) before reducing the problem dimension to one single boolean prediction layer.\n",
    "\n",
    "Interestingly, adding a Dropout layer on the input seems to prevent the generator to adapt itself to the little flaws of detection (which then only produces noise unrecognized by the discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    #x3 = tf.keras.layers.Dense(512, activation=\"tanh\")(x)\n",
    "    x4 = tf.keras.layers.Dense(256, activation=\"tanh\")(x)\n",
    "    x5 = tf.keras.layers.Dense(128, activation=\"tanh\")(x4)\n",
    "    x6 = tf.keras.layers.Dense(1, activation=\"tanh\")(x5)\n",
    "    x7 = tf.keras.layers.Flatten()(x6)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x7)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer= 'adam', loss='bce', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "The generator itself is a Convolutionnal Autoencoder.\n",
    "\n",
    "Its input size and output size are both the size of the stft array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sizes):\n",
    "    inputs = tf.keras.Input(shape=(sizes[1], sizes[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    x1 = tf.keras.layers.Dense(10, activation='tanh')(x)\n",
    "    x4 = tf.keras.layers.Dense(sizes[2], activation='tanh')(x1)\n",
    "    x5 = tf.keras.layers.Add()([inputs, x4])\n",
    "    outputs = tf.keras.layers.Dense(sizes[2], activation='linear')(x5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"autoencoder\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_generator(g, inputs, outputs, size=100):\n",
    "    res = 0\n",
    "    s = min(size, inputs.shape[0])\n",
    "    for i in range(s):\n",
    "        error = (g.predict(np.reshape(inputs[i], (-1, inputs[i].shape[0], inputs[i].shape[1])))-outputs[i])**2\n",
    "        res += np.sum(error)\n",
    "    return res/(s*100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_outputs(white, train_size, g, nperseg, clean):\n",
    "    steps = train_size//20\n",
    "    rng = np.random.default_rng()\n",
    "    g_outputs = []\n",
    "    batch = rng.choice(white, train_size)\n",
    "    for i in range(train_size):\n",
    "        if i%steps == 0:\n",
    "            print(\"=\", end='')\n",
    "        t = np.reshape(white[i, :, :], (-1, white.shape[1], white.shape[2]))\n",
    "        m = g.predict(t)\n",
    "        g_outputs.append(m)\n",
    "    print()\n",
    "    g_outputs = np.reshape(np.array(g_outputs), (train_size,  white.shape[1], white.shape[2]))\n",
    "    input_data = np.concatenate((g_outputs, clean[:train_size,]))\n",
    "    output_data = np.concatenate((np.zeros((train_size,)), np.ones((train_size,))))\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, size, g, d):\n",
    "        self.g = g\n",
    "        self.d = d\n",
    "        self.size = size\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.z = self.g.inputs\n",
    "        self.image = self.g(self.z)\n",
    "        self.valid = self.d(self.image)\n",
    "        self.combined_network = tf.keras.Model(self.z, self.valid)\n",
    "        self.compile()\n",
    "        \n",
    "    def block_discriminator(self):\n",
    "        self.d.trainable = False\n",
    "        self.g.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def block_generator(self):\n",
    "        self.g.trainable = False\n",
    "        self.d.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def compile(self):\n",
    "        self.combined_network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 3, 513)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 3, 513)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 3, 10)        5140        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3, 513)       5643        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 3, 513)       0           input_3[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3, 513)       263682      add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 274,465\n",
      "Trainable params: 274,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 3, 513)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 513)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3, 256)            131584    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3, 1)              129       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 164,613\n",
      "Trainable params: 164,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator(stft_white_dataset_real.shape)\n",
    "d = discriminator(stft_white_dataset_real.shape)\n",
    "gan = GAN(stft_white_dataset_real.shape, g, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(d, i, o, validation_split=0, batch_size=16, verbose=True):  \n",
    "    history = d.fit(i, o, batch_size=batch_size, validation_split=validation_split, verbose=verbose)\n",
    "    return np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 10000#stft_white_dataset_real.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "d_accuracy = 0\n",
    "while d_accuracy < 0.5:\n",
    "    d_accuracy = train_on_batch(gan.d, np.concatenate((stft_white_dataset_real[:train_size], stft_clean_dataset_real[:train_size])), np.concatenate((np.zeros(train_size), np.ones(train_size))), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.7148 - accuracy: 0.6012\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3650 - accuracy: 0.8850\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.1727 - accuracy: 0.9786\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.6209 - accuracy: 0.2863\n",
      "1.060109479021215\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0557 - accuracy: 0.9345\n",
      "1.3811104459241965\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0365 - accuracy: 0.9630\n",
      "1.7518710982277312\n",
      "Step 1\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.9757\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9259 - accuracy: 0.0317\n",
      "2.7240046877234763\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2305 - accuracy: 0.6907\n",
      "3.1978201170351164\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0957 - accuracy: 0.8724\n",
      "3.619551447119753\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0581 - accuracy: 0.9241\n",
      "4.01606449255332\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0427 - accuracy: 0.9492\n",
      "4.5253545053692665\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 0.0359 - accuracy: 0.9555\n",
      "5.094113480090984\n",
      "Step 2\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0503 - accuracy: 0.9860\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9849 - accuracy: 0.0017\n",
      "5.889081173025881\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8568 - accuracy: 0.0654\n",
      "6.773890196580079\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.6026 - accuracy: 0.2815\n",
      "7.479860330565338\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.4007 - accuracy: 0.5005\n",
      "8.039940550768726\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.2652 - accuracy: 0.6610\n",
      "8.586041973729905\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1912 - accuracy: 0.7518\n",
      "9.119746617082267\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1356 - accuracy: 0.8199\n",
      "9.611756307155453\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0949 - accuracy: 0.8754\n",
      "10.017121529361988\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0767 - accuracy: 0.9010\n",
      "10.461254957344904\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0633 - accuracy: 0.9151\n",
      "10.938333099194072\n",
      "Step 3\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0508 - accuracy: 0.9846\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9893 - accuracy: 0.0012\n",
      "11.48618331291025\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9780 - accuracy: 0.0029\n",
      "11.99498924985294\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9391 - accuracy: 0.0189\n",
      "12.67628478044879\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.8519 - accuracy: 0.0694\n",
      "13.393998776940208\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.6944 - accuracy: 0.1929\n",
      "14.092539897075662\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.5089 - accuracy: 0.3698\n",
      "14.668267921726544\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.3730 - accuracy: 0.5221\n",
      "15.13871201658769\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.2657 - accuracy: 0.6550\n",
      "15.739033966575525\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.1980 - accuracy: 0.7351\n",
      "16.315483617578487\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.1616 - accuracy: 0.7855\n",
      "16.82783719086855\n",
      "Step 4\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0345 - accuracy: 0.9905\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9854 - accuracy: 0.0018\n",
      "17.348246703787602\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9722 - accuracy: 0.0060\n",
      "17.818024863060206\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9390 - accuracy: 0.0203\n",
      "18.287579873380512\n",
      "2500/2500 [==============================] - 12s 5ms/step - loss: 0.8712 - accuracy: 0.0602\n",
      "18.938281348072024\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.7544 - accuracy: 0.1547\n",
      "19.555116718906792\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.6291 - accuracy: 0.2678\n",
      "20.020170065481423\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4985 - accuracy: 0.3995\n",
      "20.560087917959155\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.4032 - accuracy: 0.5076\n",
      "21.023367233526127\n",
      "2500/2500 [==============================] - 11s 4ms/step - loss: 0.3175 - accuracy: 0.6062\n",
      "21.464381469684653\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.2703 - accuracy: 0.6640\n",
      "22.027645927641533\n",
      "Step 5\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0335 - accuracy: 0.9891\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.9908 - accuracy: 0.0017\n",
      "22.459840763636553\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.9860 - accuracy: 0.0028\n",
      "22.97131428894312\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9810 - accuracy: 0.0040\n",
      "23.518328110396688\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9717 - accuracy: 0.0087\n",
      "23.939804884688463\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9619 - accuracy: 0.0124\n",
      "24.47164200539145\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9480 - accuracy: 0.0178\n",
      "24.875951149463642\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9235 - accuracy: 0.0331\n",
      "25.216007936292726\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.8838 - accuracy: 0.0584\n",
      "25.748873934429408\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.8440 - accuracy: 0.0828\n",
      "26.26620031866871\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.7888 - accuracy: 0.1318\n",
      "26.939424966261864\n",
      "Step 6\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0149 - accuracy: 0.9963\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9871 - accuracy: 0.0025\n",
      "27.588263154931102\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.9769 - accuracy: 0.0063\n",
      "28.000115377617206\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9667 - accuracy: 0.0099\n",
      "28.367112407928687\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9492 - accuracy: 0.0187\n",
      "28.857190092229345\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9192 - accuracy: 0.0337\n",
      "29.383320546610705\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.8656 - accuracy: 0.0705\n",
      "29.994999139147662\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.7979 - accuracy: 0.1209\n",
      "30.557565867632245\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.7265 - accuracy: 0.1801\n",
      "31.3203770588573\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.6454 - accuracy: 0.2602\n",
      "31.86853857877038\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5543 - accuracy: 0.3532\n",
      "32.38570977153213\n",
      "Step 7\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0197 - accuracy: 0.9939\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9956 - accuracy: 6.2526e-04\n",
      "32.87446761881306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9944 - accuracy: 8.0000e-04\n",
      "33.15604679248949\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9903 - accuracy: 0.0022\n",
      "33.65558811869742\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9869 - accuracy: 0.0035\n",
      "34.04616747222585\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9827 - accuracy: 0.0042\n",
      "34.45081182375728\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9775 - accuracy: 0.0074\n",
      "34.961374643233206\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9687 - accuracy: 0.0117\n",
      "35.50351121582237\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9527 - accuracy: 0.0189\n",
      "36.23641978182287\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9339 - accuracy: 0.0303\n",
      "36.788111856294094\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9058 - accuracy: 0.0508\n",
      "37.24744564744435\n",
      "Step 8\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0141 - accuracy: 0.9954\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9927 - accuracy: 0.0013\n",
      "37.83589963643481\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9905 - accuracy: 0.0025\n",
      "38.2800317868814\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9884 - accuracy: 0.0026\n",
      "38.753039089214546\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9864 - accuracy: 0.0033\n",
      "39.164933852420816\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9832 - accuracy: 0.0052\n",
      "39.49476283350529\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9764 - accuracy: 0.0080\n",
      "39.89803236141352\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9653 - accuracy: 0.0136\n",
      "40.456610091312776\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9536 - accuracy: 0.0190\n",
      "40.82243066279771\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9285 - accuracy: 0.0362\n",
      "41.18504641365501\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9016 - accuracy: 0.0576\n",
      "41.616834289176154\n",
      "Step 9\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9951 - accuracy: 0.0014\n",
      "41.83386395754974\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9932 - accuracy: 0.0011\n",
      "42.21619550556201\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9923 - accuracy: 0.0014\n",
      "42.536045233476436\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9917 - accuracy: 0.0026\n",
      "42.68454753246688\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9909 - accuracy: 0.0022\n",
      "43.0387510059364\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9891 - accuracy: 0.0028\n",
      "43.31681496284504\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9856 - accuracy: 0.0045\n",
      "43.65744376210381\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9852 - accuracy: 0.0048\n",
      "43.83836489398975\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9816 - accuracy: 0.0063\n",
      "44.32952242312275\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9757 - accuracy: 0.0098\n",
      "44.81001102832101\n",
      "Step 10\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 0.9969\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 8.8072e-04\n",
      "45.41997063223798\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9941 - accuracy: 0.0021\n",
      "45.942358587332286\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9939 - accuracy: 0.0019\n",
      "46.33947146601062\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9928 - accuracy: 0.0020\n",
      "46.5550192278546\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9922 - accuracy: 0.0022\n",
      "47.144990646121414\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9912 - accuracy: 0.0030\n",
      "47.65902964368077\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9886 - accuracy: 0.0036\n",
      "48.142136253515474\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9875 - accuracy: 0.0044\n",
      "48.50475765685953\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9834 - accuracy: 0.0063\n",
      "48.901270995325255\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9778 - accuracy: 0.0088\n",
      "49.170133521619256\n",
      "Step 11\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9970\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9890 - accuracy: 0.0042\n",
      "49.49465888153807\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9867 - accuracy: 0.0038\n",
      "49.970666959160596\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9853 - accuracy: 0.0041\n",
      "50.43026361409397\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9797 - accuracy: 0.0075\n",
      "50.82064178593053\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9747 - accuracy: 0.0118\n",
      "51.408195069652855\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9710 - accuracy: 0.0123\n",
      "51.641313171631445\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9649 - accuracy: 0.0160\n",
      "52.04465884104643\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9552 - accuracy: 0.0215\n",
      "52.56420524118128\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9461 - accuracy: 0.0279\n",
      "53.067209898227176\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9362 - accuracy: 0.0338\n",
      "53.55253755602097\n",
      "Step 12\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9946 - accuracy: 0.0019\n",
      "53.90666891413468\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9929 - accuracy: 0.0026\n",
      "54.3830752924409\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9922 - accuracy: 0.0029\n",
      "54.585205349207065\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9926 - accuracy: 0.0028\n",
      "54.74392034290859\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9912 - accuracy: 0.0028\n",
      "54.97079682237571\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9885 - accuracy: 0.0047\n",
      "55.4330721085644\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9878 - accuracy: 0.0040\n",
      "55.93546480140265\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9846 - accuracy: 0.0064\n",
      "56.199409784661\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9804 - accuracy: 0.0073\n",
      "56.90131012836557\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9777 - accuracy: 0.0103\n",
      "57.13391944585242\n",
      "Step 13\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9945 - accuracy: 0.0014\n",
      "57.69705965475779\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9926 - accuracy: 0.0020\n",
      "58.02591926754928\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9927 - accuracy: 0.0030\n",
      "58.5249543691447\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9913 - accuracy: 0.0029\n",
      "59.05654044793701\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9879 - accuracy: 0.0055\n",
      "59.448328075793924\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9867 - accuracy: 0.0053\n",
      "60.014895322990746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9845 - accuracy: 0.0065\n",
      "60.1727172668246\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9812 - accuracy: 0.0095\n",
      "60.65396632987219\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9775 - accuracy: 0.0118\n",
      "61.328262086525235\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9742 - accuracy: 0.0128\n",
      "61.83989988923141\n",
      "Step 14\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0058 - accuracy: 0.9983\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 4.8856e-04\n",
      "62.48722635662138\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 5.0000e-04\n",
      "62.5917733691255\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 8.0000e-04\n",
      "63.11872931149432\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0017\n",
      "63.95379723486641\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9965 - accuracy: 0.0010\n",
      "64.00298617816802\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9962 - accuracy: 0.0011\n",
      "64.40499977089264\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9952 - accuracy: 0.0016\n",
      "64.66415777358004\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9949 - accuracy: 0.0011\n",
      "65.35711589461224\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9940 - accuracy: 0.0019\n",
      "65.664571846699\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9937 - accuracy: 0.0018\n",
      "65.964573362948\n",
      "Step 15\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0071 - accuracy: 0.9977\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 5.6464e-04\n",
      "66.52200616585176\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 9.0000e-04\n",
      "66.6312033556922\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 9.0000e-04\n",
      "66.98710683961755\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9960 - accuracy: 0.0016\n",
      "67.54455489012751\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9955 - accuracy: 0.0017\n",
      "67.73965529213417\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9953 - accuracy: 0.0015\n",
      "68.46431990539985\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9937 - accuracy: 0.0027\n",
      "68.70792925463893\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9938 - accuracy: 0.0019\n",
      "69.1056342049463\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9921 - accuracy: 0.0031\n",
      "69.42967265748214\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9908 - accuracy: 0.0039\n",
      "69.83756671458598\n",
      "Step 16\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9964 - accuracy: 0.0012\n",
      "70.18969071391494\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9952 - accuracy: 0.0022\n",
      "70.26978612751178\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9957 - accuracy: 0.0015\n",
      "70.75348402441904\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9955 - accuracy: 0.0018\n",
      "71.16312833896383\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9944 - accuracy: 0.0025\n",
      "71.81953902655775\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9943 - accuracy: 0.0018\n",
      "72.12147773845344\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9935 - accuracy: 0.0025\n",
      "72.35849615877238\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9942 - accuracy: 0.0016\n",
      "72.54026015437395\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9914 - accuracy: 0.0033\n",
      "73.11436428382996\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9907 - accuracy: 0.0037\n",
      "73.51661458498745\n",
      "Step 17\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0054 - accuracy: 0.9977\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 6.9618e-04\n",
      "73.8290695678626\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0011\n",
      "74.24616049855534\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0015\n",
      "74.60186233721645\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9959 - accuracy: 0.0012\n",
      "75.10680329318028\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9954 - accuracy: 0.0013\n",
      "75.40614155460612\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9958 - accuracy: 0.0010\n",
      "75.73031124340994\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9949 - accuracy: 0.0018\n",
      "75.81537629196882\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9943 - accuracy: 0.0025\n",
      "76.16824822567372\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9940 - accuracy: 0.0021\n",
      "76.46165942249446\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9935 - accuracy: 0.0020\n",
      "76.6764380628727\n",
      "Step 18\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 8.9042e-04\n",
      "76.99521576684671\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9966 - accuracy: 8.0000e-04\n",
      "77.45426023422333\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9959 - accuracy: 0.0013\n",
      "77.93479621851822\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9956 - accuracy: 0.0017\n",
      "77.76891814053559\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9957 - accuracy: 0.0012\n",
      "78.49238928072238\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9950 - accuracy: 0.0016\n",
      "78.91927650080298\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9948 - accuracy: 0.0018\n",
      "79.04956356294419\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9950 - accuracy: 0.0013\n",
      "79.45194526022765\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9928 - accuracy: 0.0029\n",
      "79.91206688564412\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9911 - accuracy: 0.0044\n",
      "80.33184787768296\n",
      "Step 19\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 2ms/step - loss: 0.9979 - accuracy: 2.1348e-04\n",
      "80.3982692602047\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9975 - accuracy: 0.0011\n",
      "80.77184637873778\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9975 - accuracy: 8.0000e-04\n",
      "80.82912969795383\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9971 - accuracy: 7.0000e-04\n",
      "81.53583603519222\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9968 - accuracy: 0.0010\n",
      "81.99485561016297\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9962 - accuracy: 0.0013\n",
      "82.46808500835616\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9965 - accuracy: 7.0000e-04\n",
      "82.93605174947571\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9961 - accuracy: 0.0011\n",
      "83.12456280311297\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9951 - accuracy: 0.0016\n",
      "83.33249826104095\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9955 - accuracy: 0.0015\n",
      "83.73755359952582\n",
      "Step 20\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Training the generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9961 - accuracy: 0.0015\n",
      "83.91894955970781\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9957 - accuracy: 0.0019\n",
      "84.51789686003926\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9952 - accuracy: 0.0023\n",
      "84.5838805733777\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9955 - accuracy: 0.0016\n",
      "84.87452130204326\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9933 - accuracy: 0.0024\n",
      "85.3798902929255\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9940 - accuracy: 0.0019\n",
      "85.53695022003224\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9933 - accuracy: 0.0028\n",
      "85.72088132477747\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9917 - accuracy: 0.0038\n",
      "86.25833875338546\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9915 - accuracy: 0.0037\n",
      "86.38080911825854\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9909 - accuracy: 0.0032\n",
      "86.86245543599847\n",
      "Step 21\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0071 - accuracy: 0.9973\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9926 - accuracy: 0.0029\n",
      "87.12033554191507\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9925 - accuracy: 0.0034\n",
      "87.49640118916261\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9916 - accuracy: 0.0041\n",
      "87.7918200393707\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9928 - accuracy: 0.0030\n",
      "87.97965675463881\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9916 - accuracy: 0.0043\n",
      "88.17868397539759\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9898 - accuracy: 0.0045\n",
      "88.83151266744385\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9885 - accuracy: 0.0052\n",
      "89.54959261572397\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9864 - accuracy: 0.0074\n",
      "89.71457397797721\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9839 - accuracy: 0.0085\n",
      "89.88980065142553\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9841 - accuracy: 0.0081\n",
      "90.0038283712512\n",
      "Step 22\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0070 - accuracy: 0.9974\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9950 - accuracy: 0.0019\n",
      "90.80179025660433\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9949 - accuracy: 0.0021\n",
      "91.42605844847726\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9928 - accuracy: 0.0036\n",
      "91.68168716053832\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9927 - accuracy: 0.0029\n",
      "92.13868133447266\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9916 - accuracy: 0.0040\n",
      "92.36841138337068\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9924 - accuracy: 0.0024\n",
      "92.88709486470991\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9924 - accuracy: 0.0025\n",
      "93.1655058542675\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9919 - accuracy: 0.0026\n",
      "93.4558287119123\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9906 - accuracy: 0.0039\n",
      "93.65982746110427\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9908 - accuracy: 0.0030\n",
      "93.68539354683101\n",
      "Step 23\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0046 - accuracy: 0.9980\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9984 - accuracy: 1.2844e-04\n",
      "93.97873432030009\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9981 - accuracy: 6.0000e-04\n",
      "94.22218725248254\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 9.0000e-04\n",
      "94.53907677801628\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 7.0000e-04\n",
      "94.90836376265847\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0011\n",
      "95.14445676589102\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 8.0000e-04\n",
      "95.39932902855264\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 0.0011\n",
      "95.59255758091476\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 9.0000e-04\n",
      "95.92144712473109\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 8.0000e-04\n",
      "96.83345663784912\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9957 - accuracy: 0.0017\n",
      "96.94195914596725\n",
      "Step 24\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9934 - accuracy: 0.0029\n",
      "97.08535563089791\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9941 - accuracy: 0.0024\n",
      "97.55431155697381\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9937 - accuracy: 0.0027\n",
      "97.67486237354217\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9936 - accuracy: 0.0025\n",
      "97.95906091146847\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9926 - accuracy: 0.0032\n",
      "98.251287509971\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9928 - accuracy: 0.0022\n",
      "98.65131342910219\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9918 - accuracy: 0.0029\n",
      "98.94554699009677\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9909 - accuracy: 0.0038\n",
      "99.45709395782931\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9897 - accuracy: 0.0044\n",
      "100.09663692236455\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9893 - accuracy: 0.0054\n",
      "100.3280030494702\n",
      "Step 25\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 0.9977\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9983 - accuracy: 3.5378e-04\n",
      "100.69405121814948\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9982 - accuracy: 5.0000e-04\n",
      "100.95116069414011\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9978 - accuracy: 4.0000e-04\n",
      "101.28057198285528\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9978 - accuracy: 7.0000e-04\n",
      "101.62380960690881\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9981 - accuracy: 7.0000e-04\n",
      "101.81271022928607\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9978 - accuracy: 6.0000e-04\n",
      "102.35302295562472\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9975 - accuracy: 9.0000e-04\n",
      "102.61349158041789\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9973 - accuracy: 0.0013\n",
      "102.83078554607084\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 7.0000e-04\n",
      "103.2940827932956\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 0.0016\n",
      "103.32560789693476\n",
      "Step 26\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9976 - accuracy: 8.0451e-04\n",
      "103.73745918348313\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9975 - accuracy: 7.0000e-04\n",
      "103.99300999958929\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9973 - accuracy: 9.0000e-04\n",
      "103.92262790061518\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9967 - accuracy: 0.0013\n",
      "104.04181777995507\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9973 - accuracy: 7.0000e-04\n",
      "104.07492402682286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 0.0017\n",
      "104.03126755522602\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9964 - accuracy: 0.0014\n",
      "104.24159196981682\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9962 - accuracy: 0.0019\n",
      "104.2898596155044\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9962 - accuracy: 0.0013\n",
      "104.43483695368951\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9959 - accuracy: 0.0018\n",
      "104.7978332546327\n",
      "Step 27\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0073 - accuracy: 0.9972\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9967 - accuracy: 8.8728e-04\n",
      "105.01482087698862\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9957 - accuracy: 0.0017\n",
      "105.65844340056846\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9952 - accuracy: 0.0022\n",
      "105.99902494350808\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9951 - accuracy: 0.0019\n",
      "105.95055934161192\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9947 - accuracy: 0.0022\n",
      "106.1350492670934\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9934 - accuracy: 0.0029\n",
      "106.31316206691862\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9934 - accuracy: 0.0031\n",
      "106.44602016230898\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9926 - accuracy: 0.0040\n",
      "106.56269388964627\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9917 - accuracy: 0.0041\n",
      "107.06507445091563\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9910 - accuracy: 0.0041\n",
      "107.37201436051093\n",
      "Step 28\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 7.5584e-04\n",
      "107.53803601170695\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 0.0010\n",
      "107.74253419841737\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9973 - accuracy: 9.0000e-04\n",
      "107.757813632895\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 6.0000e-04\n",
      "108.02673213440349\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9962 - accuracy: 0.0015\n",
      "108.09466674670479\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9961 - accuracy: 0.0017\n",
      "108.21066076711946\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9961 - accuracy: 0.0012\n",
      "108.48491598858622\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0014\n",
      "108.63230200009009\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9942 - accuracy: 0.0030\n",
      "108.87062839837537\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9949 - accuracy: 0.0021\n",
      "109.30020720477643\n",
      "Step 29\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9983 - accuracy: 6.6424e-04\n",
      "109.69128750473989\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9982 - accuracy: 5.0000e-04\n",
      "109.97803024732141\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9983 - accuracy: 8.0000e-04\n",
      "110.5292056567461\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9980 - accuracy: 8.0000e-04\n",
      "110.98869398400257\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9980 - accuracy: 6.0000e-04\n",
      "111.36113560177147\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 0.0010\n",
      "111.4670738815122\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9978 - accuracy: 0.0010\n",
      "111.54104179423545\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9972 - accuracy: 0.0011\n",
      "111.77922805264558\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9981 - accuracy: 4.0000e-04\n",
      "111.91895155262893\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 8.0000e-04\n",
      "112.39110523004565\n",
      "Step 30\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0015\n",
      "112.74334977590844\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 9.0000e-04\n",
      "113.12513715577222\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0012\n",
      "113.1113633132894\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 0.0015\n",
      "113.15547569682727\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 0.0017\n",
      "113.30131150122166\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0015\n",
      "113.7287493111375\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9956 - accuracy: 0.0018\n",
      "114.48259099409873\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9955 - accuracy: 0.0022\n",
      "114.54732097301799\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9953 - accuracy: 0.0019\n",
      "114.70979879101299\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9947 - accuracy: 0.0027\n",
      "115.02089462756604\n",
      "Step 31\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9986\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9966 - accuracy: 8.2073e-04\n",
      "115.36609798708328\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9970 - accuracy: 9.0000e-04\n",
      "115.51675799958937\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9965 - accuracy: 0.0012\n",
      "115.87648679352883\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9965 - accuracy: 0.0015\n",
      "115.7621841805273\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9967 - accuracy: 0.0014\n",
      "115.59064266378884\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9963 - accuracy: 0.0013\n",
      "116.05350242586607\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9958 - accuracy: 0.0015\n",
      "116.67708381522559\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9958 - accuracy: 0.0018\n",
      "116.90966989023799\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9948 - accuracy: 0.0020\n",
      "117.18943712578506\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9952 - accuracy: 0.0018\n",
      "117.08471446536015\n",
      "Step 32\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9958 - accuracy: 0.0019\n",
      "117.9123543357949\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9943 - accuracy: 0.0024\n",
      "118.10312130718877\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9931 - accuracy: 0.0027\n",
      "118.617866684424\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9939 - accuracy: 0.0026\n",
      "118.92803172834478\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9932 - accuracy: 0.0024\n",
      "119.60459283474304\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9931 - accuracy: 0.0026\n",
      "119.91446024984724\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9920 - accuracy: 0.0031\n",
      "120.15123332431314\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9919 - accuracy: 0.0035\n",
      "120.25712937970813\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9915 - accuracy: 0.0037\n",
      "120.48511112522286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9914 - accuracy: 0.0038\n",
      "120.61063628986103\n",
      "Step 33\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9990 - accuracy: 2.2764e-04\n",
      "120.92640611270322\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9987 - accuracy: 4.0000e-04\n",
      "121.85593758886995\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9991 - accuracy: 1.0000e-04\n",
      "122.05488428131378\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9987 - accuracy: 4.0000e-04\n",
      "122.13793208921201\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9987 - accuracy: 5.0000e-04\n",
      "122.32157773960391\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9985 - accuracy: 6.0000e-04\n",
      "123.05915189000076\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9987 - accuracy: 6.0000e-04\n",
      "123.20567850175173\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9987 - accuracy: 3.0000e-04\n",
      "123.58886911172932\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9983 - accuracy: 6.0000e-04\n",
      "123.78138879491914\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9985 - accuracy: 4.0000e-04\n",
      "124.29558646572335\n",
      "Step 34\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9985 - accuracy: 3.1492e-04\n",
      "124.60301927462964\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9981 - accuracy: 5.0000e-04\n",
      "124.72555181700122\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9980 - accuracy: 4.0000e-04\n",
      "124.79303872799272\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 8.0000e-04\n",
      "124.77796062993345\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 7.0000e-04\n",
      "125.16688263099036\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9981 - accuracy: 5.0000e-04\n",
      "125.16075499784375\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9973 - accuracy: 0.0010\n",
      "125.6678577788041\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9974 - accuracy: 6.0000e-04\n",
      "125.8481436770542\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0016\n",
      "126.12945330988059\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9964 - accuracy: 0.0012\n",
      "126.55079947293359\n",
      "Step 35\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9956 - accuracy: 0.0021\n",
      "126.84941065467541\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9963 - accuracy: 0.0015\n",
      "127.10468895377888\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9953 - accuracy: 0.0023\n",
      "127.60675765011736\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9959 - accuracy: 0.0018\n",
      "127.75951294583366\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9953 - accuracy: 0.0018\n",
      "127.91712213344196\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9949 - accuracy: 0.0023\n",
      "128.10089798921734\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9943 - accuracy: 0.0025\n",
      "128.64265625686704\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9944 - accuracy: 0.0022\n",
      "128.84425860983796\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9936 - accuracy: 0.0024\n",
      "129.03083069504066\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9927 - accuracy: 0.0032\n",
      "129.5533930734193\n",
      "Step 36\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9974 - accuracy: 8.9483e-04\n",
      "130.01326855164106\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0010\n",
      "130.29347519242478\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0013\n",
      "130.80594630380037\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9962 - accuracy: 0.0012\n",
      "130.79559387596288\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9957 - accuracy: 0.0022\n",
      "130.65328808177196\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9964 - accuracy: 0.0013\n",
      "130.48465639714323\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9961 - accuracy: 0.0015\n",
      "130.71371295327435\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9957 - accuracy: 0.0013\n",
      "131.2158701426099\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9952 - accuracy: 0.0016\n",
      "131.224273137261\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9941 - accuracy: 0.0028\n",
      "131.35633750785408\n",
      "Step 37\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 6.5866e-04\n",
      "131.47319554872234\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9973 - accuracy: 9.0000e-04\n",
      "131.97931464481846\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9973 - accuracy: 0.0012\n",
      "132.37951650282898\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 8.0000e-04\n",
      "132.50030856415927\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0013\n",
      "132.75255441834327\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9974 - accuracy: 0.0010\n",
      "132.98628198258052\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9974 - accuracy: 4.0000e-04\n",
      "133.3038704656366\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0012\n",
      "133.34374409257654\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9967 - accuracy: 0.0013\n",
      "133.3504796128339\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9965 - accuracy: 0.0016\n",
      "133.5864765172866\n",
      "Step 38\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9985\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9978 - accuracy: 6.8948e-04\n",
      "134.21533541443773\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0013\n",
      "134.28490158279928\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9973 - accuracy: 7.0000e-04\n",
      "134.66233817603478\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9969 - accuracy: 0.0012\n",
      "135.32054073922606\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9964 - accuracy: 0.0013\n",
      "135.8872646041558\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9967 - accuracy: 8.0000e-04\n",
      "136.15738829951016\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9969 - accuracy: 0.0011\n",
      "136.25237050642735\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9966 - accuracy: 0.0016\n",
      "136.40409948776883\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9957 - accuracy: 0.0014\n",
      "136.64733699687773\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9960 - accuracy: 0.0017\n",
      "136.6599316740768\n",
      "Step 39\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9938 - accuracy: 0.0031\n",
      "137.28164988919715\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9935 - accuracy: 0.0023\n",
      "137.77693817359304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9933 - accuracy: 0.0034\n",
      "138.24976802851086\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9925 - accuracy: 0.0036\n",
      "138.74136115240006\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9932 - accuracy: 0.0035\n",
      "138.79536187411782\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9933 - accuracy: 0.0027\n",
      "139.16155865755135\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9928 - accuracy: 0.0036\n",
      "139.39064866664137\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9913 - accuracy: 0.0039\n",
      "139.70206495927647\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9909 - accuracy: 0.0045\n",
      "140.02343714113343\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9885 - accuracy: 0.0063\n",
      "140.2368909685967\n",
      "Step 40\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 6.8942e-04\n",
      "140.70068264811732\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9972 - accuracy: 0.0012\n",
      "141.14189781921664\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9966 - accuracy: 9.0000e-04\n",
      "141.04237819547416\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9964 - accuracy: 0.0014\n",
      "141.12654730247817\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9953 - accuracy: 0.0026\n",
      "141.76438802985686\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0013\n",
      "142.0183063975837\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9956 - accuracy: 0.0018\n",
      "142.57943185424185\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 5.0000e-04\n",
      "142.83657707002845\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9964 - accuracy: 0.0015\n",
      "142.82256362842767\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9960 - accuracy: 0.0017\n",
      "143.2666495714038\n",
      "Step 41\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 0.0011\n",
      "143.39306473985297\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 0.0010\n",
      "143.2890598066152\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9983 - accuracy: 4.0000e-04\n",
      "143.38481748953302\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 8.0000e-04\n",
      "143.78330046397485\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 7.0000e-04\n",
      "143.7891767798349\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 0.0011\n",
      "143.8511782497755\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9979 - accuracy: 5.0000e-04\n",
      "144.29232548362384\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9967 - accuracy: 0.0014\n",
      "144.35789511310057\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0011\n",
      "144.53699855271185\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0011\n",
      "144.5207620204802\n",
      "Step 42\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9978 - accuracy: 0.0013\n",
      "144.82222959969914\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 0.0010\n",
      "145.08372337558782\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9980 - accuracy: 9.0000e-04\n",
      "145.30750045893558\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 8.0000e-04\n",
      "145.94842651713273\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9978 - accuracy: 5.0000e-04\n",
      "146.15893823780956\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9970 - accuracy: 0.0015\n",
      "146.26016470534907\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9978 - accuracy: 6.0000e-04\n",
      "146.64639133000915\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9973 - accuracy: 0.0013\n",
      "146.84881124341263\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0014\n",
      "146.86924594878724\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0013\n",
      "147.2760592379431\n",
      "Step 43\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 0.0011\n",
      "147.48565215821372\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9975 - accuracy: 7.0000e-04\n",
      "147.59928093200563\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 8.0000e-04\n",
      "147.8855076300085\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 0.0010\n",
      "147.93719357664048\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9978 - accuracy: 8.0000e-04\n",
      "147.80634306787434\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0017\n",
      "148.11406824471084\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0012\n",
      "148.16740337967195\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9973 - accuracy: 0.0010\n",
      "148.39180280661304\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9969 - accuracy: 0.0014\n",
      "148.59925554774028\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9967 - accuracy: 0.0013\n",
      "149.2565437069399\n",
      "Step 44\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9982 - accuracy: 5.1774e-04\n",
      "149.19459002132456\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9982 - accuracy: 5.0000e-04\n",
      "149.42017882442\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9976 - accuracy: 9.0000e-04\n",
      "149.69064271680648\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9974 - accuracy: 0.0011\n",
      "150.1534366755283\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9975 - accuracy: 0.0013\n",
      "150.65247677117262\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9981 - accuracy: 4.0000e-04\n",
      "150.52316785422718\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9975 - accuracy: 0.0010\n",
      "150.7583594158876\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9975 - accuracy: 0.0013\n",
      "150.80883937701233\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9976 - accuracy: 0.0010\n",
      "151.08135757346076\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 9.0000e-04\n",
      "151.4950929654638\n",
      "Step 45\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9981 - accuracy: 9.2849e-04\n",
      "152.1484898130618\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9983 - accuracy: 6.0000e-04\n",
      "152.25502500577429\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9980 - accuracy: 7.0000e-04\n",
      "152.16895444918705\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9978 - accuracy: 8.0000e-04\n",
      "152.2904145179055\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 9.0000e-04\n",
      "152.6824107009687\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9976 - accuracy: 8.0000e-04\n",
      "153.37318623733663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 8.0000e-04\n",
      "153.43830851680633\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9973 - accuracy: 0.0014\n",
      "153.53772595671083\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9967 - accuracy: 0.0010\n",
      "153.68730429375157\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9975 - accuracy: 0.0010\n",
      "153.9429527923804\n",
      "Step 46\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9942 - accuracy: 0.0028\n",
      "154.23670447277166\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9935 - accuracy: 0.0032\n",
      "154.79961876877798\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9917 - accuracy: 0.0035\n",
      "154.8158657319733\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9930 - accuracy: 0.0027\n",
      "155.60438949713267\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9924 - accuracy: 0.0034\n",
      "155.93981498282255\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9913 - accuracy: 0.0047\n",
      "156.1497607112544\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9924 - accuracy: 0.0036\n",
      "156.18612605051024\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9916 - accuracy: 0.0046\n",
      "156.4473836529274\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9912 - accuracy: 0.0048\n",
      "156.60940205266968\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9910 - accuracy: 0.0047\n",
      "156.6628211515998\n",
      "Step 47\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9964 - accuracy: 0.0019\n",
      "156.92326032181455\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9982 - accuracy: 6.0000e-04\n",
      "157.09962017963\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 8.0000e-04\n",
      "157.49506609054484\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0011\n",
      "157.83125346684346\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0014\n",
      "157.98846383354754\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0012\n",
      "158.30948387837512\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0011\n",
      "158.9254503209969\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 0.0016\n",
      "159.29689407619156\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0017\n",
      "159.76398714899713\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9966 - accuracy: 0.0016\n",
      "159.87938505210118\n",
      "Step 48\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9977 - accuracy: 6.5923e-04\n",
      "159.82733607116066\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9971 - accuracy: 0.0011\n",
      "160.017351885775\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9981 - accuracy: 0.0010\n",
      "160.29716385845944\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0013\n",
      "160.52388952991595\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9972 - accuracy: 0.0011\n",
      "161.5045559271742\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9976 - accuracy: 9.0000e-04\n",
      "161.8631912478789\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 0.0014\n",
      "162.3042441234298\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9970 - accuracy: 0.0012\n",
      "162.1329316328431\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9969 - accuracy: 0.0013\n",
      "162.3365643994593\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9968 - accuracy: 0.0016\n",
      "162.8166124869988\n",
      "Step 49\n",
      "====================\n",
      "Training the discriminator\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9995 - accuracy: 9.9032e-05\n",
      "163.78657382234576\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9993 - accuracy: 1.0000e-04\n",
      "164.02481772338388\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9993 - accuracy: 2.0000e-04\n",
      "164.3724942613989\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9993 - accuracy: 3.0000e-04\n",
      "164.414575114261\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9985 - accuracy: 8.0000e-04\n",
      "164.5729604964708\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9994 - accuracy: 1.0000e-04\n",
      "164.7503606114479\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9992 - accuracy: 1.0000e-04\n",
      "164.58474023329165\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9990 - accuracy: 3.0000e-04\n",
      "165.4759429754808\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9989 - accuracy: 5.0000e-04\n",
      "165.898069053035\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9990 - accuracy: 1.0000e-04\n",
      "166.110180655031\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disc_acc = []\n",
    "gen_loss = [0]\n",
    "gan_acc = []\n",
    "for e in range(50):\n",
    "    g_accuracy = 0\n",
    "    d_accuracy = 0\n",
    "    print(\"Step\", e)\n",
    "    if d_accuracy < 1:\n",
    "        i, o = get_generator_outputs(stft_white_dataset_real, train_size, gan.g, nperseg, stft_clean_dataset_real)\n",
    "    gan.block_generator()\n",
    "    print(\"Training the discriminator\")\n",
    "    s = 0\n",
    "    err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "    while d_accuracy < 0.95 and s<10:\n",
    "        d_accuracy = train_on_batch(gan.d, i, o, verbose=True)\n",
    "        disc_acc.append(d_accuracy)\n",
    "        gan_acc.append(0)\n",
    "        s+=1\n",
    "        gen_loss.append(err)\n",
    "    gan.block_discriminator()\n",
    "    print(\"Training the generator\")\n",
    "    s = 0\n",
    "    while g_accuracy < 0.95 and s<10:\n",
    "        view_output(stft_white_dataset_real, gan,p)\n",
    "        s+=1\n",
    "        p+=1\n",
    "        g_accuracy = train_on_batch(gan.combined_network, stft_white_dataset_real[:train_size], np.ones(train_size), batch_size=4, verbose=True)\n",
    "        gan_acc.append(g_accuracy)\n",
    "        disc_acc.append(0)\n",
    "        err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "        print(err)\n",
    "        gen_loss.append(err)\n",
    "    #print(evaluate_generator(gan.g, white_dataset, clean_dataset))\n",
    "plt.plot(disc_acc)\n",
    "plt.plot(gan_acc)\n",
    "plt.show()\n",
    "plt.plot(gen_loss[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.combined_network.save('save2/gan_with_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(b, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
