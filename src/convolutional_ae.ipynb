{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio\n",
    "\n",
    "samplerate = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "vinyl = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = 1024\n",
    "\n",
    "c, t, Cxx = stft(np.array(clean), fs=samplerate, nperseg=nperseg)\n",
    "d, u, Vxx = stft(np.array(vinyl), fs=samplerate, nperseg=nperseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaySpectrogram(Cxx[:, 32:64])\n",
    "plt.show()\n",
    "displaySpectrogram(Vxx[:, 32:64])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxx = Cxx[1:, :]\n",
    "Vxx = Vxx[1:, :]\n",
    "print(Cxx.shape, Vxx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxx_split = []\n",
    "Vxx_split = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_length = 64\n",
    "for i in range(0, Cxx.shape[1]-samples_length, samples_length):\n",
    "    Cxx_split.append(np.reshape(np.array(Cxx[:, i:i+samples_length]), (Cxx.shape[0], samples_length, 1)))\n",
    "    Vxx_split.append(np.reshape(np.array(Vxx[:, i:i+samples_length]), (Cxx.shape[0], samples_length, 1)))\n",
    "Cxx_split = np.array(Cxx_split)\n",
    "Vxx_split = np.array(Vxx_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Cxx_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cxx_r = np.abs(Cxx_split)\n",
    "Cxx_i = np.imag(Cxx_split)\n",
    "Vxx_r = np.abs(Vxx_split)\n",
    "Vxx_i = np.imag(Vxx_split)\n",
    "print(Cxx_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ker1 = (16, 4)\n",
    "ker2 = (1, 4)\n",
    "def simple_autoencoder(input_shape, V_shape_1):\n",
    "    print(input_shape)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(1, kernel_size = ker,  activation = 'relu', input_shape = input_shape, padding='same', data_format='channels_last')) \n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker1, activation = 'relu', padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker1, activation = 'relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker1, activation = 'relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(V_shape_1*V_shape_1/8, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(V_shape_1*V_shape_1, activation = 'relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Reshape((V_shape_1, V_shape_1, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker2, activation = 'relu', padding='same'))\n",
    "    model.add(tf.keras.layers.UpSampling2D((2, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker2, activation = 'relu', padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker2, activation = 'relu', padding='same'))\n",
    "    model.add(tf.keras.layers.UpSampling2D((2, 1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(1, ker2, activation = 'relu', padding='same'))\n",
    "    model.add(tf.keras.layers.UpSampling2D((2, 1)))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "model = simple_autoencoder((Cxx_r.shape[1], Cxx_r.shape[2], 1), Cxx_r.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_number = 0\n",
    "inp = (np.reshape(Vxx_r[sample_number, :], (Vxx_r[sample_number, :].shape[0], Vxx_r[sample_number, :].shape[1])))\n",
    "displaySpectrogram(inp)\n",
    "plt.show()\n",
    "for _ in range(10):\n",
    "    model.fit(Vxx_r, Cxx_r, batch_size=4, epochs=1)\n",
    "    layerIndex = -1\n",
    "    func = tf.keras.backend.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)\n",
    "    layerOutput = func([Vxx_r])  # input_data is a numpy array\n",
    "    out = (np.reshape(layerOutput[sample_number], (layerOutput[sample_number].shape[0], layerOutput[sample_number].shape[1])))\n",
    "\n",
    "    displaySpectrogram(out)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(Vxx_r.T[:predict_length])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaySpectrogram(Vxx_r[:, :predict_length])\n",
    "plt.show()\n",
    "displaySpectrogram(output.T[:, :predict_length])\n",
    "plt.show()\n",
    "displaySpectrogram(Cxx_r[:, :predict_length])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output = istft(output.T + Vxx_i[:, :predict_length]*1j, fs=samplerate, nperseg=nperseg)[1]\n",
    "clean_output = istft(Vxx_r[:, :predict_length] + Vxx_i[:, :predict_length]*1j, fs=samplerate, nperseg=nperseg)[1]\n",
    "Audio(clean_output, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(cleaned_output, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that auto encoders are always blurry: therefore, the audio output cannot be "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
