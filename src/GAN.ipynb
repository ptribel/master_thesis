{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10659, 1024)\n",
      "(10659, 1024)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio\n",
    "\n",
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"int32\")\n",
    "white = np.array(white, dtype=\"int32\")\n",
    "\n",
    "clean_split = []\n",
    "white_split = []\n",
    "\n",
    "samples_length = nperseg\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_split.append(clean[i:i+samples_length])\n",
    "    white_split.append(white[i:i+samples_length])\n",
    "clean_split = np.array(clean_split)\n",
    "white_split = np.array(white_split)\n",
    "\n",
    "print(clean_split.shape)\n",
    "print(white_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_test0 = np.reshape(clean_split[0, :], (1, clean_split.shape[1]))\n",
    "input_test1 = np.reshape(clean_split[1, :], (1, clean_split.shape[1]))\n",
    "input_test2 = np.reshape(clean_split[2, :], (1, clean_split.shape[1]))\n",
    "b1 = np.reshape(input_test0.T, (clean_split.shape[1],))\n",
    "b2 = np.reshape(input_test1.T, (clean_split.shape[1],))\n",
    "b3 = np.reshape(input_test2.T, (clean_split.shape[1],))\n",
    "b = np.concatenate((b1, b2, b3))\n",
    "\n",
    "c, t, Vxx_input_test = stft(b, fs=samplerate, nperseg=nperseg)\n",
    "displaySpectrogram(Vxx_input_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stft(inputs):\n",
    "    return tf.math.real(tf.signal.stft(inputs, frame_length=nperseg, frame_step=nperseg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_outputs(white_split, train_size, g, nperseg, clean, clean_labels):\n",
    "    rng = np.random.default_rng()\n",
    "    g_outputs = []\n",
    "    print(\"Predicting Generator Outputs\")\n",
    "    batch = rng.choice(white_split, train_size)\n",
    "    for i in range(train_size):\n",
    "        t = np.reshape(batch[i, :], (1, batch.shape[1]))\n",
    "        m = g.predict(t)\n",
    "        o = np.reshape(np.array(m), nperseg)\n",
    "        g_outputs.append(o)\n",
    "    g_outputs = np.array(g_outputs)\n",
    "    labels = -1*np.ones((train_size, 1))\n",
    "    input_data = np.concatenate((g_outputs, clean[:train_size,]))\n",
    "    output_data = np.concatenate((labels, clean_labels[:train_size,]))\n",
    "    return input_data, output_data\n",
    "\n",
    "def show_prediction(input_test0, input_test1, input_test2, white_split, samplerate, nperseg):\n",
    "    output_test0 = g.predict(input_test0)\n",
    "    output_test1 = g.predict(input_test1)\n",
    "    output_test2 = g.predict(input_test2)\n",
    "    o1 = np.reshape(output_test0.T, (white_split.shape[1],1))\n",
    "    o2 = np.reshape(output_test1.T, (white_split.shape[1],1))\n",
    "    o3 = np.reshape(output_test2.T, (white_split.shape[1],1))\n",
    "    o = np.concatenate((o1, o2, o3))\n",
    "    c, t, Vxx_test = stft(o, fs=samplerate, nperseg=nperseg)\n",
    "    displaySpectrogram(Vxx_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"skip_autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 1024, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 1024, 4)           20        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              1049600   \n",
      "=================================================================\n",
      "Total params: 5,244,948\n",
      "Trainable params: 5,244,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1, 513)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 512)            263168    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1, 1)              129       \n",
      "=================================================================\n",
      "Total params: 427,521\n",
      "Trainable params: 427,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def skip_generator(size):\n",
    "    inputs = tf.keras.Input(shape=(size,))\n",
    "    x0 = tf.keras.layers.Reshape((size, -1))(inputs)\n",
    "    #x0 = tf.keras.layers.Dropout(0.1)(inputs)\n",
    "    x1 = tf.keras.layers.Conv1D(4, kernel_size = (4,),  activation=\"tanh\", padding=\"same\")(x0)\n",
    "    x2 = tf.keras.layers.Flatten()(x1)\n",
    "    x3 = tf.keras.layers.Dense(size, activation=\"tanh\")(x2)\n",
    "    outputs = tf.keras.layers.Dense(size)(x3)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"skip_autoencoder\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def stft_discriminator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x0 = tf.keras.layers.Lambda(process_stft)(inputs)\n",
    "    x1 = tf.keras.layers.Dense(512, activation=\"tanh\")(x0)\n",
    "    x2 = tf.keras.layers.Dense(256, activation=\"tanh\")(x1)\n",
    "    x3 = tf.keras.layers.Dense(128, activation=\"tanh\")(x2)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x3)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer= 'adam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def GAN(size, g, d):\n",
    "    z = tf.keras.layers.Input(shape=(size,))\n",
    "    image = g(z)\n",
    "    valid = d(image)\n",
    "    d.trainable = False\n",
    "    combined_network = tf.keras.Model(z, valid)\n",
    "    combined_network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return combined_network\n",
    "\n",
    "g = skip_generator(clean_split.shape[1])\n",
    "d = stft_discriminator(clean_split.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator_on_batch(g, d, white, clean, clean_labels, train_size=5000, batch_num=1, max_accuracy=0.4, max_iterations=50):\n",
    "    it = 0\n",
    "    for _ in range(batch_num):\n",
    "        previous_accuracy = 0\n",
    "        input_data, output_data = get_generator_outputs(white_split, train_size, g, nperseg, clean, clean_labels)\n",
    "        history = d.fit(input_data, output_data, batch_size=16)\n",
    "        while previous_accuracy < max_accuracy and it < max_iterations:\n",
    "            it += 1\n",
    "            if abs(np.mean(history.history['accuracy']) - previous_accuracy) < 0.001:\n",
    "                input_data, output_data = get_generator_outputs(white_split, train_size, g, nperseg, clean, clean_labels)\n",
    "            previous_accuracy = np.mean(history.history['accuracy'])\n",
    "            history = d.fit(input_data, output_data, batch_size=16)\n",
    "    return np.mean(history.history['accuracy']), d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_labels = np.ones((clean_split.shape[0], ))\n",
    "white_labels = np.zeros((white_split.shape[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training the generator\n",
      "667/667 [==============================] - 16s 24ms/step - loss: 26114586.0000 - accuracy: 0.0065\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-training the generator\")\n",
    "g_accuracy = g.fit(white_split, clean_split, epochs=1, batch_size=16).history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training the discriminator\n",
      "1333/1333 [==============================] - 5s 3ms/step - loss: 0.2520 - accuracy: 0.5005\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-training the discriminator\")\n",
    "d_accuracy = d.fit(np.concatenate((white_split, clean_split)), np.concatenate((white_labels, clean_labels)), epochs=1, batch_size=16).history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator accuracy: 0.006473402958363295\n",
      "Discriminator accuracy: 0.5004690885543823\n",
      "Training the generator\n",
      "667/667 [==============================] - 20s 29ms/step - loss: 0.2494 - accuracy: 0.5394\n",
      "Generator accuracy: 0.006473402958363295\n",
      "Discriminator accuracy: 0.5004690885543823\n",
      "Training the discriminator\n",
      "Predicting Generator Outputs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-202e278acfff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the discriminator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#history = d.fit(np.concatenate((white_split, clean_split)), np.concatenate((white_labels, clean_labels)), epochs=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0md_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discriminator_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhite_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-727b1676b924>\u001b[0m in \u001b[0;36mtrain_discriminator_on_batch\u001b[0;34m(g, d, white, clean, clean_labels, train_size, batch_num, max_accuracy, max_iterations)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprevious_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generator_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhite_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mprevious_accuracy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_accuracy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-50bb5f786cb1>\u001b[0m in \u001b[0;36mget_generator_outputs\u001b[0;34m(white_split, train_size, g, nperseg, clean, clean_labels)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generator accuracy:\", g_accuracy)\n",
    "    print(\"Discriminator accuracy:\", d_accuracy)\n",
    "    previous_accuracy  = 0\n",
    "    gan = GAN(white_split.shape[1], g, d)\n",
    "    print(\"Training the generator\")\n",
    "    history = gan.fit(white_split, clean_labels, epochs=1, batch_size=16)\n",
    "    new_accuracy = np.mean(history.history['accuracy'])\n",
    "    it = 0\n",
    "    while new_accuracy < max(g_accuracy, d_accuracy) and it < 50:\n",
    "        it += 1\n",
    "        previous_accuracy = np.mean(history.history['accuracy'])\n",
    "        history = gan.fit(white_split, clean_labels, batch_size=16)\n",
    "        new_accuracy = np.mean(history.history['accuracy'])\n",
    "        if new_accuracy > d_accuracy:\n",
    "            g_accuracy = new_accuracy\n",
    "    #show_prediction(input_test0, input_test1, input_test2, white_split, samplerate, nperseg)\n",
    "    print(\"Generator accuracy:\", g_accuracy)\n",
    "    print(\"Discriminator accuracy:\", d_accuracy)\n",
    "    print(\"Training the discriminator\")\n",
    "    #history = d.fit(np.concatenate((white_split, clean_split)), np.concatenate((white_labels, clean_labels)), epochs=3)\n",
    "    d_accuracy, d = train_discriminator_on_batch(g, d, white_split, clean_split, clean_labels, max_accuracy=max(g_accuracy, d_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [np.reshape(white_split[k, :], (1, white_split.shape[1])) for k in range(25)]\n",
    "o = [g.predict(i[k]) for k in range(len(i))]\n",
    "p = [np.reshape(i[k].T, (white_split.shape[1],)) for k in range(len(o))]\n",
    "q = [np.reshape(o[k].T, (white_split.shape[1],)) for k in range(len(o))]\n",
    "\n",
    "\n",
    "a = np.concatenate(p)\n",
    "b = np.concatenate(q)\n",
    "Audio(a, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(b, rate=samplerate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
