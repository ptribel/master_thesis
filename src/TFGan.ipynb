{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Generative Adversarial Networks\n",
    "## Initialisation and dataset preparation\n",
    "\n",
    "First, let us import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio\n",
    "import tensorflow_gan as tfgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us include the dataset.\n",
    "\n",
    "The dataset is made of two files: `clean/p1.wav`and `white/p1.wav` which are converted into arrays of `int32` and then split into segments of `samples_length`.\n",
    "\n",
    "The goal of the CGAN here is to predict the clean sample, when fed with the white one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"int32\")\n",
    "white = np.array(white, dtype=\"int32\")\n",
    "\n",
    "clean_dataset = []\n",
    "white_dataset = []\n",
    "\n",
    "samples_length = nperseg\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_dataset.append(clean[i:i+samples_length])\n",
    "    white_dataset.append(white[i:i+samples_length])\n",
    "clean_dataset = np.array(clean_dataset)\n",
    "white_dataset = np.array(white_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10659, 3, 513) (10659, 3, 513) (10659, 3, 513) (10659, 3, 513)\n"
     ]
    }
   ],
   "source": [
    "stft_clean_dataset_real = []\n",
    "stft_clean_dataset_imag = []\n",
    "stft_white_dataset_real = []\n",
    "stft_white_dataset_imag = []\n",
    "\n",
    "for i in clean_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_clean_dataset_real.append(np.real(inp).T)\n",
    "    stft_clean_dataset_imag.append(np.imag(inp).T)\n",
    "    \n",
    "for i in white_dataset:\n",
    "    c, t, inp = stft(i, fs=samplerate, nperseg=nperseg)\n",
    "    stft_white_dataset_real.append(np.real(inp).T)\n",
    "    stft_white_dataset_imag.append(np.imag(inp).T)\n",
    "\n",
    "stft_clean_dataset_real = np.array(stft_clean_dataset_real)\n",
    "stft_clean_dataset_imag = np.array(stft_clean_dataset_imag)\n",
    "stft_white_dataset_real = np.array(stft_white_dataset_real)\n",
    "stft_white_dataset_imag = np.array(stft_white_dataset_imag)\n",
    "print(stft_clean_dataset_real.shape, stft_clean_dataset_imag.shape, stft_white_dataset_real.shape, stft_white_dataset_imag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = stft_clean_dataset_real.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_output(stft_white_dataset_real, gan, p):\n",
    "    outputs = []\n",
    "    for i in range(10):\n",
    "        y = np.reshape(stft_white_dataset_real[i, :, :], (-1, stft_white_dataset_real.shape[1], stft_white_dataset_real.shape[2]))\n",
    "        t, y1 = istft(np.reshape(gan.g.predict(y).T, data_shape[::-1])+np.imag(stft_white_dataset_imag[i]).T)\n",
    "        y2 = np.reshape(y1.T, (clean_dataset.shape[1],))\n",
    "        outputs.append(y2)\n",
    "    b = np.concatenate(outputs)\n",
    "    c, t, bxx = stft(b, fs=samplerate, nperseg=nperseg)\n",
    "    displaySpectrogram(bxx)\n",
    "    plt.savefig(str(p)+\".png\", format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN Model\n",
    "The main idea of a GAN model is to create two networks who play an adversarial game:\n",
    "- A Generator, whose goal is to produce the most realistic samples possible to fool the Discriminator\n",
    "- A Discriminator, whose goal is to correctly guess if its input is a real sample from the clean dataset or an output created by the Generator\n",
    "\n",
    "A first model is saved in `'save2/gan_without_add'`. It does not have any add layer. It has been train on 3104 steps on 5000 samples of size 2048, visualizable in the folder `save2` gif.\n",
    "\n",
    "A first model is saved in `'save2/gan_with_add'`. It does have an add layer. It has been train on 2475 steps on 10000 samples of size 1024, visualizable in the folder `save3` gif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator here uses a layer to process the Short-Time Fourier Transform (https://en.wikipedia.org/wiki/Short-time_Fourier_transform) before reducing the problem dimension to one single boolean prediction layer.\n",
    "\n",
    "Interestingly, adding a Dropout layer on the input seems to prevent the generator to adapt itself to the little flaws of detection (which then only produces noise unrecognized by the discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    #x3 = tf.keras.layers.Dense(512, activation=\"tanh\")(x)\n",
    "    x4 = tf.keras.layers.Dense(256, activation=\"tanh\")(x)\n",
    "    x5 = tf.keras.layers.Dense(128, activation=\"tanh\")(x4)\n",
    "    x6 = tf.keras.layers.Dense(1, activation=\"tanh\")(x5)\n",
    "    x7 = tf.keras.layers.Flatten()(x6)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x7)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer= 'adam', loss='bce', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "The generator itself is a Convolutionnal Autoencoder.\n",
    "\n",
    "Its input size and output size are both the size of the stft array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sizes):\n",
    "    inputs = tf.keras.Input(shape=(sizes[1], sizes[2]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    x1 = tf.keras.layers.Dense(10, activation='tanh')(x)\n",
    "    x4 = tf.keras.layers.Dense(sizes[2], activation='tanh')(x1)\n",
    "    x5 = tf.keras.layers.Add()([inputs, x4])\n",
    "    outputs = tf.keras.layers.Dense(sizes[2], activation='linear')(inputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"autoencoder\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_generator(g, inputs, outputs, size=100):\n",
    "    res = 0\n",
    "    s = min(size, inputs.shape[0])\n",
    "    for i in range(s):\n",
    "        error = (g.predict(np.reshape(inputs[i], (-1, inputs[i].shape[0], inputs[i].shape[1])))-outputs[i])**2\n",
    "        res += np.sum(error)\n",
    "    return res/(s*100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_outputs(white, train_size, g, nperseg, clean):\n",
    "    steps = train_size//20\n",
    "    rng = np.random.default_rng()\n",
    "    g_outputs = []\n",
    "    batch = rng.choice(white, train_size)\n",
    "    for i in range(train_size):\n",
    "        if i%steps == 0:\n",
    "            print(\"=\", end='')\n",
    "        t = np.reshape(white[i, :, :], (-1, white.shape[1], white.shape[2]))\n",
    "        m = g.predict(t)\n",
    "        g_outputs.append(m)\n",
    "    print()\n",
    "    g_outputs = np.reshape(np.array(g_outputs), (train_size,  white.shape[1], white.shape[2]))\n",
    "    input_data = np.concatenate((g_outputs, clean[:train_size,]))\n",
    "    output_data = np.concatenate((np.zeros((train_size,)), 0.9*np.ones((train_size,))))\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, size, g, d):\n",
    "        self.g = g\n",
    "        self.d = d\n",
    "        self.size = size\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.z = self.g.inputs\n",
    "        self.image = self.g(self.z)\n",
    "        self.valid = self.d(self.image)\n",
    "        self.combined_network = tf.keras.Model(self.z, self.valid)\n",
    "        self.compile()\n",
    "        \n",
    "    def block_discriminator(self):\n",
    "        self.d.trainable = False\n",
    "        self.g.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def block_generator(self):\n",
    "        self.g.trainable = False\n",
    "        self.d.trainable = True\n",
    "        self.build()\n",
    "        \n",
    "    def compile(self):\n",
    "        self.combined_network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 3, 513)]          0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3, 513)            263682    \n",
      "=================================================================\n",
      "Total params: 263,682\n",
      "Trainable params: 263,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 3, 513)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3, 513)            0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3, 256)            131584    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3, 1)              129       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 164,613\n",
      "Trainable params: 164,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator(stft_white_dataset_real.shape)\n",
    "d = discriminator(stft_white_dataset_real.shape)\n",
    "gan = GAN(stft_white_dataset_real.shape, g, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(d, i, o, validation_split=0, batch_size=16, verbose=True):  \n",
    "    history = d.fit(i, o, batch_size=batch_size, validation_split=validation_split, verbose=verbose)\n",
    "    return np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_train_size = 2500#stft_white_dataset_real.shape[0]\n",
    "generator_train_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "d_accuracy = 0\n",
    "while d_accuracy < 0.5:\n",
    "    d_accuracy = train_on_batch(gan.d, np.concatenate((stft_white_dataset_real[:train_size], stft_clean_dataset_real[:train_size])), np.concatenate((np.zeros(train_size), np.ones(train_size))), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7139 - accuracy: 0.2914\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6331 - accuracy: 0.4638\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.4900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.4894\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.4944\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.4940\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.4938\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.4962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.4976\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.4970\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5330 - accuracy: 0.2415\n",
      "0.990365987327889\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1626 - accuracy: 0.7292\n",
      "1.4473062248924307\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1398 - accuracy: 0.7755\n",
      "1.889592999617717\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1275 - accuracy: 0.8038\n",
      "2.4349849156710826\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1175 - accuracy: 0.8225\n",
      "2.9214183926539583\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1116 - accuracy: 0.8364\n",
      "3.3477368033468626\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1081 - accuracy: 0.8463\n",
      "3.8508730141989633\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1077 - accuracy: 0.8405\n",
      "4.339147169376917\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1040 - accuracy: 0.8477\n",
      "4.749808752810988\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1024 - accuracy: 0.8559\n",
      "5.276357190229843\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1008 - accuracy: 0.8592\n",
      "5.836338588374067\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0985 - accuracy: 0.8614\n",
      "6.362373563515106\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0908 - accuracy: 0.8690\n",
      "6.939495416092268\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0905 - accuracy: 0.8774\n",
      "7.468237596222742\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0860 - accuracy: 0.8816\n",
      "7.999898204555597\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0849 - accuracy: 0.8856\n",
      "8.48015045345254\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0811 - accuracy: 0.8946\n",
      "8.936213241812897\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0797 - accuracy: 0.9024\n",
      "9.620325496091818\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0771 - accuracy: 0.9088\n",
      "10.125670011496904\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0729 - accuracy: 0.9139\n",
      "10.690464461085371\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0736 - accuracy: 0.9075\n",
      "11.129784336956906\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0705 - accuracy: 0.9128\n",
      "11.67343222586573\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0691 - accuracy: 0.9128\n",
      "12.067773882010714\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0717 - accuracy: 0.9097\n",
      "12.61092249097117\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0713 - accuracy: 0.9141\n",
      "13.11617118646693\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0693 - accuracy: 0.9147\n",
      "13.534186900925544\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0675 - accuracy: 0.9206\n",
      "14.01385494913545\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0666 - accuracy: 0.9217\n",
      "14.458070704382491\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0654 - accuracy: 0.9258\n",
      "15.010598398351773\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0650 - accuracy: 0.9222\n",
      "15.462054367173241\n",
      "Step 1\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.4594\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.4962\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.4986\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.4994\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2345 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2257 - accuracy: 0.4996\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2192 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2143 - accuracy: 0.5000\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2070 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9472 - accuracy: 5.5183e-05\n",
      "15.834409361519914\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9397 - accuracy: 3.0000e-04\n",
      "16.2609429919783\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9280 - accuracy: 6.0000e-04\n",
      "16.822316245560526\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9096 - accuracy: 0.0017\n",
      "17.403314639040705\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.8641 - accuracy: 0.0086\n",
      "18.03065498915507\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.7811 - accuracy: 0.0430\n",
      "18.59702687572017\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.6559 - accuracy: 0.1321\n",
      "19.16975274731219\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.5323 - accuracy: 0.2592\n",
      "19.69354648359256\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.4364 - accuracy: 0.3722\n",
      "20.354625463583275\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.3447 - accuracy: 0.4908\n",
      "20.807858947357072\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.2680 - accuracy: 0.5948\n",
      "21.371540511826836\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1954 - accuracy: 0.7018\n",
      "21.802598365479437\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1525 - accuracy: 0.7755\n",
      "22.255819280178514\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1184 - accuracy: 0.8363\n",
      "23.04093940595704\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0942 - accuracy: 0.8738\n",
      "23.553111846678487\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0783 - accuracy: 0.8986\n",
      "24.119897544647745\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0674 - accuracy: 0.9142\n",
      "24.70962535447605\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0587 - accuracy: 0.9246\n",
      "25.33015030470748\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0525 - accuracy: 0.9368\n",
      "25.90393468726385\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0453 - accuracy: 0.9466\n",
      "26.396207808794127\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0395 - accuracy: 0.9554\n",
      "26.855926133838217\n",
      "Step 2\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.4726\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2097 - accuracy: 0.4992\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2019 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1872 - accuracy: 0.5000: 0s\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9735 - accuracy: 0.0000e+00\n",
      "27.014127558318297\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9686 - accuracy: 1.0000e-04\n",
      "27.217856301961454\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9629 - accuracy: 1.0000e-04\n",
      "27.334203153138446\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9538 - accuracy: 4.0000e-04\n",
      "27.660929394194152\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9323 - accuracy: 0.0013\n",
      "28.147175431390455\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8912 - accuracy: 0.0039\n",
      "28.68602852936465\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8113 - accuracy: 0.0186\n",
      "29.369939723369356\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6959 - accuracy: 0.0783\n",
      "29.958358151816064\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5644 - accuracy: 0.1748\n",
      "30.595690835408867\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4415 - accuracy: 0.3139\n",
      "31.257788150926476\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3332 - accuracy: 0.4717\n",
      "31.889280421015545\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2500 - accuracy: 0.6113\n",
      "32.433850040364945\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1971 - accuracy: 0.7079\n",
      "33.13562882625383\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1616 - accuracy: 0.7743\n",
      "33.86686690951372\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1347 - accuracy: 0.8243\n",
      "34.47025313632173\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1146 - accuracy: 0.8593\n",
      "35.20124391562144\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0957 - accuracy: 0.8864\n",
      "35.725803218996546\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0856 - accuracy: 0.9041\n",
      "36.238986596598515\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0780 - accuracy: 0.9142\n",
      "36.635629997121214\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0699 - accuracy: 0.9262\n",
      "37.34491969215863\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0623 - accuracy: 0.9381\n",
      "37.960002116393504\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0586 - accuracy: 0.9426\n",
      "38.64054637315844\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0541 - accuracy: 0.9479\n",
      "39.21794679154895\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0504 - accuracy: 0.9536\n",
      "39.93422591500796\n",
      "Step 3\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2545 - accuracy: 0.4834\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1796 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1723 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1680 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9844 - accuracy: 4.4535e-05\n",
      "40.10402775861304\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9805 - accuracy: 7.0000e-04\n",
      "40.37377865624609\n",
      "2500/2500 [==============================] - 11s 5ms/step - loss: 0.9763 - accuracy: 9.0000e-04\n",
      "40.54227174805194\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9699 - accuracy: 0.0012\n",
      "40.896928050365304\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9589 - accuracy: 0.0021\n",
      "41.13030930782727\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9406 - accuracy: 0.0029\n",
      "41.51600524034891\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9098 - accuracy: 0.0079\n",
      "41.86653612175145\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.8649 - accuracy: 0.0135\n",
      "42.54705940699626\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.7944 - accuracy: 0.0364\n",
      "42.919709898575206\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.6956 - accuracy: 0.0890\n",
      "43.56454544332003\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.6028 - accuracy: 0.1618\n",
      "44.185352980827425\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.5227 - accuracy: 0.2429\n",
      "44.60704626401203\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.4473 - accuracy: 0.3343\n",
      "45.22600389091857\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.3769 - accuracy: 0.4324\n",
      "45.72661686847596\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.3303 - accuracy: 0.5054\n",
      "46.45223722320142\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.2865 - accuracy: 0.5691\n",
      "47.00207945047926\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.2531 - accuracy: 0.6222\n",
      "47.6427325397379\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.2181 - accuracy: 0.6800\n",
      "48.20968733988906\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.7346\n",
      "48.79752388415069\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1637 - accuracy: 0.7746\n",
      "49.3193355505766\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1442 - accuracy: 0.8102\n",
      "49.85392195547447\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.1317 - accuracy: 0.8270\n",
      "50.38103804247751\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1158 - accuracy: 0.8518\n",
      "51.008421144636465\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1044 - accuracy: 0.8762\n",
      "51.68675588052049\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0958 - accuracy: 0.8905\n",
      "52.50000157891\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0869 - accuracy: 0.9030\n",
      "52.976024325271524\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0833 - accuracy: 0.9056\n",
      "53.58828486908911\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.0776 - accuracy: 0.9172\n",
      "54.36668315905821\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.0737 - accuracy: 0.9235\n",
      "54.973346113392154\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0663 - accuracy: 0.9348\n",
      "55.513756692920936\n",
      "Step 4\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2517 - accuracy: 0.4804\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1793 - accuracy: 0.4996\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1730 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1675 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9856 - accuracy: 7.7863e-04\n",
      "55.72776420015117\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9821 - accuracy: 8.0000e-04\n",
      "55.75228132612745\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9790 - accuracy: 0.0011\n",
      "56.14785267960808\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9738 - accuracy: 0.0022\n",
      "56.581653129949295\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9682 - accuracy: 0.0025\n",
      "56.79873376513871\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9599 - accuracy: 0.0018\n",
      "56.85488125295556\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9409 - accuracy: 0.0064\n",
      "57.07418002899678\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9186 - accuracy: 0.0107\n",
      "57.31984691908438\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8841 - accuracy: 0.0234\n",
      "57.734110507194046\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.8364 - accuracy: 0.0426: 0s - loss: 0.8\n",
      "58.27508808593054\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7800 - accuracy: 0.0770\n",
      "58.87609261924973\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7125 - accuracy: 0.1239\n",
      "59.63313337381471\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6409 - accuracy: 0.1733\n",
      "60.13268085175543\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.5763 - accuracy: 0.2310\n",
      "60.72398283322023\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5184 - accuracy: 0.2875\n",
      "61.34134234060349\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4780 - accuracy: 0.3263\n",
      "61.93452501108504\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.4210 - accuracy: 0.3936\n",
      "62.57927957028252\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.3688 - accuracy: 0.4563\n",
      "62.99756656839411\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.3273 - accuracy: 0.5143\n",
      "63.63390224220184\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2870 - accuracy: 0.5711\n",
      "64.03712699628055\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2592 - accuracy: 0.6196\n",
      "64.59565382224038\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2348 - accuracy: 0.6576\n",
      "65.0780920558799\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2121 - accuracy: 0.6887\n",
      "65.55902735999493\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1937 - accuracy: 0.7262\n",
      "66.26414058624327\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.1790 - accuracy: 0.7471\n",
      "66.62292634023127\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1560 - accuracy: 0.7869\n",
      "67.0474164076216\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1442 - accuracy: 0.8045\n",
      "67.64600278497792\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1312 - accuracy: 0.8256\n",
      "68.27939824121094\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1193 - accuracy: 0.8446\n",
      "69.0070243409845\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1120 - accuracy: 0.8600\n",
      "69.56538517071915\n",
      "Step 5\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2376 - accuracy: 0.4854\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1793 - accuracy: 0.4994\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.4994\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.4992\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1667 - accuracy: 0.5000\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.49 - 1s 3ms/step - loss: 0.1670 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9858 - accuracy: 0.0017\n",
      "69.91504624447609\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9864 - accuracy: 7.0000e-04\n",
      "70.33082890438327\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9839 - accuracy: 0.0013\n",
      "70.8213854288732\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9805 - accuracy: 0.0014\n",
      "71.17954653955834\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.9778 - accuracy: 0.0020\n",
      "71.43454635805591\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9748 - accuracy: 0.0024\n",
      "71.47835792153421\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9697 - accuracy: 0.0026\n",
      "71.60746463810962\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9612 - accuracy: 0.0050\n",
      "72.18395543012169\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9522 - accuracy: 0.0055\n",
      "72.59906113663763\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9424 - accuracy: 0.0082\n",
      "73.21863396327407\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9290 - accuracy: 0.0114\n",
      "73.54569462401084\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9120 - accuracy: 0.0169\n",
      "74.04057651864258\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8888 - accuracy: 0.0233\n",
      "74.42211375606315\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8551 - accuracy: 0.0370\n",
      "75.11725499448663\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8048 - accuracy: 0.0603\n",
      "75.61769643704456\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7487 - accuracy: 0.0944\n",
      "76.07557909996892\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6933 - accuracy: 0.1333\n",
      "76.50098791501881\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.6322 - accuracy: 0.1771\n",
      "76.81038907512469\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5726 - accuracy: 0.2305\n",
      "77.46091035977453\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5146 - accuracy: 0.2996\n",
      "78.23160290218522\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4579 - accuracy: 0.3546\n",
      "78.92270670654038\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.4035 - accuracy: 0.4260\n",
      "79.39305648155619\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3655 - accuracy: 0.4791\n",
      "79.93863016207197\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3306 - accuracy: 0.5198\n",
      "80.27423008634563\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3015 - accuracy: 0.5674\n",
      "80.8459485823908\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2726 - accuracy: 0.6089\n",
      "81.39973216932113\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2519 - accuracy: 0.6389\n",
      "82.03716671160016\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.2292 - accuracy: 0.6728\n",
      "82.70027820733564\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2122 - accuracy: 0.6981\n",
      "83.23180602819023\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1972 - accuracy: 0.7272\n",
      "83.6702582779757\n",
      "Step 6\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2215 - accuracy: 0.4900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.4994\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1675 - accuracy: 0.4996\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.5000\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9920 - accuracy: 6.6850e-04\n",
      "84.32473498335646\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9905 - accuracy: 3.0000e-04\n",
      "84.67916929831793\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9904 - accuracy: 4.0000e-04\n",
      "85.24928625342126\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9876 - accuracy: 8.0000e-04\n",
      "85.4612872051793\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9855 - accuracy: 5.0000e-04\n",
      "85.81922998112536\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9819 - accuracy: 0.0026\n",
      "86.50350973213311\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9803 - accuracy: 0.0013\n",
      "86.97398122602941\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9762 - accuracy: 0.0016\n",
      "87.38089061367246\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9711 - accuracy: 0.0028\n",
      "87.85952130287333\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9659 - accuracy: 0.0030\n",
      "88.20980082998771\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9597 - accuracy: 0.0047\n",
      "88.29216806343416\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9517 - accuracy: 0.0067\n",
      "88.75197669125181\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9420 - accuracy: 0.0090\n",
      "89.01375450218669\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9324 - accuracy: 0.0103\n",
      "89.54891361306768\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9164 - accuracy: 0.0172\n",
      "89.95842699088662\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8995 - accuracy: 0.0252\n",
      "90.11529934179819\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8758 - accuracy: 0.0343\n",
      "90.68202984720237\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.8491 - accuracy: 0.0528\n",
      "91.33918976584997\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8237 - accuracy: 0.0701\n",
      "91.79956150436135\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7936 - accuracy: 0.0837\n",
      "92.31345588166087\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7652 - accuracy: 0.1073\n",
      "92.79931356688233\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.7294 - accuracy: 0.1331\n",
      "93.40201633917776\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6909 - accuracy: 0.1624\n",
      "93.9799083703243\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6447 - accuracy: 0.2053\n",
      "94.23713437212938\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6064 - accuracy: 0.2367\n",
      "94.65678032629528\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5626 - accuracy: 0.2821\n",
      "95.39551207866539\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5233 - accuracy: 0.3202\n",
      "95.67865047634878\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4881 - accuracy: 0.3581\n",
      "96.2843755926974\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4639 - accuracy: 0.3857\n",
      "97.16793920841305\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4389 - accuracy: 0.4105\n",
      "97.72661079926384\n",
      "Step 7\n",
      "====================\n",
      "Training the discriminator\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.4928\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.4988\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.4992\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.4998\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.5000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.4992\n",
      "Training the generator\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9897 - accuracy: 0.0011\n",
      "98.1212575766651\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9882 - accuracy: 0.0012\n",
      "98.13958618044681\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9873 - accuracy: 0.0010\n",
      "98.58825517064024\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9855 - accuracy: 0.0019\n",
      "98.98529797713718\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f1c9d59c61ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mg_accuracy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mview_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_white_dataset_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-49636dd6386e>\u001b[0m in \u001b[0;36mview_output\u001b[0;34m(stft_white_dataset_real, gan, p)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_white_dataset_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_white_dataset_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_white_dataset_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_white_dataset_imag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclean_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2969\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2971\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2972\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABTHUlEQVR4nO29Z3Sc53H3PdsLsNhFW/Te2UCAJNjFIhaJVJdsS3KJq1z02nHiEjt+HMdJ3hSn2o6SyC1y5CJLVqFkUZVVFDtIgg0AC4hG9LKLXWCx9X4/2PjwxtRG9/UTQ57z7JzDL3s4uNt1zTXzn//MGDRNk5SkJCUpScn/vhhv9A2kJCUpScn/rZIywClJSUpScoMkZYBTkpKUpOQGScoApyQlKUnJDZKUAU5JSlKSkhskKQOckpSkJCU3SMx6/rPL7NRyrB6lCzlMcSW9OYkkTEjfamTX7w0hdSl2GJD+eJidlQXOKNL3RyxIPyczgvQjQfb84ThbP2l29fc3FbKia7udYaRvtLG1F51m+pYMph+aZPo2ewzpz8ywtS8i0jk9PKZpWu5//12XAY6KXWyOdUo3sNXVoKQ3J9/v/yek33rLR5F+/bJxpN9+NAfpux2zSN+VwfSNJsYXd+azA7DteB7Sb1o7gvRnr6rr/texKnTtP1h5Cek7ytjhY0hjBshYkIH0J3ZMIH2bixngp46w7yci8qnT3+651u+6DHCG0SGb0tQMKcU6nlj4h0h/KsJc2K6THqR/2scW4d1lbBHGo8yLcC9mm1iszAtsdo0i/fEz7PoGg/oBtCrXj649PWFD+rEQi36i4QTTj04h/cxiZkAdtxYh/Q9nXkb6IiKfOn3t33UZYJtJpMqldgMtWUE1xd9JIKrrVn9P8tJmkL7VzDy47fW9SD86y46wrLVsE2uzbBNoIaZvTGPfn0prX76y7i2N7Nsb2dkh/RfdSP+Ngd+LnHXJbcXDSH92kh0g8Z0gfLnO8r+2qo9OpCP9zQUMAnC7mAectYAZkHP7spB+cZ4P6e/9uQfpLyhiHujMDDsAIjHmgVffxb7fFv+Asm58El1aEgw9koJi5oF+chHz4Mcv2ZG+q4rBX6E+Fv0dbC9G+slElwEOxTQ5PaH2MjbkszDmud5spN80pei6/06aY+wUr6pkB8hLJyuQfp6dJcE8NcwLsQ1ADxhi0DueKEX6MU09AilPm0bXtsPoa/6D7NtpPnYCeN3s+tMMAhdLOls7y6vfAw/6yLV/1mWALUaDFDjVFmLrBDuF7i5iEIKRXV4sFnaAmBxsEdRlBJD+cMiB9CmI72T2TzS2h+W2FdfMgbxrmR5VDxZHYfR3yccghI7H2ce79x4GoRhsLHoxQ+chwdRF06DxSCK6VlVCEwlG1QzJnUUMAjjhcyL9jTCETyTYRwgMMSAvEGX6m27tQ/ozvZAK5GYH2IlTBUg/D3qhZSvUcxj+I8yDzbCw0+eWmiGk3/Ymiz57ptOQ/m3Lu5F+DFIYHTns+yUTfTxgiybr89QWgwsuIpOBeXCleQyIs2ewEHrXqTKkv34eM6DH3lJPIomIFLqYB767jdHI7lt4BemfvsKeP++qOo6ak8eMf34Ze/cjvcwDL4EsjoVrxpC+/yKjwbmKme251MbyN8lElwGeiRvkjF/NE7sUZC8xAGlUPz3NMNSH6pgBtAAak4jIxAiLAEoz2SYyGpkHu9LLaHRPn65E+vc1MAji6aPqXFD67DVrWRLt3ElmQApmWPTqqWMGeGySedCRMMOw+4Ps+slElwEej03LE2PvgCb/D/KXZUuU9ObECCFMWolnNDIDurqhH+nvP1+C9G+/hyUSXt1RiPTjEEf78C0sE2NkJAyZP6gOQTR8jJGNxnawEHrLRuY8CIRAE9Ns73izGYXVVc72/iIDYwAlE10rw21Mk21pLUoXOsMcMGn0wExwlg/pv97FyNzUA7bAA6BrHzvFmwtZJVlmKfNChi6yMJpWAl4IqL+/0mfUKWwiIu3DDL5Z5mSH7yFIw5qKsQOoMZtFEJ39zHurK2YefDLRyYIQKVCMhMudzIA+euF5pH8k9xakX+ZkG7gun9HQzg+yUuZAmCXxSuphNdcw24SeLMaCsXkYhPJQfbey7s6dLHpJwKlh//x2DdL/0voLSH9mkq29rCXsBRR2sbXb3XWTYMAWoyb5drWFfH6KbcD9yzci/dPjjAdcA2lg4Qh7/mXzmRcT8rFNYC1nZHpbNQujQ+3MAM+MsfefblFPwm5ayvBnI+wFs6ybeYBXuz1Iv+ZulgS7uIO9gNMTmUj/9maWABYRkV3X/lnXqhyIBOVbvW8pXf/71auU9ObklQF2CpU5GYuhsop5sKc7GI0qy8sMUM4WZkCnD7MD6MwFFkYvWcWe3zQF+xkAGJJ++1wne3YcvbQzAH10DzPAbthMZxWMXqcnYC14EtGJAafLNqdaKF+WxhZBIMqa2biBByMisruN0ciikEdcM8W8gHNPMi+o5YMsDFy5jrHhNYDBioh4GhmLJHpWHQdcUcMwRN9J9u4DA8yApDlYO8xXLzEI5gMbWDOcnnMepG+DtiOZGPSMpTcYjJpBsX1E28bPKenNSQD2o/1eJ9uA317MEgEX/fQAYV4E5WFnpjMqUsndDAIInYA0OtrMrUR9/V3ZzQ6/8jWMR9z1Fktg5hcyGlz6Cnb9WA9jQUQV2yfMyfEzjAEkIrL+4HdaNU1b+t9/17UrCm0F8rmyTyvdwMkJloTbN8wwxC81sEVU3uRD+kdeZxDKrStYOagGi3km+xmEMbWfGfAIbGqe2QCbcl9UP8CqPsEqyX79d0z/gT9mBizexfbe2JvMg951uRzprypiDJ7xyE0CQdiMmlSkqe3kK9PMBXkfpDEdGGP19AN7mBdT62JezOVzEAOvYB58jE6UYHUU0r2PRRCJcwzDdmaoQyi7/5l5/9taWBIo0obUxeRi3z6jlMFPD8AiGqOLvX/b4UGkLyIix6/9s75eECISVsQyl2YyA5plY6eoZ5adYksK2CnqymT3PzrEwrjDZxmXc81SVkgShVTKaoijhvwMwrIDGrj/LDMAvZc8SH8Gwne/6mXX//b2i0j/B6+z0/uRe7uQ/rE+hmEnE10rI5IwSLeiJ9sIDfDQDPNAl2b7kH4mbCY0eZXdv83KQuhLQQYhrHOzJKK5iCXRpo+zCCI9n2Hg4UH159++sRtd2+hgEEDnAQ/S/3Qda+Zjzmb3/8nbWBWkBhPg+Q44EDKJ6DLA6eaErMlRo8TsG/Eo6c1JtpWBmLUwCfX8IXYK37GwG+kfucAq8Vbm+JC+0c42kf9tRqXybGFczrb/ZPfv9ajjqIkxZgBo9EThp6PnWPQ0toclwBfMZ724zx9lEz3y3QxDTya6DLAvYpQdip5cPuzlkAtx8AjEMO9dzsIYayG7/rpcWM8P5cI+ZgAbPsc24eB/MR72rmEWRj4CGur397H8gzMdNrSFzZyX1bEiIIMZlvIxCrcs/Rhzvr7398z5SSb6hnJaErI5X20xzM9i7SBf6mNE/suQBjZ+loXw33yKefD/uJgtYjLRQUSkvgKOJHqNff/saqQun8ljOOTfvFmrrPuXf8ryB77d7Nu7ljHvx5DN4KPEMEuAUjnxBMPgN+azCEJERM5f+2dddxZOGOVSUM0V7Q95lfTmJN/GMNB5sKFH6TKGQT5XxsJQC+ylEQ6wRWjPhW4InKgRGmR/4DdnypH+F5q6gTbz/odGmPNgv+BD+t3tLIn3Yi+DMP4QJvEWb2O2Y/zYTTIRw2ZMSLViOHRR0XDPSS+digw94NG9bBNl2hmON0KTkE2MShOBI6XSWhiLI9DDEiGV6bCZT5r6Jo4PMQyxYiEzIKY0dnjZzez6txUy52f8Mos+83KZ82KG+aekf1vPfw4njMqGdE0OK4SYCMOpugm2CNfdyULo2AjD8dIuMAN+9ASr5sl1MgPonWZh6N5LzIu67zPs+00fUocBEkG2gX3dbO27ctnaSUtja7egjh1ARjs7/BOwFa6WgGWUSUSXATYaNMlQBNRz05gH0g89QA12lT7wAmsH2VTLPNDsUmYATw+xTHBLPTNgpnTYC2ME4ohR6AU51Q3wwX0sieOAHmjzfIbfGy3MAFvK2d6NXIJVlAHmfFnTr18vCH084LhBuqfVHub8OKvkspsYBpkLIYC+abaIpiZYGCUwD3Dbx6EH38MM6JmD7ABbsJwZkcARtgmdper684tZEi4eY/c+dIqtvaxi5jy99gt2+C8pYTzktCx2gIz2M/gsmegywLNxTTr9ag9TA8sBd8NqwI9VMQ/o9qXdSH9mkiUyLDZ2/1dfZga0cAMLg01wIghNwh2GPOpN9epGwE49KDgNJRJke292kumvqmNVlOOjjIVhMjPnbQJG38lE15u1mgxSnKZmSPYPs0W0qYDpV3gYEBSdgR5UJuMiWr3s+h99jHkhT+axevzhELu+N8CSuGubGY/a36ZuhDJvZQngt59gCWArjB5pIcSP9rGJHHeXM+/LswC285y6SSrh4pomwajaw8zPZB5Yf4jpD8PJpkWLGQ3t9V2lSH/DEtYN7bm/ZRCEfx87ABYWMAjBARNBGnRCO/rVD5CmU8yA9M8w+K7BzfDzjvPs8PzUBkYjM3vY3r+8nxXCHB5h3eiSic5SZJGVuWoG2G1hIfRJGsLDseqa4sEzJ50BFsKnt7EQuv0tFkZ96iFI4xpgvUDoWJ7+duaFppnVIxhrIQvhtzaww/diP8TfoQdsdsH8wQF2/8EoWzyr89+Dqcjv0JFO18qIJQwyGlbzhM75mQf1cJkP6VMMMgaT8A0ulgRcvZUlIsoOw2ooC/t+s5OMymNzswN81wArBPro7eoNYRJBSKOCZfSLFjEDOtbDIJBYN4ye1rBOeKNnmfMzNQMT6ElENw3NpUhDK8tiHujX2tgivMXrQfpfXcQWwZp5DIMcbmWLIKExI+A/xQxg5nYWRk+8xCAUB8RB39irDiE1wDL8wCwzIItuZfBNVpRx+Hu7PEh/+DRzHnJrWPQWPHOTGGAidLT27YWMCrI2lyXhItCDpzQ0J8RAaUcto4UZsJkDLIwbHGUG3AaZBOsWqcMAzlqWQBw7wr7ds48z+KrGxe5//jo4DGCcrb04S9+IFfKwk4k+CEIzyPCsmiGajjEPLAj1r0IqSXM5UpfhQYZDGSGGbYowAzQwwTDUEq8P6dc0sU3s7WbVWH3d6t3gJjvY4VudxzrB3bGSTdSIzbC9t+M3bKDtthXdSP/AKdYJz266SUqRE5pIRNGV3V7MFtFFvwvp59iYB/mLFyqQfouXPf8EnAp8cYq9v+VFDIMOz7JgywCbMfXDkVTFOeoRVP0mdu/nnoZrfzlLYMQvsr1zz32MB+w/w9bOho3s+v/yPGzFl0R0PZnJIJKh6Mi1+9gG6A+xj1DpYh7Qg5sZlchSySCUv/8uowJ9fhOjAg1eZkagb4p50Fk+1pO2YQGDQPwD6jhsfJhhkHlZDIKI+xkH3T/CPHizizFggpBC+sLL+Uh/nZdh4CIi0nHtn3VZNYtRk0KHWijsgjjKpSlmgMudzABmnGObwDvNDoBPNrEwctdRFgZuWMwKMewjzAgkYE9y2o4zq0H9BszlrJm9o4cl8a4cZc5P2UIf0k+wrSPecgbiLp32If2SAqafTHRCEAaZiqphwKNhdoqaYEtOmoSxwRDYxBLZYrYxDHjrrYxLerWNHWAla5gXFGLnj7jns+8/0qr+AQvUe7mLiEhoiuUPHutg0dPX0ti3e+MKSwIaIIX0/RvZNBtKQU0mugywJiIxxXdhgw251+cxD2pFNQthQ9NsEwQHmQd2ZZCxABblsoYwRY3MCzE42Al0GU4GLppiLJjcheoe8MQr7PAeHGcebBGj8cqIjx2+t1UzCuYovL61gb2/P/trxiFPJvoMsCYSUXTEajNYDPnzbsYDXlHMDKjby7yAgR62CBYsYgb0h6+wRMIj91xG+o/9mGWit8OOWN9rZUnUR2PqEEwCTuWdhpVcX9jK8H9KwQxPM+ejrIxBMFdfZAyob25gU5lFRP7+HSI4g6a9e5e21FGo/Un1p5VuIAd2lU8zw6nIsBkPHepJJ1r0wGqcPBuLILJsDMirKmA0st5hD7t+KWOhaAABsqYz+CimSP2ck7/YW4X0P1bN3l1tCzOgwR72/CYLgzAoBCIi4n7iyVZN05b+9991JuFEvIptEWkSriKDATF7BhkORkpRRUSqIZe75iKLIwMhBgGcn4QevJsdAG4/OwAmx9j785arJ1GfP1SJrn3faoZh/vX7mAdMDh8REXMBe/dHd7NmOJmQgjqvlpVyJxNdBjiaMMiAIh3MbmIeZH+IVeNsKWYhrNHBTuHRNnb/l8dZJj3HwVrqbZrHknhpq9j9Z00zKtCFPtbQZfisOhWKdiMbuMQofK2jzID5omzvLs/2If3mEmYAs5fBXtQcgXhH+V9LwrlgU2SDsJcYhDPljLAUOBxmOFhz7QDSj0cZDmmCLIzwGRaGulsYhLP8PmZETj+m7oGnWZn3H4XzDLPg9deVs7WXBnnMznkMfhvah9Sla4wd3slEl1UwiKZM59o1xBbRHUVsEU3AhiaPfpd5cP/6GcajOv46y8Quu5dh4DPnWRLS5GLff/oUu77AnryeNPUwuvTRPHTt+AkWfWSfZIUgUUXq6ZyM9LMingIbiyAKP8gKMbIPwnE8IiJvX/tnfQbYIGJV/BafqmYvsXWSfcQM2I/4O5sZCyA6yjz4DIhjRbqYAXvzFKzn97BCDkcJMwLmWnaA2s+rJxFnXmAYbiTInj0WY9GXt5k5P1qIecDmcrb3v/NNpn9bIXv+ZKIvCWfQJM+udjPf72TlhHcUMQOa52RewMQIu//IAAuBrbAhyL5jjAa2ZQkzoGMXYTkrhLBy82BD+Ax1I2aOsw0cGGU0tMxS9uwx2I/cvp0lIS/8E2PQfOXzDELxH7pJRhLNJozSqTibq9bNMMgonClDDVjBPFZKfPIIC0MnIIZdDlkkFzsZDtY/wzLhyyAPeGQ3Wz/2NPX14yxlaz+zEtbywiKosU52eKY/1Y30y5vY4du5w4P0OyZvEgw4lhAZVjwMWrKZF1DoYKc45fEeOsjKKWthN7QFuRADheIbZkmw+WuZF/P5nzAv6q/XMQw+EVc3ogf3FKBrtzSxKs6ZMQZBePLZ2pscZGsnEmKHZ1mtD+lPtN0sU5GNmlSkq2GZs3F2DF8IQB5nhNHAymE3tUiEbQJaSReHEzEq5vuQ/tAp9v3+bBlrKRiPsfWXfYv6+llZyAzo8cPMgGdYYTP/APPArVZmQJ9rZ/mHB4zdSD8GKxmTiS6rEIqLnPWpXag5iz3E0CzT98JmOPk5jIfqrmKLcPgsO4WL7mI44uQudoBklzIMnoqthr2/+Li6F2guZCF8fTEDYaf8sBEWHOdks7O1/+FbGBE3MMScr3nw/ScTXbvKbDBIpk3NEPbBrvrlAIMT4aXI9gwGoXS3Mg+2BzZUP/44g2DW1bIIgBYTPNfDMPTPQja9DTihxmIPura5jfUBKVnFkkjBC5DBs5Y10+l8hkUvebks/5FWfJNMxHCYNJmfoXYzNhP7iLQhe3+QLYJxOFZmHCbRNi1nLIQTp1gYOzvDPOiCShZBfNDOwmhHDVs/rzxXqKy7VRiP9y/3sUZKnx1mCczMLBa99L3IDFjNLawT39PPMQjD2glrsZOIrmY8OZZC7Y6cR5QutDKXecA16ewUn1fAphq7ixkOFoMR+JkORiavKWRJwK4h1g6z5VMsDI1dYJV0/ccZBp1TpB4B0F7QlhzmARrdLATf+wxjAaxZzfD72VH2/PZcZkC72zxIX0Sk/o1/5c14Mq2a3F+itpGe7WMeyAI3HEoJeaTUgHZcYJVs05BM/2KH+lh1EZFNpcyL2v1vrBCiOptl4ktvZRDS5DH1928TdvhEWB2HpNez669awgzorv1s7W3ezpKYrW8y+CoA24EmE12rymgQcSq2hfxwBQtDhmEpcdoIw2BLjD6kPxVlXkhngEEgDRnMgBWtZhBA6VoP0o/vYwdAYppBYIOjHmXdrFkWQvfDTnSuQfbtKuax6IMOQ+g9xKKX5Z9hzpf/VVbIISIih6/9sy4DHE4YpHtazRAWOWAzG8DDFBF5fYh5YH/YwiCMlnTmRbQgbZFYiIVxCT8zYPEXzyL9GMuhinMVg1AWlKs/f4KhP5I7zpJw5hKW/wizTyeZ97BWsM6D7PAdf5HBl7Y03g/4nUT3VOR0xVCeMumOTrAQfFsB+wi0Goh6MfUVjArjyGNewPnDDAekTa0Lc1kSb/RXzAEYmFI3Yss2w9MDSqiNsQACwyz6tPkYfheHhYDhWWY7HFmwmXcS0d0PeEjxYWgl25JMBmHQiQ6uTKZv8cNEQC/z4CNXGA2tpoxFAPNeYiyOc9tZJjsOyfRLVql7YUY7wxBnemgWnj17ejZb+7NtTP+tE6yPyaY7GITQsZdFT8lEZyGGJu2KoajXxjxIugS/38l4qF+HPVWNsJ9xRRkr5Z2agO8fQkD9f1WP9GkvB9rMx+RSP8B+/ktmQO5tZmXUJgdbe92d7PC/GmSNrOqyGAbd9RaDYDRYRZpMdJYiG6QkTe1mXh9kHlhVBnsJX1/IQvjKNXA2dYJtgoFWlojIcDMIxp4Nj0D4/D9rZ5n0D8BEUHRYPQKLQO+bjgSyFrIQvMDHIBRvNoRAppjzMAobQVV5mfOTTHRiwJq4FQfcfbKaZYL9ERbG0ZlmtiPMA/PBoZrFeT6k397DaHArN7Ew8nt/zzDkP/oEK2aIDkAIKU99/X1kG+SRMd9Fwr1s7QanmAGzO1j0WLqefTtvN6viPHWGFTElE10GOJIwyJWg2ml+YITV4n+wnGHAmbAhSAw2E/J62CKgYVB1PjvFNTiTj4rvOPv+nf2skGV+lToTwZbNvP8zx9nhWZjJEpjeBpZEg51kxeBgB0BwhO2dsiwf0k8mOg2wJv3Tam9zbR47xhPCNuAk7EZWBQ243cm8gI5eRuWpK2ZJtM7n2fv7/BfZYMVXf6ReCiwismljH9KfvKjuAWesZxhoUybjsfW8zQxY/2kWff74AvMgv76eTXU2W5jtmZm5fs6Hrl2Vbha5JV/tYf7jKksk/Ns85gWcmGRAfHyAXT/PzsIoWgnn9LIDpDzHh/RP/YIdIJs2MwManWBe6N4r6v2g83/Ivr0mzIBm2hgDKS+TRW9/9UXGgddgK9ndv2LRD0xfJBVdu9ppSsgitxqW+xf2YiW9OfnhJWaA7ixmBujWeoZBdkIPdnERI+PvOcySWEthKXLDIpYEvXLUg/Srt8OetsfUM2G0F3OZm0EIEzMM/nO46Ew05oEOH2Dvb0E2g9/icCp1MtFn1Qy/LUdWkYtBdop9uoadwrNwIgZt6F2Zx6g0Z68yA+6BTbn7RlkSs2kLM4DpPcyLe+vpbKS/baM6jzkB+4gYmO8hRcJYCE/vZdNIKi4xBk4hHIbQ5WNrt7GYOT/JRNennQib5Jc9aqH8N1sYEf9gD8ORnLCpNK2mOTPEDGhLFSOT056mJjd7/n/9bgXS//BiNpV63X3MCHzlWzXKuivgOK711SyE7x/2IP0QTECv2MTwfy3CMIDcQWbAx4cZhp9MdO0qu0mT+gy1l3Gyn3UkUvW858QXZQbEBPsZh2EYY4TXH+1gYWjhnSyC+fyXWRKw61dsE0w9wzzwv/2EOpUsOsoOP0seW7vuGIu+hneytWMqZsMEBl5i0ZvFwt4/hXCSia4vq4lBwoqk8kwbe4lnfSyJVgybAXnK2QbOH2Mh9Ow0y0SHIQvk1R+yMM5iZBHIqkbmBTqWsvsfeUX9/eWugaXI59naCYwxDnoFxKCnD8FxXl6YQG1jZey59us3EFfXqkpov50LpyL7RlgpcJqZfYSD4+wUWznBXHAP7EWxG2ThRURWF7EwcP0yloQMjbMDIBJkEcTo88wL8gAY4a1fM/js+CRjQXx0EWMgVTQxCOVXzzP46d6VrJBl82oGf37vVXX46X8Sne0oNbkSUDOEzSwHImVO5sG+f94g0r/UzSq5qLR4WQhPS5HNLnYAhfqYF3hpjDVEueVhH9KPdKl78CuyWRl09mm2eVxljAFkTGPd0B7+HFu7cdjGoHM/i36q0ykL5J1FJw1NpElxH1ADuneELYJcO9vAmTAMmQixMLCohoVxl9vZ88+/g3mwXhOjoV3ewyKgK7+BlYyARemcx759VZQVYry6h4Xgy2D0lFnK1q5tIWzlupFdv7z7PegFcfzaP+vaVZPRuDzdr9aY444Cj5LenCyDPTmpAc3OYr0ssjSmH1UsAZ8TWsoc62BejKWeHQCVp31Iv6CFQUAGq7oHP9vJ1t7MJIsebtvAQvC332Lw19omxiHX/Oz9mfJZ/sgujEWRTPTNhLOY5f4ij9KFKtOYB5xhYWFAl59h0EUVrCNUPMwM4NMnGBfzgUaGA8YmWRLt6i+ZARwKsEx64gh7/3mgmdQ/7mYY4ifmsSpAM+yGVpTOnIdLB9i3y3Qx+Cyrju3dAOylnUx0fZm4JuJXtIPUgP7gEgvjvlDPFlHIxxaxS3GY6Zx8aBPjwdq2ViH94ccZC4FKaTbbRK4c5kWZs9U3YZ6dwSd5S9neOfxrVkbf1MjyJ3Sqs8HODKDByPau0cQSuMlEHwtC1HubjoQZhtsMNoCISHeQZZJrzQzDfGE3ywRnwYbwjb3Mi3LlsQgmbwNr6j38FOOyOhcwFszkIfX3/8gfMwy34xfMgzzlYxzq5dCDjgzAJKCFRV+2VawXxN5nmO1KJvo84ITIeFjtNG/zMRxraz4rp3RBD3w6wD7CPA9LBNQsYpvY5GJeiCmXHWCxdnaA5Sxj93/k1+wAyAYjtbLCzABpGjOA9S7m/fcdYNGnFXYStNlhL254eDfnw1rwJKKzEk6kQTEh6VIcZz8no9CDtsJS5Nx6hkPlRJg+nYqQCLE/oA2z+7fMYzS+sR0+pN+8lCWCSD+GBEyiFRWxveOdZc5LJMwMUP4Wph/rZfkDUybD/0fhMIZkon8ihuJsrRInO4UjsJSXFkIYbez6HceZB5aZzjq6jICpviIi9fOZB/vz77Ak6NYKZkRstzAcNLRLncubGGTR1yxsZGVzwnl6sJFTuANWgY6zvReDA0mmgiwCSCa6DHBMM8hYRO1lnPKxEHZZFvMCHNPs+mUBH9KvrGMQAp0q4IAN4Y3MicMyAkvRve2My2oCEHKgj3mAu7pYK9f33dGN9A1W5kEacxmGPfYy2/s5Zcx5cRWzBLCIiLx+7Z/1TcSIi/QoUuLisKnx4CxLwuXbYSXXKDuFXzlfjvS3LehG+hp8/8FBZkT+4NPMAEbhXK/Aefb9omF1L7RnxIOu/cA2RiE0ZjMP7vJO5oF782D+xoPUxVbPkpAdL9wkEzFmEwm5FFDDAhvcLAt9bIydghtgFp8WMmyqYjQu2g3t62+VI/3HPsJocH072f1bzMyIZNfCYoir6iFI02YW/Yy0svyHdwlb+0UVDP//zTHGANpQyUq5d/2MwX9rWt4DCuab1/5ZlwH2WA1yT4naRqhIYx/xjWHYEs/AklC9A+wjUnH4GQbRCG+/7SDrZ7zkAebB+o8wI2JtYC/Ad1mdRx4bZ/c+EWCluBm9rJTWAtfO+x9lLITQCfb+Nt0O197em2QihsOUkAVutYfpmWYG9P4SRuOyQhZGup0tgiE/wzBLc1kY91A2W4T2THYAhC8gdfFs9LA/4GLrL92rbkQog6WynhnQsI8ZkKFetnZzBtnetcNGXj/5LvsDofj1a8SlywBHE0bpU2xO3JjtU9Kbk+kIywJFYgxDzqlgQH6umelHfQwC+dlRVgn3fohBZ32EJZISHYxGNvoyi8BcYJ6AEUKI5ly29i0wge1eDnnMITgObJLBVx//P6wKNvEeNOP5/Fev/btOAywyGlZ7mX9zmjVjybKzU3y9l3mw9VaG410+xeK48joWxj28hHFxrvSw7xf9ESxntTIjEosxIzZ0RT2TX7aaHb6zXYzB8srxcqR/W3M30rcwBEXCY8z5CL7AKJTWtJukFDmSMEjvjNrLKEhjL7Eliy1CTdj1Dx1kHaGaa9lMt5kxxkLwLGbPb+pjXsiZAYYhl2UwCKZiNYNg3npV/QCKv8WcB5oAthjZt7OXMg/WmMdYCNMDzIM1WdjzX7jI1m4y0b2rVZdCX5CdIvcUsSx2eY4P6dshj/bqVeYGZLuZF7VnBytEWLuKZYLr3WwTH3uDbYKCHoZDHhhT55F/JJPxSAsbmQEytDIDdHYXi95M8AAo9LIDKBJiB2ApnGieTHQZYLNRJFuREbMsi2Ui2qfYKeo0MxxrYphRgdZuYiF4eIi9v+wxVgmYYOpizWOFMM0tDAOOMwhYvrBCnYZ3posNpJ04xBKIszD/0VDGxrKnlTMDPHUJ5m+2MtsxuYtFX8lElwG2GjQptKt5soWgmYmIyBnaz9fBFrEX3v9kO4MQ+kaZB12cw7wwcwbzQgyQBx4LsE1w5TLLhL85pA5BPHr3JXTtQ/vYTLnqXJZECk2zLKJjmu0dzwJmwLUoi74jszdJM564JhKIqbnzj11gHtD2IjgRA05lrqlkEyGisywMKsllBtRTxyCUt3bDoaBhBmGQZjgiIkNwtHiTRx0CMnnYzTdWMe9/cIg5L6WVPqQ/dAHS2IoYfj96kBlwKyzFTiY6m/GIuBSb8Xx1PjMgk2FYThlgYcjUeWaAnJCHTCU2wBbRmrXMgE5eYhCOK5dhIMvrWTWVESRyevcyA5SZw/D/3inWi6FUfEi/eCXDf4aPs71fvIJd32B+Dwzwjmv/rLMU2SAXg2qneaGDvcQCOBbl+X7mgf/dfcwA+XqZAXrlMuPRbixhXlT/abaJK7axA+jKTmhElrH1Ex5SN8DPXGEQwmfyGIRRDyGIcIBhsKZJ2IrWz5KAhbUs+gzuYhh4MtE3EUMTCUbVFiJtiD4QZF7EXUXsFLxyzoP0fwypLF9ZwgYruksYBEMPkNA55sG60hkOGZ1gSUx7pTqP+NMR1kfjB0eqkf62IgafZXmZB/7RJ9k8w++tY87PhZ8w58tsYod/0r+t5z8bDSLpFjV3/JVBlkQKwnaMtJTZZGA40vvgaO60LGZAO9tYEmr+Fnb/UUYCkXE/20S5D7Jy0mir+gNk3MLW/h/NZ4fvv/+0FOl/dguLHh5oY4dfVhPTD4FxUiIik0GWP0gmupNwU4oecDmDYAUOZJBJ0E5QRGTpdhbGxcYZBh6DLUnn3UK5jCwMtVayRZw7zBIxXT9iYXBhrfoBHG/zoWsPXWTR3/ZSBj9NtTHv584N3UhfgzS6kjsYBJHxFi9FfifRZYDTzZqsyFb7GEFF9sScrM5lHujwLDPAo0fY/U8FmRfkhM2AsszsBAsOs0x+9hqkLoEplkOgxQD+fnUIZhQ2k2/YzKKPcC/zAK1wqvGxPWwo5vwqhsG2v8mipwX1NwkP2Cia8mw3VfranNCpwEF4iroLGYZ59QzkMVdAHq+LZXIdIfb+L7zMNsGWYx1Iv/vrJUifGDGaQK3zMw8sEWbffnaQQQDL72L3372bhc8zMTiW/vr1Y9dngMMJo1wMqnkCM5CFNROnNDR2/buzbyyP1zfEnt+bzzzol06WI32rkW3ijg8wL2ryBPOAM6rVjdhHHu5F1/7VU6yh+T2rWCOm4DCzQG/9mn275mI2TWXNEtiHpfcm6Qecbo7Jmlyf0oX+qZ1lEh8sYxb8llyWSNBibANHIswDPznIejmsTmOZ5HWlbBEP+dj3j86wTZD9EDMC0cPqPOL4FMNQ53vY4d1xjjFwaC+E2x9l+H28l72/qXa2dq4OeZB+MtFlgIMxs7w95lG60Leb2Cn2N6eZAfpmEyuH1BSTj3PinceuvzDG2mFeucraSVYWs+unzzAIw+ZmHnTgBVaI4R9XTyLSZvwFHha+zYZhK84xBp/ZYBLLyHwX8axiEMaZXzAKZjLRZYANoolFkY6VgC311niZAXytj3lAd1iYB/nLCwyDXJvLEjEhioPBUuDqrSwJOH6YhcHZLUhdXv6lekOde9exoZoxFryJ2cXevb+HvXt7CbOgsVEW/cbHYS8K200ylj6cMMjloJohPXqahUEPl7OXGE6wMMTuYGHQo5svIv0XDzAccGM1O0AicKpB+ApspybMCBzcwXjQxIhSDnYhPHyzWB2HuBMsf2CuZnv/6Bvs9F++nRWilBbeJO0oRX5bjKEiaYoFHHPyJhzK+Ugd40LeaLnvbpbIoRKH5aS2JgaBxGEY6/UzL/CVA2XKusVOdm2rg737BCtkwx64ZZRhwM2LYS8H6MG+cJYVsiQTnRMxNOkJqHmC8zNhRygPO4VnIsyDyjLBVQjlG0+wcs4vNbNqqgnY0KVuHosgdhxnz9+cw7yYuz+iPtYmEWBrNxGA00j2sSrAyhKG/xvMLPq01TMM1+Bla7cQcvCTic6pyAZlQ+qBXLoc2E7y0Chr6HG/F5aiCUsi/fUj3Uj/wEssibnqFsaCiJxnRmRTJYMw8u5libDQYXU3cvcx5kEthTSsmmo2E82Ww6LXvleRuvymmzUz+tg61sxo3Wqk/ls5cu2fdSbhRGyKh1kntF+js+wUK3YyAzg4yjLBORHmQY+dY17AD2E7yN4ZhkHfv5JxUY2wki3cyry4gUvq3391DcPfnQVs7Z46yiZyVAXYuwuE2NrbWsQq4WxlzPsLnoONaJKIvm5oIhKMqZ2GxWlsA+UrTuKYk60VjIZEeayJBPMiJmfZIv6Pu5gBDPnYIv74M8yA/+gexiQY62I5hLIWdRxzuI19u5GR60eDejcShhMhapcx+GcWpm8SAbb3QgFG40sm+lgQcU26A2qG0AB7Gnty2R+YCTEDsmAly6SOnGOJgP2jLIReeQdcRJcZBPTZWqY/dpU9fxEcbDl+Tn39FKyHfSiOMx5wSaYP6UeDDMMdPMvK0AsWwCwiLGSbmGL3n0x0GWCbySDlLjU6UksWw/BmIY3M7WaZ1PbDLItfnMcwmLthIkSLsDDWBJ2w5lqGIRvMzIhdbvUg/ZJyn7LuVCtcu4uZBxruYdHj0ACD3/YNsSTgRxewfspTnez9m2EZfdK/rec/a7/7pyL/eZl5sPeUMn2bk+E4dU3MAJpcbBHMhpgXYCpgGLKJ5UHkucfZAbaiiCWiymp9SN8IDqBwgH37wBm2dk9dZuO0Fpayd78KOk9U2noYBp6fBj3wJKKPBWHUpN6lthjsJhYCRxLsFOrtYyyI2gKGY+19rRDpL61iHuTOHzEWxPYvMwjh/i+yMDp8kkUwPWc8SD/NoR7B5S1h767rAPNAPVYWfbrns+gjC9JooxeY/rp7WBJv8O2bZSqyiEzH1U6zY6NsET5cwU5RTxrbwGPtLAavyfIh/RfOsiRWFCYBJ55jB0Asyr5fOjs/pPZD7PpHf6xuBAsz2eGTncUKGU72sDL8yBCDMCaOsb2Xv5xVYU63swji5pmKLCIZiv2AtxXTTCJbBIeuskW4DrIogjOwH7GFPf+CLObB2xQjnzn5xk5WD/vYlxiVK9rOnr9prbqu/wjbwKMTzAPe9HnmAQd3sfsv3MT0DS44k+2iD6nb0m4SGprZqEmOTa2rlarenIzBjk7UA3zlImumY4E81pX5LIwKRdn7M8ORUt9oZh708H52/R2XqpD+TFx9/TxY24eunZfLPOiuJ1kW325j0d93/5Vh0I8sYlWcnYPM+boyfZPMhPNHjbJzUO1mWrLYKWI3MQz4jJ/R0D5Sw6ZKFsxjYWT7cZZJHp1lNLiSKR/SD8KRUE54gC/NYg1tFq1QPwBnhxn8cbmHNfOZhdNgZv1M/6FKRuSlHPpV97PoZ1EbS0KKiMipa/+sG11OKDpylS6WSbQZWQjeArPoeS3sADnwMvMCls5nEEgVc8DFUcY2Yd0KdoAO7WTfv3E1K8fVgP13rYFVnNOMwugqhN3MMtkBcvhNxkJYsYztXW2aGfCOK6ybWzLR2QtCk8WZahvpL04zD+iRGrYICnPoWHVmgFeuYQY0MgZpeJBGdm63B+kvfJi9v/xtbP3EYDvM6QH1A8g8xtZeZgP79uZKxgAK7PMhfQ/s4zLdjdQlYy3Dz4ozaR+YdxZdBjiWMMjQrJohvK+UbSCbkX3Ex06VI/0HShkPOAq5kKMhBiHcWsPCQMqD/v4/1yD9tV4f0r84xcL4taXqENRr51j082A6K0To+gULf3KyWfTTsMGH9BOzsBvcL1n+IxiFCZAkossAW42alCj2Jo3DiRgjMAmXb4ch8AwD4unzUwN+9W12AE7NsEz8B+pvbD/jPDdLZAWm1Q9A1UniczLcxcqwM90M/jPC/Ev3ATiSqZJFELSh/d8dLUf6yUSXAQ4lDNIRUCMlP1jOeim0jrEwqg6OZamEYYjDwTz4q+Nupg+bCTU1w0QKy6Hh0eoXu1gSs6JIPQLYXMgMQFotO3z9Z5C6vHK+HOmvhvkXWzErhPAB+EhEZJEHjnRPIrqebCIWlCcnDild6NDYAiW9ObmjiC3C1n5Gxfl/GxiNyl7EDEj7LubBrr2HJaFmYDWSDTZTMlewA2ReBnv+qx3q14/FmQHwxpgB/882RsHbnM+mkRyFE73viTAaWnYFG2e2IsTgt2SiywAX29LkryuWKl2I8mBf6GNh0Icr6EwyJrtfZzhgNexoZfAwDNlgYB78nt3FSH/VfFaIkbaSRRBau/r6pfDR6SuMx+qCjYxyMlgnOTpTTYux+yfjpERE6jzsAEwmOkcSGaQ/pDgRw8IM6JJstoj7YVNoGyyFXZ/DyPgGE/MgO59hBqi8AalLjp15ITSC+NbfMirUnz0MpirAXjT+DthNbdiD9K02FoI7i9jeN1hZBLFtPfOgDeb3oBT5zWv/rMuappni0qJYlz4ECwGyrIzGRAcjRsbZKXy124P0O3zMgFa6WCGIGWbCmx5iBnimlW3iP/90N9JPhNQ34Zk9rBMcncmWDmlgmU1IXQwOlsA2OFkCPjbOPNiJi9evIb7OSjiT7BxUy2jeU8xewsExloV/sZ99xL9wMwN2ZJRtwuW5DIcrb/Qh/SirhBbzMkYDM5xkLIbp8ywLOD6sTkVqvIetnd7XWP6C9sKe7mAesGslc760IDtA7E0sgR8E8NP/JLoMsN2kSUOG2sc4PsGSKBcgDLOE7X/JrWJUnttsDMO8OMQeIKefGQHakvAnX2Me9Mc+yYyQFmMetGOSfH/mQdFpMmbYyMmSzt7dTCs7POkwAP8AW7uTsx52A0lE91BOVTSq2ME8ELeZbeBAjOFooVGoP8s8cH+E6VMDOtvLNvEDTWymW6SLGQHb3fVI33BOHcOPXWWHd8k6RsN6/mnWkPeuLQxDNeUyCxrtZ/CV93bmgSdevkkq4abjBmmdVDOEaWa2iCrSmAHIst7YRILZwTLJVbAQpe8gw+HoTDVLM8tijj/LeOTyUgdS7z+nDoGVQgyV9rMtdDADFg+ww7vtbQYfluRAFkcuOwAD0zdJJZymicwq2rFSOBV5FnZEskD9GDwEZ6eYAa1cxTCYroNsE2iqXZh+J0e+z/QtRobjLV7JIJjQKfXvZ6nzoGufP8yiv+YWVkRjm+9B+ktvg1WkJ1kS8sIutvanYfSZTHSWIouUKx4GdsgDjkMcnDY0H+1j5ZQv9zIu58e9gAYlIlNhVsgRHmEH2LwqlsWjI6UMaez5C3LVT+DBHSz6K/Kytdt1mr27aocP6ZvjLHq8uJ/lj+rvY/DnqadvkpFENpMmlelq4VDvDHuINbCe+7FOZkA3LmQh+PucrBdCBA52pJIADclFRJzF7AQtmGXff+YoC+Pd89S9UKODGaAdT7Mins2woXlfK9s7+bAbXGEhW/takNkeozAMOZkYNO3dbwyLKU3zpKuVFO9f3qKkNyenx9kpngYbopSlMwNc18JoZFE/M2Ad51lP07J8Vs00Ms68GG82y6T7fIxFUbZK/ftfeZsZsMIyhn91dzEKZFkFW7vpKz1IX4zs8KftNKnzISKS+eR/tWqa9ntlxPoKMQwZssq0WekGRqZZGEBHGs3AqQCfbWUf4Y0FzIDua2WZ7FvXQw8c9iM2TVw/LuW7kfL1jAtrTFPP5FduYEkgbYZ5gLkTDP8+BttpLgqwZjz08MzMhBNBFKt/343o+stuq0G2Kw7X3DvKqCjFim0w56Qlx4f0n1jBDoCTJxgG/NMutoiWV7JFFJhiYVj17SwT3/06S+RkmlgvEMIjnulk8MeTx1kznc/9GTPA6bvYMAFHE4t+LIfY/Q8MsCRcQf5N0gvCICImg5onk2FhHlB1OvNgDo0yCOMDzV1IPyfBFtGTa9n7M2WyTK6zl92/Ns0OkNFpVoqdcZwdAEajuhFNh/j33ZXMAM4eYHvHBGdSajPMeTFZGYZe1cIgnPNvwyquJKLLAI9H4vLTHrXT4Gt17CseHGdcvA/XsUq0qQnmAZ4bYR9xfTZr5jPTz7ywnWcrkf7t87qRfoWXYdA59zMc1P8b9XaWtJlLVgkzoJfOsrVXv5q9e/9xZoC1BIveElEWPWdC5y+Z6Hoyp8ksSzwepQs928e8gM/UsFPsmUuwHSKcKeexsnp2fx+jUeVuYB7wg8sZjhe7yr5/4gosh91LJ9uq47Bh2EfjMmwmPxxizk/VBOPhuhvZ2pvtYgbckgmTeH03STMeUojxYBkLAR+7wHCkP1nIGnIXwqkGQR8zoCYzM0Dnn2eLqHYF84LMlQyHc8LJwAbI4jMY1d//1CB790fGPUj/4WVsplzPBXb9wRMsel2zng1DsNQz+LF/z01SCRdKxKU9oLYRnuphG7A4je2gcxMepJ+Xy2hQ3ZBGV1/MDhCXgyWhBttYJrrQyN5fAvbTdyxkm6j1aXX9JQ/DcVgDzHl54zRrSL51WTfSt165fiN93o0E9zHnwWJkaz+Z6GNBmE1ye75aMqTGxcKIQJQlcehgxKERdoDUFrJeBi93MBra/ctZEvFiJwuDSwpYGGicZEnA0T1s/S3eoP79YhB+W7uCHV7nTjIOeAzS4J7tZgygNUH2/Ms2M+clfPb6FUHpY0EYREyK93L/8b9VU/ydvL3mi0ifyiBsyJGr2Mh+TsqczAsKjjEIZOE2BsGM72VGKJ3tYXFmMgw+AnBcq5dt4PErED6qYQbIDAvBvvInzPnQQuzwnDrE1t75wE2CAc/ENDkxpuZJdt/xCSW9Obk8zjzgLBuLYb1pjEyPe7ICDPK9kMED7P2/3c8s6B3ZrJ1lf48H6ZfX+ZR1zeWMQte9i1nA5pJBpE/L4K2TDIIJtTPnw8bQP6lJZ4d3MtFlgB0mgzRmqW3EJy8UKum9V/Kxhus32fTdSM9VRoPqmWaZ7GXzGA0tHmCLsGaKRQCXOhiVqnYh+/6HjqlXg80eZYeXE8JnOroNXFPSG1n0lAgwD9YGe0GMnGL3v2E+qyIVEZFj1/5ZpwFOyEK3mid50sfc+E2wGoWOBjcqFqC8V3IhyKg8xnT2/AY72wSleSwR4sxhB0jEz+5/+SL1YogEzEEN97H8A2VhxPoYfp9dzl7AlfPMha1ZyRg0093vwVDOdxB9NDQRiWpqN+Nnh6Cc9bGGJt401kzHW8P0cxIMwvhyHcPROt9gi7iwANLAIA/s33bXIP1GOBdtUZE6CNzax+CXhmzWDGcywKKn2k1s7RscjEVQ7fQh/Y63WfRZv45dP5noLjFR7cu9vYB9RDPsJ9zl8yD99sPsI873shD42CDLZG9b0Y30jTAPceQwM0J3lbBqhqIKdoBMDKgbkbULWBWjf4xhwHSmXGyUeU+XTzHnKaGx569dyvberp0lSD+Z6DLA4YRRLk+r4SlDcCbaP1w9hfR/sZA1NLkUZIUgK6EH5hqFDeV7GIvDk83uf8UaRqbvOMYw4B1HWSk1oTFug88uwpJQVCI+pl9ex+Cn6VFmOwI9rJR57WJ2gIqIyJFr/6zrzswGTbw2tYV4xzzWFNpibET6vjBLIi3NYh6UPZOxGAKwnWbJNuYGabMskaGFGIYbjLLrv+8etv4696szGQwOiN/DVqyUxxuFjZQycpnz4Mli+okw23u0FWsy0WWA/RGRlxRJ5TlW1lP01iJWy+90MgNsNDEIhFJ5NGGLIDHJvCgtxp4/Bj345dsZBk6vPx1VN6I9r7C1V7qVYbhDe9i3szvY4anBeWJRH9O/coHBh9dTdBdiOMxqhsQXZQbk6DDDQM/6mRfyrY+zSrKTr7FKsi0LmAdnsLHnNzjY95s8ya5/+SRLIq66lyWyGpvVHYCxLmZAE+OMw56/jkUPE4fZt9+/nzXCuvVDDMKoSWPf/q+er0X6yUSXAU63iKz2qn2MRVnsJT7XyzDAMjjWvv9tlgiwmm5sPbwWhYUccCpyYJolYprmsWKCvt3s+sWr1b9f73FWiOE7yDzo+k2slHcKNuMPJ1j05z/E8g/hEMsgf3EZc75ERP7qHfoh6TLAJhFJM6lt5FicfYQtkAf8/U6WhLpvAVsEJ2E/YMcgCwOF2S/x5rFNnAubGVkVD/45yYwwGuCPn1JP4t1ZxXpRm2EnPIPlxg50XV7OFp8jjz1/tJc5D04v3HtJRJcBjmkivqjaxzw05lHSm5O1eSyM2ASbwZjgRI9Ni1g1jaOKJUJGjrFMsDWDbQJHswfp+/eyA9i9kXmhJe3qXmg4zN59+7AH6becZxM13G4WvWWtZR7o2F5YCLICwmdw7yQTXX/ZahQpVATkLwYYBngEjhRaX8h4pLEw8yLcjWwRDB9mBngahmGDZxkNrzGfHaAXexiGHvkxe3+bNqtTkUxutvb9O1kCNW0xw6B/+UPWRmBbiB0Ap4YYh3xxhDUjIs34/yfRORNOE6tiUxg/TMKtz2O9BEIgiy0ikmlkIezIket3ir4bcUAqkycDThXOZdVQBR4GYVDxX1T/ftnrWRKsJN+H9OPjLHr56F2soXt4mEWPZUFWxFWwHjKYuq4fD1ufB2xKSIliSe8G2M3r4hTDcC8GmQH8JkxkZMSYATRY2SkcG4VDKR3s+t/+h3Kk/40HLiJ9SyNj0UzvVo+gNHh2ZNTAaSj7WfTYsIpFL84FzAMvDrEEvtFNe2lcv06EuqxSMGaSI2NqH7Mxk63CsTDzYB8ohd3QIAvg6efYVIJFWT6kf9HPIITtmxiG/YctzIvavYdRmbY2MSaBFleP4A7sYMZ/1a1DSH/+Rh/SN9XlIX2Jw/xBHou+Jt5g0XPWgvfAAD977Z91GeDZuEHap9QWYu8MS4LUpLNEgC/MwsBgB/sI60pZOeoh2E+3DPYztjR5kX5mIzvANg8yHG/6TRYBOCrUMeR6Pysime5G6rgbm+kSy5/shCORPvAxBl8ZIHx402DANqNIuSISkGtjVI4SJzsFG2uYF2GHExkscKLFvRtYJeDMWfb+Bn/JuKCBaaYf11gY2/BBpj9zVD0MfqubNXOpSIcYKIw+825B6vLgeh/Sj/WyQpRW2AiqPMeH9JOJQi8INUN6YJRhsLfmsyx+ZxcLAxsLmAd25DQrxV4WZ5lk/wgzQE44FSCRoD1l2QEiThZGGwGJgpaRL7qFwWcxP4ve4iPs/v3HWf4j81YGn9UWsQjkV+fKkX4y0VeIYdAkXZEUviaXecBtcKx7SyHzIBMhWE8PK+ESivzrOaEG1J7J7n9gmB0AuVZogKuZF2p3qDsAizpZEslczpJIRjgSaPosWzvnehh81fgWi16vwFaublgIk0x0GeC4ZpBgTM0Q0IkOn2xg1UQ+ONKnsJJ5ASuqWRhoqCpH+lf/nVUjaQnmxTgsTD8O7a+MsEy+NuRT1q1cwZJAY68xDnPOhwqQvjPM8hdr7oDdxPwsf9Q8z4f0c/ZQDFlETl37Z10GeDIi8kyPmif48WqGgb4Fk1BpcK5W+Rm2gW35cK7VG2wTFH2QLeJED/PiskrYARiEmezBx9n7mwmpR2AVG+FA2SVIXRJdDD6LjbPoNfA882DTSlj0aS5nfUCsVjjOJ4noMsAui0HWF6h5sjv62Ut8sIwZ8AI4kshRzTx4DUYx3ma2CM4+zjZR3Up2/TM72QuYvwFCMHUQAgqqHwBXYCOgU2OsneJyWAVauI7lX8zZ7N23vQ5nwg0xDDgj9/rNg9RlgC1GTQrtahtx63yfkt6cnBpnH6HczQzQ8CEYBjawTK65jG3iBd9iOFzkZZYIanysDulru04ifUMayyEcf1ndCM2rZgZwWzXrg2H2MAjA4GRFUMYSD9IvP8PWnutWdoAF912/ieq6DHA0ITI0q8Zm8A+zbmALPCwEPTHKeglsqGZjSXa8Xo707/8DSEN7qh3p22sYjey1j7NCji0fYwfgwIssgmpep24EoxPMg6LRUxh2wjNlwirOHHYAeFoYg2rqTQafXbjCnJdkotMDFsm3q3mSe0dYCG8zslO4I8A+4t0VLIy6q+wK0g8x+ymBYRZGWrKYB7/5fcwL1CCVylPIjEgIjGZ3lNzYdpDRCfbuZs4zFsTMIZY/Sc9h18+4kzUTqtnBMOxkossqBaIG2TOsZkjX5zEI4Klu5kXYjOz6UT+7PuGRioiY4FTivDtZNdHsSWaALUtYBBI+wHjQ9AAyASpSehGLHmLdLPprP8toWOkwCVVa50P6tBAtcpglYP2TzPlLJroMsMOkyQKPmiHqgs1wKhgXWzSIo9MNbDCwG5iFvTDSBhkNzsWqSUXM7AQyuZl+9nxmRMJD6gb4yX8vRde+bwkzwG47OzzL1zMOoKmB9fHQBnxI39BcjfTznzuF9EVE5DfX/llfJZxRJEdxKnKxg4VBpelwETrYIsxqYGFQdAyeACyRK34/o4H1HGFeXPMS9v4nz0ADTJtyn1K//ke+7EPXbv+pB+nXbmCHb+As27tutw/pX3qBffuabAaCz1y9SXpBiPy2J7CKqLaxnJPJMDMAIyHYEi+dGZAEHCmUvZhh0N75rJpKAswLGn3Gj/Rz72QskP5fsyRcHhhJlRhm365uCzu8O19n4WPDIxD/ymcJ+OpEN9Kf3MG8l38/XoX0k4luFsSw4niVnhnYk9TFDGA/INKLiGxA2iJjgxBHgpls/y72/sqKfEj/eC8LQ9fuYywUN7MBYi5R/3697xB+vlvxVrDor2Y1O/z3/wsrglp1K8sgD7exAyC7lB2AjyzuRvoiIv/nwrV/12eANYMMhtTc8TU5zIM6CyezbszzIX0qxSvY8w8dZ4twwWYf0o+NsjB0QyajoRnY+SlXzzMvcOI36l5oyXoGXx1+kZUSL13BTu+mWqY/fo59vMI7mb4hg0V/wWcZiyOZ6EvCGTWpd6mdphMRlkSqTGNJlL5pxgKo62XlnNZ8hmN5cuFobliJKJCL6pjP3v/hp9kmqitmYagjW92L7N7NjP+ytYwGZall0WfsMOPRWqzMA935Q1ZG74SNsGpymO1KJrrxBKNiLmMTHM29/wrj8h0ZZ6fobRBB6NzPFlH1QnYKt51g7RjNBmaBm29lB9DCWlaIQsUEvr9DsXp0TrQoOzwnXmNJOCdjEIp7Prv/LVUMfrLUs0o4/+s3yUy4yYjIs71qGzHPzqpJ6txsEZkMLIljsLEsekU1M6DnTjIu59K7fEjf4IReQD7jscWjrJCjq4+BwI316klEr4sZ4MQ0W3vppQwD/tmrLAm1Ko+V8tZuha3w4DgxZ9FN0gvCa0/IF+rU8KwsyEW0wjCiLJ21lAtcZh5cDPbzXbSeLeJLr7EQvqjch/TTbKyQwn0/i4AWtjIyfnRAPQKwNTEPzAQNiFSxd7f+NMPvS1eyvWfMZdHj1WeZAXfDCCCZ6DLARoOITdEQHh/3KOnNyfJc5kEWZTMaVFoh8yJMacwAv/QyI/PfuZ1tIi3GvLDoJfb+f/k95sF+5ItsE5ut6oVE2jRzPqYPs+jPMcD0y29j0c/4Aea8pA2xvW+1MvgxFob9jJOIrlU1OmuUxy+qJRTWeNkp3j3FEhnxBDOA3gfYIgofYyH07Su6kf74GcaiyPsIg0AkixnAxkMQAy5kXqiE1WGE+AUWvRgtbO8YbGztju5n+H9mJWOBWEpZAte5gjGoNP97gAH//No/6zLATrNBFmepnQZtk+wUKS1ii2A2xhahNs4KSahY8tj9590La4m72QEy/F+MRdL4CYbh+3/GmiG5N6ofIOZydvjExhkLwbikAul7nSyBblhUg/QlzAz4019hGPx6yMNOJjqnIiekSrEi7LYi1tP0xBij0pRlsDDs0ousl0XZIqQupoWMC0p7MSSgF2BzsE0wc4B5kRnLmBc19or6JqQTLWLUAQuxP2BwwUo4IyzlDTEI5/1/w/Zuz3chCT2J6LqzcMIgPTNqN1OZwTzgLCsca1/LMMjAEMSRoANtnWR/YORJ5sF6vzKPXf+VbqRfvYg9f88rzAiU3QcM+G2r0LVHPnUA6Q/+C/Ogq7YxD9QIe0FoA+z+DVWskq9kHTsARERk57V/1p2Ec5rU8KgIhACMsJvYWA/zgIo/xDDoxFV2AGjTbBN4/2Q+u/7xi0jfaWcQkrEUTkT5EGQS5IPrHzyBLp2dyw6fc1cYB7wEJlDtDZDCCFkgWjtj4Lz4DGORJBNdBtgg6q05Z2IsDFhYyDDERAJmMmOwFAzqx0ZgP95MiON5GY2t+P9hzZBkxIfUv/c3LAn3hSfUKzEmftiFrt3Zzzj0qz4P1y7s4yIDjMVAx0lJMeOR1Wey6DGZ6LKKdlNC6t1qWNhIiGUiG3OZATp2pgjpF7iYBz/ZysIoF5wMSz1wYwGLAKZeYuW0GetZIuvzu+qRvrzdqqwajzH4Y+Wfsr0jfjhWvYElcLUcdvgZ/Cx/dPSPWCXdsve/B1OR37j2zzr7ASckx6n2MefBUtLjZ1gYcHySQRDrZlkSz10PvRA4FiDzzw8hff9LDyH9jK9CAzjAvBDDAGwnBxJBuY9WsmuP+pD61KtwKvDdDEIwRGApdgczoC1f9rDrD98kpcjRhFGGgmp0IA3M1BIROTzOmjFsLvAhfWlgXfWvPsGoLGWPeJC+/983I33pZ5s40dqN9KkHnjjZw65fDxI5XtgLc4RFT+lNkMVABU4VNWQxCmKig0VfsTGWf0kmugxwQjNIIKqG5f75YfYS13ghi8IJ68nbGY+UZlJjJ2Ep7RjbBI6lDAc0VjIcLnqSebBGO6RCJdTfn5bDDPD0aweRvqOCPbs2zpwHAyhiERGRChb9GuEwAblZDLDRoInLokYH+2oDnEopDMfq8zMPqgx+xM432AFUvcyH9O2LGYYqZraJn/9blkjZ0sQwcEsm6yVi7Ff3Qndsb0PXvvuT0AMcZXvHUASTcKMMw5UAY4FoUfbtaSvWZKLLAIfiRjnnV4MClmSxJFA4fmNpbLSUtf4uFgZpEdiUeg2rBOn9CqNS3f0hZgTGD7Dnz66GVKYZdS/urvex6EVjW0dM5R72B4IMA9VCzAM2DLAiHIODYdjmQpgETfa39fxno/yWCaEiZfkMxxocZR7cyQmmv9zFkniTB1kY42mCNLoACyNLv8bKWWWAYcieGpbEjY0yAzzZpY6j2tNYEZH7Q+zda5fZuzNkMg9chpgHrEEKpyGb5Y+M2WzvJxNdBthi1MRrUzvN7BlsEfZdYS/RZoQeUCmjsWWuYlxQQyOkApWVsOsPQA/exzxgy2rWDU5rZJV8eWPqXlhiXgO6ds+9zyL9so/DgazQ+TAshgfIWZZATQwzBpOxEjaiSiK6DPClmQm599Q7tPX5H+SJ6B8o6c1JTQbz4JbAdpSJJxkVxpjLFrHWyap5cEM9WI3k38e+n+fT7AAZ/eIupO/9gnpT8u8sYkm0r/0jS+L1P86KmIo/xDBUbf1ypG+AfUzkxGWknuhi7y+ZGDTt3W+smrQC7Z/mf0LpQlGNmYBlBYwHmp7BcCz3OhaGvfojD9K//cswEwu9GHHDMDQKM+Fp8ADzMAjK0AE2MUxC7fkB5LDfywyIFmUQQCLADLhlG4tetKpypv/zd6ii0CHmr/6kVdO0pb/3u54/khCDzCr21V1dwmhEThczQCbaU9XCTuEtdzIPdnY/W8T2ZbAfLjXgM7ChCU3E5DAjGGtVL+U237MMXXtJ7VGkrzD68f8npq2NSD/43ZNI3/nKeaRvqYbRY/VNAkEEogbZPaz2Mb9xhUEA86QW6f/DMkhmt7NMqqmSGUBjJsNQg/vY86fBTHbrL1gviKWPwokcuy4hfZMXFDOcuoCubcumfUSY8xL5D/UybBER992Mx5sAFEARkSfgNJUt5cyAJxOdvSBE6hXx/NU5LBFB21G63ZCMXc9KaTu+yjZh/cOMhpX+R7Ah8WWGgTc/18Ku38q4tOZHm5G+9uxedWWYxT92hPWCXvU+H9K3fnAh0qdJSGNHJ9L/g/sgB/41xuAREZEd1/5ZXy8Igya5NrVQeL6HecAXplgmt2uIeaA5VuYBF+RDMno5iwCkB3JRh2Azn4PHkX54L5xp9xJLxNi3lSvr0lLYVffDhupgnp2IiEz4kLqxizGA5Cp7f4YRBl9RHnMy0dmMR5Nsq9rNhGA7ysZs1tLOBj1o6gE6S6/faOt3I6FXGJXH8QHYT/gUK+W2VrMkoKGUhaGBp9XfX/oqVoXZ+jNWCLD0Wx6kH36ZRW/WWpb/mT0Dh5J+eDHSpzziZKLLKsYSBhmPqHmC+Ypd1Obk+CjEcWqZB3X8H5gXUs96+Uj8+Q6k73gAdiO7zDxouogpl9NQzXjUaYvUixloJdaCxYwBlDjOMFRrAwvhw2dY9OS4g3WTi+85h/THj98kU5EDMZH9I2osiLdHGQTwcDnjkfp8LIu/cCncBJAEYG9i9fhn/5JRkRZ8k01VEA+DkIw5LIzs/wqDQPLmq3/A2U52eP/DbgY//enDLAEpQXb4RaeYAbNdYXvPVMca2mfHGAQiIiLvUEujywC7zCK3eNUSCpXprKHGRJi11Ct0sUSI7QGWxBr8DsyEl7H3t+DD0AM92Y30Y0PXr6fqu5HCdWz9GNLVIRBLHYPfHrrCSonN1ezwDuxi8J/rLjjSh3Yzgw3pDQ6IoScRfRCEJjIZVfOAx6AB7Zpm+nkORoMqv8yoKK4cZoDCDMIVS4jxiM3LWCWadQXzgKceP4v00/Mhja1L3Qs8+jZjMTjNMH8Bx0mlLYBj2avY2knsYQyYiYOQQVUJ338S0cmCEHGb1TzJ1weZAbXCasTVrB2tRM6wENgCy/GnehkNra2VhWHrQuwEiPpZEvJfD9Ug/T92s6Give0eZd2V2xj8072fwWcjP2AJZHcJ4xGP/9kppG+zMwN4rp/BZ8uybxIe8HhEk190q32MH9zCDFjPhAfp28zQAyxkHnTlt9lQzL0rWBKpJsuH9GMBZkAPnypG+l99iNHIfvIcy4I+tET9+kY3M6CudBY95a5jIXSonRng7Ap2/7ZGBqG0/yPbu1X9N0k3NJvRKGXpag8TjTIXNqpYAj0nRfk+pB9k1ZTynYrfKwPXJZk5zAPt6GbllCUVjAu5sYXhcNF2dgB86guwoUpIfRPPtjP8/vIwGIckIjkh5vxMQANkUmxhOyf585n+Z77Enj+wD2LQSUSXAXaYNVmcqbYRhoMsCZRpY6foEyfVu1mJiHzuDhbCFl9m9//Ph5gH9+ffYAYosI95QT8+ytpJfqKFUanG21gElOFWf36zjTkPixpYFv6fn4DwzWdhL4VShv+d/i4zgAs/wNbubJDRCJOJ/plwMbVkxiAcS++1s5cIJ4JJXxsDcScV+dNzssDNPNATT7AwtH4e80A//+FupH98J8Ow68vZAWTPVffCjhxmLIDRMMP/q9LY3jn5LHOeGjexQoyqanZ47vkpg79WLGLwYTLRtSvj2m8b8qhIOsRgx+AiXAB7QZQ2My7kuTcZjgXbCcjiO1kpdHySsQjik+wAoQY0rZrdvxE0Y7oUZBjk8lzm/Vc1MBrZX+5kPOQFAfbtnC2sEGSVjRnQsJ+6b+8sugzwbFyTDp/aRro0xQzoVkglzLExLyARZh4g/YS3L2AY8OxlZsEPnmRexKZH2QE4cIZVsrg3sghktlXdCD7Vw579/UuZAbavZ5vnG3HGYbcUMwy55znmvJV/iOU/+n56k0xFthoNUuZSC2VrYSHEbJx5MD3TzAup7WcbePsnmBfifwupSyLM3t+qJuZF9PyS9XJwOtkm0KZvXC+O1/6e8WijF9i9R08yCCDsZwn0sdfZ2vOWsvf3639iBvi2xm6kn0x0GmBNSp1qiyEBJ2JMQwO8tYxVE/2krRzp3zXJwrALPkZmv30L64UhCfb+C1xsE8UYAiQDrzMj8tRF9UTWZ8IsgbvnFKMgrqhgfTymplj+hk4kj0PnYVsLawSVuH7N0PSNJDIYDKMiAmuyUpKSlKTk/zop0zTt91xxXQY4JSlJSUpS8t7J9UvvpSQlKUlJSpJKygCnJCUpSckNkpQBTklKUpKSGyQpA5ySlKQkJTdIUgY4JSlJSUpukKQMcEpSkpKU3CBJGeCUpCQlKblBkjLAKUlJSlJygyRlgFOSkpSk5AbJ/wfAwuw55vfKjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disc_acc = []\n",
    "gen_loss = [0]\n",
    "gan_acc = []\n",
    "for e in range(50):\n",
    "    g_accuracy = 0\n",
    "    d_accuracy = 0\n",
    "    print(\"Step\", e)\n",
    "    if d_accuracy < 1:\n",
    "        i, o = get_generator_outputs(stft_white_dataset_real, discriminator_train_size, gan.g, nperseg, stft_clean_dataset_real)\n",
    "    gan.block_generator()\n",
    "    print(\"Training the discriminator\")\n",
    "    s = 0\n",
    "    err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "    while d_accuracy < 0.95 and s<10:\n",
    "        d_accuracy = train_on_batch(gan.d, i, o, verbose=True)\n",
    "        disc_acc.append(d_accuracy)\n",
    "        gan_acc.append(0)\n",
    "        s+=1\n",
    "        gen_loss.append(err)\n",
    "    gan.block_discriminator()\n",
    "    print(\"Training the generator\")\n",
    "    s = 0\n",
    "    while g_accuracy < 0.95 and s<30:\n",
    "        view_output(stft_white_dataset_real, gan,p)\n",
    "        s+=1\n",
    "        p+=1\n",
    "        g_accuracy = train_on_batch(gan.combined_network, stft_white_dataset_real[:generator_train_size], np.ones(generator_train_size), batch_size=4, verbose=True)\n",
    "        gan_acc.append(g_accuracy)\n",
    "        disc_acc.append(0)\n",
    "        err = evaluate_generator(gan.g, stft_white_dataset_real, stft_clean_dataset_real, 100)\n",
    "        print(err)\n",
    "        gen_loss.append(err)\n",
    "    #print(evaluate_generator(gan.g, white_dataset, clean_dataset))\n",
    "plt.plot(disc_acc)\n",
    "plt.plot(gan_acc)\n",
    "plt.show()\n",
    "plt.plot(gen_loss[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.combined_network.save('save2/gan_with_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(b, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
