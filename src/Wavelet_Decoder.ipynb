{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Generative Adversarial Networks - Decoder\n",
    "## Initialisation and dataset preparation\n",
    "\n",
    "First, let us import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from misceallaneous import getWavFileAsNpArray, displaySpectrogram\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us include the dataset.\n",
    "\n",
    "The dataset is made of two files: `clean/p1.wav`and `white/p1.wav` which are converted into arrays of `int32` and then split into segments of `samples_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_family = \"db38\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 12000\n",
    "nperseg = 1024\n",
    "\n",
    "clean = getWavFileAsNpArray(\"../dataset_2/clean/p1.wav\")\n",
    "white = getWavFileAsNpArray(\"../dataset_2/white/p1.wav\")\n",
    "clean = np.array(clean, dtype=\"float32\")\n",
    "white = np.array(white, dtype=\"float32\")\n",
    "\n",
    "clean_dataset = []\n",
    "white_dataset = []\n",
    "\n",
    "samples_length = nperseg*2\n",
    "\n",
    "for i in range(0, clean.shape[0]-samples_length, samples_length):\n",
    "    clean_dataset.append(clean[i:i+samples_length])\n",
    "    white_dataset.append(white[i:i+samples_length])\n",
    "clean_dataset = np.array(clean_dataset)\n",
    "white_dataset = np.array(white_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = clean_dataset[0]\n",
    "ca, cd = pywt.dwt(ex, wavelet_family, \"per\")\n",
    "data_shape = ca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790526\n",
      "(5329, 2048)\n"
     ]
    }
   ],
   "source": [
    "wavelet_clean_dataset = []\n",
    "wavelet_white_dataset = []\n",
    "\n",
    "for sample in clean_dataset:\n",
    "    ca, cd = pywt.dwt(sample, wavelet_family, \"per\")\n",
    "    wavelet_clean_dataset.append(np.concatenate((ca, cd)))\n",
    "for sample in white_dataset:\n",
    "    ca, cd = pywt.dwt(sample, wavelet_family, \"per\")\n",
    "    wavelet_white_dataset.append(np.concatenate((ca, cd)))\n",
    "    \n",
    "max_clean = np.max(np.abs(wavelet_clean_dataset))\n",
    "wavelet_clean_dataset = np.array(wavelet_clean_dataset)/(max_clean)\n",
    "\n",
    "max_white = np.max(np.abs(wavelet_white_dataset))\n",
    "wavelet_white_dataset = np.array(wavelet_white_dataset)/(max_white)\n",
    "\n",
    "print(np.max(wavelet_white_dataset))\n",
    "print(wavelet_white_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(d, i, o, validation_split=0, batch_size=16, verbose=True):\n",
    "    history = d.fit(i, o, batch_size=batch_size, validation_split=validation_split, verbose=verbose)\n",
    "    return np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(sizes, lr):\n",
    "    inputs = tf.keras.Input(shape=(sizes[1]))\n",
    "    x = tf.keras.layers.Dropout(0.3)(inputs)\n",
    "    x1 = tf.keras.layers.Dense(512, activation=\"tanh\")(x)\n",
    "    x2 = tf.keras.layers.Dense(64, activation=\"tanh\")(x1)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"tanh\")(x2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_110 (InputLayer)       [(None, 2048)]            0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,081,985\n",
      "Trainable params: 1,081,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.3489 - accuracy: 0.4985\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.2698 - accuracy: 0.4937\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2636 - accuracy: 0.5003\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2599 - accuracy: 0.5060\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2569 - accuracy: 0.5165\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2558 - accuracy: 0.5084\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2546 - accuracy: 0.5097\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.2546 - accuracy: 0.5115\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2536 - accuracy: 0.5109\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2534 - accuracy: 0.5136\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2531 - accuracy: 0.5116\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2531 - accuracy: 0.5104\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2524 - accuracy: 0.5211\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2526 - accuracy: 0.5185\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2522 - accuracy: 0.5255\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2520 - accuracy: 0.5255\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2516 - accuracy: 0.5260\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2511 - accuracy: 0.5350\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2509 - accuracy: 0.5325\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2503 - accuracy: 0.5407\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2496 - accuracy: 0.5457\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2491 - accuracy: 0.5489\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2486 - accuracy: 0.5476\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2476 - accuracy: 0.5559\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2465 - accuracy: 0.5542\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2449 - accuracy: 0.5661\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2430 - accuracy: 0.5776\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2417 - accuracy: 0.5833\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.2395 - accuracy: 0.5872\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2378 - accuracy: 0.5943\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2339 - accuracy: 0.6099\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2317 - accuracy: 0.6129\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2281 - accuracy: 0.6232\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2270 - accuracy: 0.6280\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2220 - accuracy: 0.6457\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2182 - accuracy: 0.6587\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.6724\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.6810\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.6972\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.6949\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.7012\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.7087\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.7249\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.7302\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.7253\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.7380\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1834 - accuracy: 0.7426\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.7442\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.7541\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1741 - accuracy: 0.7641\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1716 - accuracy: 0.7655\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1668 - accuracy: 0.7732\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1660 - accuracy: 0.7800\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1604 - accuracy: 0.7918\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.7962\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.7940\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1547 - accuracy: 0.7983\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.8114\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1463 - accuracy: 0.8203\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.8184\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.8292\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1384 - accuracy: 0.8267\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1362 - accuracy: 0.8376\n",
      "667/667 [==============================] - 4s 5ms/step - loss: 0.1333 - accuracy: 0.8417\n",
      "667/667 [==============================] - 4s 6ms/step - loss: 0.1334 - accuracy: 0.8387\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.8477\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1280 - accuracy: 0.8467\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1236 - accuracy: 0.8605\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1249 - accuracy: 0.8575\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.8612\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.8635\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.8692\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.8687\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.8751\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.8757\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.8783\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1129 - accuracy: 0.8754\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1108 - accuracy: 0.8796\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.1105 - accuracy: 0.8799\n",
      "667/667 [==============================] - 4s 6ms/step - loss: 0.1084 - accuracy: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8887\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.8900\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1052 - accuracy: 0.8898\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.1052 - accuracy: 0.8933\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.8972\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1023 - accuracy: 0.8958\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0998 - accuracy: 0.8999\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1024 - accuracy: 0.8988\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0992 - accuracy: 0.9013\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.1013 - accuracy: 0.8940\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0976 - accuracy: 0.9087\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0964 - accuracy: 0.9050\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0970 - accuracy: 0.9093\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0969 - accuracy: 0.9073\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9043\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0970 - accuracy: 0.9058\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9101\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0966 - accuracy: 0.9069\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9107\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0942 - accuracy: 0.9096\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0931 - accuracy: 0.9124\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0918 - accuracy: 0.9176\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0923 - accuracy: 0.9155\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0912 - accuracy: 0.9174\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0895 - accuracy: 0.9196\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0906 - accuracy: 0.9152\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0905 - accuracy: 0.9163\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0905 - accuracy: 0.9141\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0898 - accuracy: 0.9178\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0871 - accuracy: 0.9242\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0893 - accuracy: 0.9215\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0860 - accuracy: 0.9254\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0864 - accuracy: 0.9248\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0877 - accuracy: 0.9194\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9217\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0854 - accuracy: 0.9237\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0845 - accuracy: 0.9292\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0867 - accuracy: 0.9202\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0843 - accuracy: 0.9261\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0868 - accuracy: 0.9219\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0867 - accuracy: 0.9242\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0853 - accuracy: 0.9263\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0837 - accuracy: 0.9293\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0827 - accuracy: 0.9302\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0819 - accuracy: 0.9278\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9274\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0828 - accuracy: 0.9316\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0833 - accuracy: 0.9278\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0823 - accuracy: 0.9306\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9330\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0818 - accuracy: 0.9297\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0802 - accuracy: 0.9354\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0805 - accuracy: 0.9333\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0806 - accuracy: 0.9306\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0798 - accuracy: 0.9318\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0806 - accuracy: 0.9325\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0806 - accuracy: 0.9339\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0799 - accuracy: 0.9323\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0783 - accuracy: 0.9374\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0786 - accuracy: 0.9363\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0801 - accuracy: 0.9354\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0795 - accuracy: 0.9350\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0785 - accuracy: 0.9359\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0778 - accuracy: 0.9355\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0783 - accuracy: 0.9361\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0788 - accuracy: 0.9334\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0784 - accuracy: 0.9344\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0763 - accuracy: 0.9391\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0767 - accuracy: 0.9399\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0760 - accuracy: 0.9373\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0744 - accuracy: 0.9429\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0758 - accuracy: 0.9391\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0746 - accuracy: 0.9417\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0747 - accuracy: 0.9417\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0753 - accuracy: 0.9433\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0757 - accuracy: 0.9404\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0758 - accuracy: 0.9404\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0746 - accuracy: 0.9393\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0757 - accuracy: 0.9435\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0742 - accuracy: 0.9428\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0736 - accuracy: 0.9469\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9405\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0755 - accuracy: 0.9368\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0740 - accuracy: 0.9414\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0737 - accuracy: 0.9432\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0736 - accuracy: 0.9444\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0738 - accuracy: 0.9417\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0712 - accuracy: 0.9470\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0705 - accuracy: 0.9473\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0733 - accuracy: 0.9461\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0738 - accuracy: 0.9432\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0730 - accuracy: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9500\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9451\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.0722 - accuracy: 0.9458\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.9466\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9468\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9472\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9491\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9481\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9475\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9461\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9476\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9481\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0694 - accuracy: 0.9492\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0703 - accuracy: 0.9491\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9442\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0707 - accuracy: 0.9478\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0694 - accuracy: 0.9488\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9506\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9503\n",
      "667/667 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9511\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0701 - accuracy: 0.9477\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0687 - accuracy: 0.9497\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.0679 - accuracy: 0.9515\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0696 - accuracy: 0.9474\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0680 - accuracy: 0.9503\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0671 - accuracy: 0.9524\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0686 - accuracy: 0.9513\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0689 - accuracy: 0.9523\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0675 - accuracy: 0.9511\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0682 - accuracy: 0.9483\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0671 - accuracy: 0.9515\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0685 - accuracy: 0.9513\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9546\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0682 - accuracy: 0.9479\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0679 - accuracy: 0.9495\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0679 - accuracy: 0.9532\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0668 - accuracy: 0.9516\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0657 - accuracy: 0.9552\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0680 - accuracy: 0.9506\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0674 - accuracy: 0.9506\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0672 - accuracy: 0.9501\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0663 - accuracy: 0.9542\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9506\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0652 - accuracy: 0.9562\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0657 - accuracy: 0.9528\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0649 - accuracy: 0.9544\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0664 - accuracy: 0.9544\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0661 - accuracy: 0.9522\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0639 - accuracy: 0.9554\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0658 - accuracy: 0.9532\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0672 - accuracy: 0.9516\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0651 - accuracy: 0.9553\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0652 - accuracy: 0.9546\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9576\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0651 - accuracy: 0.9539\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0644 - accuracy: 0.9559\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9556\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0638 - accuracy: 0.9551\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0641 - accuracy: 0.9566\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0643 - accuracy: 0.9550\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0649 - accuracy: 0.9550\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0659 - accuracy: 0.9536\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0632 - accuracy: 0.9569\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0645 - accuracy: 0.9568\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0631 - accuracy: 0.9559\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0655 - accuracy: 0.9546\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0637 - accuracy: 0.9552\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0638 - accuracy: 0.9557\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0629 - accuracy: 0.9600\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0622 - accuracy: 0.9605\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0612 - accuracy: 0.9598\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0626 - accuracy: 0.9548\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9540\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0636 - accuracy: 0.9589\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0625 - accuracy: 0.9586\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0637 - accuracy: 0.9570\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0618 - accuracy: 0.9593\n",
      "667/667 [==============================] - 3s 4ms/step - loss: 0.0629 - accuracy: 0.9566\n"
     ]
    }
   ],
   "source": [
    "d = discriminator(wavelet_white_dataset.shape, lr=0.0001)\n",
    "output = np.concatenate((np.zeros(wavelet_white_dataset.shape[0]), np.ones(wavelet_clean_dataset.shape[0])))\n",
    "for e in range(250):\n",
    "    train_on_batch(d, np.concatenate((wavelet_white_dataset, wavelet_clean_dataset)), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31221697]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.predict(np.reshape(wavelet_white_dataset[0], (-1, 2048)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
